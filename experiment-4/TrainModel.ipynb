{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37df1e8d",
   "metadata": {},
   "source": [
    "# Imports & Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73b3316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from yaml import safe_load \n",
    "from typing import Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8705fa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1776935e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.version:  2.9.1\n",
      "tf.keras.version:  2.9.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#@title Versions:\n",
    "print(\"tf.version: \", tf.version.VERSION)\n",
    "print(\"tf.keras.version: \", tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99764632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.compat.v1.enable_eager_execution()\n",
    "# tf.compat.v1.disable_eager_execution()\n",
    "# from tensorflow.python.ops.numpy_ops import np_config\n",
    "# np_config.enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6314444",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# # Check that GPU is available: cf. https://colab.research.google.com/notebooks/gpu.ipynb\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(tf\u001b[38;5;241m.\u001b[39mtest\u001b[38;5;241m.\u001b[39mgpu_device_name())\n\u001b[1;32m      4\u001b[0m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mclear_session()\n\u001b[1;32m      5\u001b[0m tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mset_jit(\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # Check that GPU is available: cf. https://colab.research.google.com/notebooks/gpu.ipynb\n",
    "assert(tf.test.gpu_device_name())\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "tf.config.optimizer.set_jit(True) # Enable XLA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b965151e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84ba337",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('LSTM65.yaml', 'r') as file:\n",
    "    model_config = safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf18162e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maximum sequence length including padding\n",
    "global MAXLEN\n",
    "MAXLEN = model_config['MAXLEN']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34891f72",
   "metadata": {},
   "source": [
    "# Load data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ed9c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"x1TrainRnnS\" not in locals():\n",
    "    train = pd.read_pickle(\"../data/proccesed_train_set.pkl\")\n",
    "    print(train['x1'].apply(len).describe())\n",
    "    x1TrainRnnS, x2TrainRnnS = train[[\"x1\", \"x2\"]].applymap(lambda x: np.asarray(x).astype('float32')).values.T\n",
    "    yTrainRnnS = train[\"y\"].astype('float32')\n",
    "    test = pd.read_pickle(\"../data/proccesed_test_set.pkl\")\n",
    "    x1ValRnnS, x2ValRnnS = test[[\"x1\", \"x2\"]].applymap(lambda x: np.asarray(x).astype('float32')).values.T\n",
    "    yValRnnS = test[\"y\"].astype('float32')\n",
    "    del train\n",
    "    del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7eb342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del x1TrainRnnS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdcd664",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1b0ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y = tf.constant([[[1.0,2.0,3.0], [1.0,2.0,3.0]],[[3.0,4.0,5.0],[3.0,4.0,5.0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecffcf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineSimilarity(tf.keras.layers.Layer):\n",
    "    '''Cosine similarity to be calculated as sum(x*y)/(sqrt(sum(x))*sqrt(sum(y))).\n",
    "    This is achieved through Tensorflow functions to retain performance.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    vects: tf.TensorArray\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    cosine_similarity: tf.TensorArray\n",
    "       The result of the cosine similarity between the vectors.    \n",
    "    '''\n",
    "    __name__ = 'CosineSimilarity'\n",
    "    def __init__(self, **kwargs):\n",
    "        super(CosineSimilarity, self).__init__()\n",
    "       \n",
    "    @tf.function  # The decorator converts `cosine_similarity` into a tensolflow `Function`.\n",
    "    def call(self, vects: tf.TensorArray) -> tf.TensorArray:\n",
    "        x, y = vects\n",
    "        return tf.math.divide(tf.reduce_sum(tf.multiply(x,y), axis=1, keepdims=True), tf.multiply(tf.norm(x, ord=2, axis=1, keepdims=True), tf.norm(y, ord=2, axis=1, keepdims=True)))\n",
    "\n",
    "    def get_config(self):\n",
    "        return super(CosineSimilarity, self).get_config()\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a72ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.assert_less(cosine_similarity(tf.constant([[[1.0,2.0,3.0]],[[3.0,4.0,5.0]]]))[0][0], 0.982708)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff560c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # @tf.function(jit_compile=True)  # The decorator converts `cosine_distance` into a tensolflow `Function`.\n",
    "# def cosine_distance(vects: tf.TensorArray) -> tf.TensorArray:\n",
    "#     '''Cosine distance to be calculated as 1-(cosine similarity).\n",
    "#     Where cosine similarity equals sum(x*y)/(sqrt(sum(x))*sqrt(sum(y))).\n",
    "#     This is achieved through Tensorflow functions to retain performance.\n",
    "    \n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     vects: tf.TensorArray\n",
    "        \n",
    "    \n",
    "#     Returns\n",
    "#     -------\n",
    "#     cosine_distance: tf.TensorArray\n",
    "#         The result of 1-cosine similarity between the vectors. \n",
    "#     '''\n",
    "#     x, y = vects\n",
    "#     return tf.math.subtract(tf.constant([1.0]), tf.math.divide(tf.reduce_sum(tf.multiply(x,y), axis=1, keepdims=True), tf.multiply(tf.norm(x, ord=2, axis=1, keepdims=True), tf.norm(y, ord=2, axis=1, keepdims=True))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafc3241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.assert_greater(cosine_distance(tf.constant([[[1.0,2.0,3.0]],[[3.0,4.0,5.0]]]))[0][0], 1 - 0.982708)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcd3f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(tf.keras.losses.Loss):\n",
    "    '''Returns a value between 0 and 1 representing the average error of the y_pred vector by comparing it to the y_true.\n",
    "    '''\n",
    "    __name__ = 'ContrastiveLoss'\n",
    "    def __init__(self, margin: tf.float32 = 1.0, **kwargs):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = tf.constant(margin)\n",
    "        \n",
    "    @tf.function # The decorator converts `loss` into a tensolflow `Function`.\n",
    "    def call(self, y_true: tf.TensorArray, y_pred: tf.TensorArray) -> tf.Tensor:\n",
    "        return tf.math.reduce_mean((1 - y_true) * tf.math.square(y_pred) + (y_true) * tf.math.square(tf.math.maximum(self.margin - (y_pred), 0.0)), axis = -1)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(ContrastiveLoss, self).get_config()\n",
    "        config.update({\n",
    "            \"margin\": str(self.margin)\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc864cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = ContrastiveLoss(margin = 1.0)\n",
    "# print(a.get_config())\n",
    "# tf.assert_ a.call(np.array([1,0,1]), np.array([1,0,1])).numpy() == 0.0\n",
    "# tf.assert_ a.call(np.array([0,0,0]), np.array([1,0,1])).numpy() >= 0.666\n",
    "# tf.assert_ a.call(np.array([0,1,0]), np.array([1,0,1])).numpy() >= 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57038ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_type: Literal[\"lstm\", \"gru\"], embedding_dim: int, num_rnn_node: int, num_dense_node: int, num_layer: int, activation_fn: str, learning_rate: float, optimizer_fn: Literal[\"Adam\", \"RMSprop\", \"SGD\"], margin: float, output_activation: str) -> tf.keras.Model: \n",
    "    '''Specifies the architecture of the model to be trained.\n",
    "    '''\n",
    "    input_x = tf.keras.layers.Input(MAXLEN)\n",
    "    input_1 = tf.keras.layers.Input(MAXLEN)\n",
    "    input_2 = tf.keras.layers.Input(MAXLEN)\n",
    "    embedding = tf.keras.layers.Embedding(input_dim=28, output_dim=embedding_dim, mask_zero=True)\n",
    "    x = embedding(input_x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "    match model_type:\n",
    "        case \"lstm\":\n",
    "            x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(num_rnn_node))(x)\n",
    "        case \"gru\":\n",
    "            x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(num_rnn_node))(x)\n",
    "        case \"rnn\":\n",
    "            x = tf.keras.layers.Bidirectional(tf.keras.layers.RNN(num_rnn_node))(x)\n",
    " \n",
    "    num = num_dense_node\n",
    "    for _ in range(num_layer):\n",
    "        x = tf.keras.layers.Dense(num, activation=activation_fn)(x)\n",
    "        num /= 2\n",
    "        \n",
    "    embedding_network = tf.keras.Model(input_x, x)\n",
    "\n",
    "    tower_1 = embedding_network(input_1)\n",
    "    tower_2 = embedding_network(input_2)\n",
    "\n",
    "    cosine_similarity = CosineSimilarity()\n",
    "    merge_layer = tf.keras.layers.Lambda(cosine_similarity)([tower_1, tower_2])\n",
    "    normal_layer = tf.keras.layers.BatchNormalization()(merge_layer)\n",
    "    output_layer = tf.keras.layers.Dense(1, activation=\"hard_sigmoid\")(normal_layer)\n",
    "    contr = tf.keras.Model(inputs=[input_1, input_2], outputs=output_layer)\n",
    "    \n",
    "    match optimizer_fn:\n",
    "        case \"Adam\":\n",
    "            opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        case \"RMSprop\":                \n",
    "            opt = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "        case \"SGD\":                \n",
    "            opt = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "    contr.compile(loss=ContrastiveLoss(margin = margin), optimizer=opt, metrics=[\"accuracy\"])\n",
    "    \n",
    "    return contr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e297fd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_metric(history, metric, title, has_valid=True):\n",
    "    \"\"\"Plots the given 'metric' from 'history'.\n",
    "\n",
    "    Arguments:\n",
    "        history: history attribute of History object returned from Model.fit.\n",
    "        metric: Metric to plot, a string value present as key in 'history'.\n",
    "        title: A string to be used as title of plot.\n",
    "        has_valid: Boolean, true if valid data was passed to Model.fit else false.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    plt.plot(history[metric])\n",
    "    if has_valid:\n",
    "        plt.plot(history[\"val_\" + metric])\n",
    "        plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "    plt.title(title)\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e10db6",
   "metadata": {},
   "source": [
    "# Build model, load weights and evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314b46ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = model_config['Learning_Rate']\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.90,\n",
    "    staircase=True)\n",
    "\n",
    "model = get_model(\n",
    "    model_type =  model_config['Model_Type'], \n",
    "    embedding_dim = model_config['Embedding_Dimensions'], \n",
    "    num_rnn_node =  model_config['Number_RNN_Nodes'],\n",
    "    num_dense_node =  model_config['Number_Dense_Nodes'], \n",
    "    num_layer =  model_config['Number_Layers'], \n",
    "    activation_fn =  model_config['Activation_Function'],\n",
    "    learning_rate = lr_schedule,\n",
    "    optimizer_fn = model_config['Optimizer'],\n",
    "    margin =  model_config['Margin'],\n",
    "    output_activation = model_config['Output_Activation']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c1d074",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "time = datetime.datetime.now()\n",
    "checkpoint_filepath = \"../ModelCheckpointSaves/maxlen-{}/{}/{}/{}\".format(MAXLEN,model_config[\"Model_Name\"],time.strftime(\"%a-%b-%d-%Y\"), time.strftime(\"%I-%M%p\"))\n",
    "print(checkpoint_filepath)\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', mode='auto', patience=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e8f2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model weights are saved at the end of every epoch, if it's the best seen so far.\n",
    "history = model.fit(\n",
    "    x=[np.stack(x1TrainRnnS), np.stack(x2TrainRnnS)],\n",
    "    y=np.stack(yTrainRnnS),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=200,\n",
    "    validation_data=([np.stack(x1ValRnnS), np.stack(x2ValRnnS)], np.stack(yValRnnS)),\n",
    "    callbacks=[model_checkpoint_callback, early_stopping],\n",
    "    use_multiprocessing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ac27e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy\n",
    "plt_metric(history=history.history, metric=\"accuracy\", title=\"Model accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aae1b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the constrastive loss\n",
    "plt_metric(history=history.history, metric=\"loss\", title=\"Constrastive Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d179e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = input(\"Want to replace best model with this model? (y/n): \")\n",
    "\n",
    "if save.lower() == \"y\": \n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    tf.keras.models.save_model(model, './saved_models/{}_extended'.format(model_config[\"Model_Name\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
