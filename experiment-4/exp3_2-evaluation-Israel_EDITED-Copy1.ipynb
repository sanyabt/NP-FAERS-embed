{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6af2f21c",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "090cfeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from IPython.display import display, clear_output\n",
    "import re\n",
    "# from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "\n",
    "# tf.enable_eager_execution()\n",
    "# tf.executing_eagerly()\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()\n",
    "\n",
    "\n",
    "import string\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#!pip install scikit-optimize\n",
    "# import skopt\n",
    "# from skopt import BayesSearchCV\n",
    "# from skopt import gp_minimize, forest_minimize\n",
    "# from skopt.space import Real, Categorical, Integer\n",
    "# from skopt.plots import plot_convergence\n",
    "# from skopt.plots import plot_objective, plot_evaluations\n",
    "# from skopt.plots import plot_histogram, plot_objective_2D\n",
    "# from skopt.utils import use_named_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8ac8644",
   "metadata": {},
   "outputs": [],
   "source": [
    "global encode_dict \n",
    "encode_dict = {l:i for i,l in enumerate(string.ascii_uppercase + \" \", 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77bf5508",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maximum sequence length including padding\n",
    "global MAXLEN\n",
    "MAXLEN = 65"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d07e995",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3126405d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST_TXT = \"Eirmod horrida ingénii pariant secundum? Cognitionem compositis conséquat dicantur exercitus, intellegitur invenire negat oportet sapientium suam. Ceteris diu erat fecerit, impéndéré intelleges máerores malorum mei re reprehendunt? Constringendos intus mentitum quale urna! Convenire cotidie dixit malé vigiliae?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "639e9acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessInput(filename: str) -> pd.DataFrame:\n",
    "    ''' Preprocess CSV file into a Pandas DataFrame.\n",
    "    \n",
    "    Expects the file name or path of a csv file with named columns containing strings representing product names.\n",
    "    Returns a Pandas Dataframe containing uppercased versions of the strings on each cell.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    df : Pandas DataFrame\n",
    "    '''  \n",
    "    df = pd.read_csv(filename)\n",
    "    print(df.info())\n",
    "    \n",
    "    print(\"Processing file: ---------------------------------------\")\n",
    "    original_count = len(df.index)\n",
    "    print(\"Dropping sequences longer than the maxlen:\")\n",
    "    for column in df.columns:\n",
    "        df.drop(df[df[column].apply(len).gt(MAXLEN)].index, inplace = True)\n",
    "    new_count = len(df.index)\n",
    "    print(\"\\tDropped\", original_count - new_count, \"that exceeded the maximum sequence length.\")\n",
    "    # Uppercase all values\n",
    "    print(\"\\tUppercasing string sequences.\")\n",
    "    df = df.applymap(lambda x: str.upper(x))\n",
    "    print(\"Done processing: --------------------------------------\")\n",
    "    print(df.info())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e38610fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(w: str, percent: float = 0.1) -> str:\n",
    "    ''' Adds a specified proportion of noise to a string.\n",
    "    \n",
    "    Expects a string and a number stating the percent of noise to add to this string.\n",
    "    The string is modified by editing, deleting, or adding characters in/to the string.\n",
    "    The modification to perform is determined randomly by generating a random number from an uniform distribution [0,1].\n",
    "    If the number is < 1/3 edit one position with new random character.\n",
    "    If the number is < 2/3 delete one position.\n",
    "    Finally, if the number is > 2/3 add one random character. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    w : str\n",
    "        The string to add noise to.\n",
    "    \n",
    "    percent: float, defaults to 10% if not specified\n",
    "        Percentange representing the proportion of noise to add to the string.\n",
    "        \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    w : str\n",
    "        Modified string with noise added.\n",
    "    '''  \n",
    "    positions = random.choices(range(len(w)), k=int(percent*len(w)))\n",
    "    print(\"Adding noise to\", int(percent*len(w)), \"% of the string\")\n",
    "    for p in positions:\n",
    "        r = random.uniform(0,1)\n",
    "        \n",
    "        # if <1/3 edit one position with new random character, # else if <2/3 delete one position, else add one random character \n",
    "        if r <= 0.3333: # edit\n",
    "            w = w[:p] + random.choice(string.ascii_uppercase) + w[p+1:]\n",
    "        elif r<= 0.6667: # delete\n",
    "            w = w[:p] + w[p+1:]\n",
    "        else: # add\n",
    "            w = w[:p] + random.choice(string.ascii_uppercase) + w[p:]\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84c406ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_noise(TEST_TXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76dec01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_noise(TEST_TXT, .01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5e9e0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text: str) -> str:\n",
    "    '''Removes all the non-ascii and special characters from a string and returns the string's alphabetichal characters with spaces.\n",
    "    \n",
    "    Expects a string to be cleaned and removes all the non-ascii and special characters. \n",
    "    This is done by applying a substitution to regex matches\n",
    "    Returns the cleaned string containing uppercased versions of the characters.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    text : str\n",
    "    '''\n",
    "    regex = re.compile('[^a-zA-Z ]')\n",
    "    r = regex.sub('', text)\n",
    "    result = re.sub(' +', ' ', r)\n",
    "    result = result.strip()\n",
    "    return result.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d6ecd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean(TEST_TXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f21e6000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(x: pd.Series, y: pd.Series) -> (pd.Series, pd.Series):\n",
    "    '''Applies the cleaning function to the dataset.\n",
    "    \n",
    "    Expects two Pandas Series, namely the 'FAERS_drug_match' and the 'lookup_value' columns.\n",
    "    Applies the cleaning function to them and returns them separately.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : pd.Series\n",
    "        A pandas Series containing the 'FAERS_drug_match' column.\n",
    "    y : pd.Series\n",
    "        A pandas Series containing the 'lookup_value' column.\n",
    "      \n",
    "    Returns\n",
    "    -------\n",
    "    x : pd.Series\n",
    "        Returns the cleaned 'FAERS_drug_match' series.\n",
    "    y : pd.Series \n",
    "        Returns the cleaned 'lookup_value' series.\n",
    "    '''\n",
    "    return x.apply(clean), y.apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae47b9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_dataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da17e429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_dataset(x: pd.Series, y: pd.Series) -> (pd.Series, pd.Series):\n",
    "    '''Applies the encoding function to the dataset.\n",
    "    \n",
    "    Expects two cleaned Pandas Series, namely the 'FAERS_drug_match' and the 'lookup_value' columns.\n",
    "    Returns these Series enconded into an array containing an integer mapping to each character and space (1-66) separately.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : pd.Series\n",
    "        A pandas Series containing the clean 'FAERS_drug_match' column.\n",
    "    y : pd.Series\n",
    "        A pandas Series containing the clean 'lookup_value' column.\n",
    "      \n",
    "    Returns\n",
    "    -------\n",
    "    x : pd.Series\n",
    "        Returns the encoded 'FAERS_drug_match' series.\n",
    "    y : pd.Series \n",
    "        Returns the encoded 'lookup_value' series.\n",
    "    '''\n",
    "    return x.apply(lambda string: list(map(encode_dict.get, string))), y.apply(lambda string: list(map(encode_dict.get, string)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c73327d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode_dataset(*clean_dataset(test))[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb4895a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_encode_padding(q, maxlen):\n",
    "#     q = clean(q)\n",
    "#     return tf.keras.preprocessing.sequence.pad_sequences(\n",
    "#         [encode_dict[m] for m in q] , padding=\"post\", maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "229e70ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_dataset(X: pd.Series,Y: pd.Series, maxlen: int = MAXLEN) -> (pd.Series, pd.Series):\n",
    "    '''Applies the padding function to the dataset.\n",
    "    \n",
    "    Expects two cleaned and encoded Pandas Series, namely the 'FAERS_drug_match' and the 'lookup_value' columns.\n",
    "    Returns the enconded Series padded.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : pd.Series\n",
    "        A pandas Series containing the clean encoded 'FAERS_drug_match' column.\n",
    "    y : pd.Series\n",
    "        A pandas Series containing the clean encoded 'lookup_value' column.\n",
    "      \n",
    "    Returns\n",
    "    -------\n",
    "    x : pd.Series\n",
    "        Returns the padded 'FAERS_drug_match' series.\n",
    "    y : pd.Series \n",
    "        Returns the padded 'lookup_value' series.\n",
    "    '''\n",
    "    return X.transform(lambda x: x + ([0]* (maxlen-len(x)))), Y.transform(lambda x: x + ([0]* (maxlen-len(x))))\n",
    "#     return tf.keras.preprocessing.sequence.pad_sequences(X, padding=\"post\", maxlen=maxlen), tf.keras.preprocessing.sequence.pad_sequences(Y, padding=\"post\", maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33e3bb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding_dataset(*encode_dataset(*clean_dataset(test)), MAXLEN)[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98b10d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_negative_pairs() -> (pd.Series, pd.Series):\n",
    "    '''Create negative pairs where 'FAERS_drug_match' does not match the correct 'lookup_value'.\n",
    "\n",
    "    For each unique name in the 'FAERS_drug_match' column of the train set, get the product name\n",
    "    and then pick four random different product names. For each of those 4 additional product names \n",
    "    check if it matches any of the names in the training set if its not then add it to the dataset as \n",
    "    a negative pair. The goal of this is to help further distance the embeddings in the vector space.\n",
    "\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    The function has no parameters but it expects a Pandas dataframe called Unique_df\n",
    "    containing the 'dUnique_label' series and another Pandas dataframe called train\n",
    "    containing the 'FAERS_drug_match' and the 'lookup_value' series.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    faers_match : pd.Series\n",
    "        Returns the 'FAERS_drug_match' series.\n",
    "    lookup : pd.Series \n",
    "        Returns the 'lookup_value' series.\n",
    "    '''\n",
    "    faers_match = []\n",
    "    lookup = []\n",
    "    for np_name in train['FAERS_drug_match']:\n",
    "        np_temp = dUnique_df['dUnique_label'][dUnique_df['dUnique_label'] != np_name].sample(4)\n",
    "        np_temp = np_temp[~np_temp.isin(train['lookup_value'].loc[train['FAERS_drug_match'] == np_name])]     \n",
    "        faers_match.extend([np_name]* len(np_temp))\n",
    "        lookup.extend(np_temp)\n",
    "    return faers_match, lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab15102",
   "metadata": {},
   "source": [
    "------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193e520b",
   "metadata": {},
   "source": [
    "# Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae8f0708",
   "metadata": {},
   "outputs": [],
   "source": [
    "fName = '../data/NP_FAERS_mapped_20220215.csv'\n",
    "fName_unmapped = '../unmapped_data/upper_unmap_orig_drug_names_202201201812.csv'\n",
    "fName_negatives = '../data/NP_FAERS_negative_pairs_20220222.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622bfc23",
   "metadata": {},
   "source": [
    "## Create the train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "168de8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5358 entries, 0 to 5357\n",
      "Data columns (total 2 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   FAERS_drug_match  5358 non-null   object\n",
      " 1   lookup_value      5358 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 83.8+ KB\n",
      "None\n",
      "Processing file: ---------------------------------------\n",
      "Dropping sequences longer than the maxlen:\n",
      "\tDropped 374 that exceeded the maximum sequence length.\n",
      "\tUppercasing string sequences.\n",
      "Done processing: --------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4984 entries, 1 to 5357\n",
      "Data columns (total 2 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   FAERS_drug_match  4984 non-null   object\n",
      " 1   lookup_value      4984 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 116.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(preprocessInput(fName), test_size=0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb5d87e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3987, 2) Test: (997, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\", train.shape, \"Test:\" , test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037a06e2",
   "metadata": {},
   "source": [
    "## Clean, Encode and Pad the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b10fe6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_xTest, padded_yTest = padding_dataset(*encode_dataset(*clean_dataset(test.FAERS_drug_match, test.lookup_value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1307539",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = clean_dataset(train.FAERS_drug_match, train.lookup_value)\n",
    "padded_x, padded_y = padding_dataset(*encode_dataset(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1577f320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9242 entries, 0 to 9241\n",
      "Data columns (total 2 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   FAERS_drug_match  9242 non-null   object\n",
      " 1   lookup_value      9242 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 144.5+ KB\n",
      "None\n",
      "Processing file: ---------------------------------------\n",
      "Dropping sequences longer than the maxlen:\n",
      "\tDropped 1372 that exceeded the maximum sequence length.\n",
      "\tUppercasing string sequences.\n",
      "Done processing: --------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7870 entries, 3 to 9240\n",
      "Data columns (total 2 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   FAERS_drug_match  7870 non-null   object\n",
      " 1   lookup_value      7870 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 184.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "negative_set = preprocessInput(fName_negatives)\n",
    "padded_xneg, padded_yneg = padding_dataset(*encode_dataset(*clean_dataset(negative_set.FAERS_drug_match, negative_set.lookup_value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3181fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test padded x: (997,) Test padded y: (997,)\n",
      "Train padded x: (3987,) Train padded y: (3987,)\n",
      "Train padded x_neg: (7870,) Train padded y_neg: (7870,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Test padded x:\", padded_xTest.shape, \"Test padded y:\", padded_yTest.shape)\n",
    "print(\"Train padded x:\", padded_x.shape, \"Train padded y:\", padded_y.shape)\n",
    "print(\"Train padded x_neg:\", padded_xneg.shape, \"Train padded y_neg:\", padded_yneg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cdae7d",
   "metadata": {},
   "source": [
    "## Creating Pandas DF for simplified view of the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59682339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dUnique_label</th>\n",
       "      <th>dUnique_seq</th>\n",
       "      <th>dUnique_seq_padded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ECHINACEA</td>\n",
       "      <td>[5, 3, 8, 9, 14, 1, 3, 5, 1]</td>\n",
       "      <td>[5, 3, 8, 9, 14, 1, 3, 5, 1, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GARLIC</td>\n",
       "      <td>[7, 1, 18, 12, 9, 3]</td>\n",
       "      <td>[7, 1, 18, 12, 9, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VACCINIUM MACROCARPON</td>\n",
       "      <td>[22, 1, 3, 3, 9, 14, 9, 21, 13, 27, 13, 1, 3, ...</td>\n",
       "      <td>[22, 1, 3, 3, 9, 14, 9, 21, 13, 27, 13, 1, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZINGIBER OFFICINALE</td>\n",
       "      <td>[26, 9, 14, 7, 9, 2, 5, 18, 27, 15, 6, 6, 9, 3...</td>\n",
       "      <td>[26, 9, 14, 7, 9, 2, 5, 18, 27, 15, 6, 6, 9, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SERENOA REPENS</td>\n",
       "      <td>[19, 5, 18, 5, 14, 15, 1, 27, 18, 5, 16, 5, 14...</td>\n",
       "      <td>[19, 5, 18, 5, 14, 15, 1, 27, 18, 5, 16, 5, 14...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dUnique_label                                        dUnique_seq  \\\n",
       "0              ECHINACEA                       [5, 3, 8, 9, 14, 1, 3, 5, 1]   \n",
       "1                 GARLIC                               [7, 1, 18, 12, 9, 3]   \n",
       "2  VACCINIUM MACROCARPON  [22, 1, 3, 3, 9, 14, 9, 21, 13, 27, 13, 1, 3, ...   \n",
       "3    ZINGIBER OFFICINALE  [26, 9, 14, 7, 9, 2, 5, 18, 27, 15, 6, 6, 9, 3...   \n",
       "4         SERENOA REPENS  [19, 5, 18, 5, 14, 15, 1, 27, 18, 5, 16, 5, 14...   \n",
       "\n",
       "                                  dUnique_seq_padded  \n",
       "0  [5, 3, 8, 9, 14, 1, 3, 5, 1, 0, 0, 0, 0, 0, 0,...  \n",
       "1  [7, 1, 18, 12, 9, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0...  \n",
       "2  [22, 1, 3, 3, 9, 14, 9, 21, 13, 27, 13, 1, 3, ...  \n",
       "3  [26, 9, 14, 7, 9, 2, 5, 18, 27, 15, 6, 6, 9, 3...  \n",
       "4  [19, 5, 18, 5, 14, 15, 1, 27, 18, 5, 16, 5, 14...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dUnique_df = pd.DataFrame(columns = ['dUnique_label','dUnique_seq', 'dUnique_seq_padded'])\n",
    "dUnique_df['dUnique_label'] = y.unique()\n",
    "dUnique_df['dUnique_seq'] = dUnique_df['dUnique_label'].transform(lambda x: list(map(encode_dict.get,list(x))))\n",
    "dUnique_df['dUnique_seq_padded'] = list(tf.keras.preprocessing.sequence.pad_sequences(dUnique_df['dUnique_seq'].array, padding=\"post\", maxlen=MAXLEN))\n",
    "dUnique_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ede033",
   "metadata": {},
   "source": [
    "## Add positive pairs\n",
    "Data from NP_FAERS_mapped_20220215.csv -- the manually create references set for ~70 drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0017a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3987 3987 3987\n"
     ]
    }
   ],
   "source": [
    "x1TrainRNN = list(padded_x)\n",
    "x2TrainRNN = list(padded_y)\n",
    "yTrainRNN = [1] * len(padded_x)\n",
    "print(len(x1TrainRNN), len(x2TrainRNN), len(yTrainRNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a1f592",
   "metadata": {},
   "source": [
    "## Add negative pairs from unmmaped\n",
    "Data from NP_FAERS_negative_pairs_20220222.csv -- the negative pairs created by random sampling from the NP_FAERS_mapped_20220215.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f290eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11857 11857 11857\n"
     ]
    }
   ],
   "source": [
    "yTrainRNN.extend([0] * len(padded_xneg))\n",
    "x1TrainRNN.extend(padded_xneg)\n",
    "x2TrainRNN.extend(padded_yneg)\n",
    "print(len(x1TrainRNN), len(x2TrainRNN), len(yTrainRNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34303435",
   "metadata": {},
   "source": [
    "## Generate additional negative pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7369033f",
   "metadata": {},
   "outputs": [],
   "source": [
    "faers_match, lookup = generate_negative_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f5c6d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfneg2 = pd.DataFrame(columns=['FAERS_drug_match', 'lookup_value'])\n",
    "dfneg2['FAERS_drug_match'] = faers_match \n",
    "dfneg2['lookup_value'] = lookup\n",
    "padded_xneg2, padded_yneg2 = padding_dataset(*encode_dataset(*clean_dataset(dfneg2.FAERS_drug_match, dfneg2.lookup_value)), MAXLEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10975c1",
   "metadata": {},
   "source": [
    "## Add additional negative pairs \n",
    "Generated from training data using generate_negative_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "594f5dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27579 27579 27579\n"
     ]
    }
   ],
   "source": [
    "yTrainRNN.extend([0] * len(padded_xneg2))\n",
    "x1TrainRNN.extend(padded_xneg2)\n",
    "x2TrainRNN.extend(padded_yneg2)\n",
    "print(len(x1TrainRNN), len(x2TrainRNN), len(yTrainRNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eda81396",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1TrainRnnS, x1ValRnnS, x2TrainRnnS, x2ValRnnS, yTrainRnnS, yValRnnS = train_test_split(x1TrainRNN, x2TrainRNN, yTrainRNN, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "479a632a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22063"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x1TrainRnnS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea67a844",
   "metadata": {},
   "source": [
    "# Save data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f9204378",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data={\"x1\": x1TrainRnnS, \"x2\": x2TrainRnnS, \"y\": yTrainRnnS}).to_pickle(\"../data/proccesed_train_set.pkl\")\n",
    "pd.DataFrame(data={\"x1\": x1ValRnnS, \"x2\": x2ValRnnS, \"y\": yValRnnS}).to_pickle(\"../data/proccesed_test_set.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34891f72",
   "metadata": {},
   "source": [
    "# Load data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b4ed9c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"x1TrainRnnS\" not in locals():\n",
    "    train = pd.read_pickle(\"../data/proccesed_train_set.pkl\")\n",
    "    x1TrainRnnS, x2TrainRnnS = train[[\"x1\", \"x2\"]].applymap(lambda x: np.asarray(x).astype('float32')).values.T\n",
    "    yTrainRnnS = train[\"y\"].astype('float32')\n",
    "    test = pd.read_pickle(\"../data/proccesed_test_set.pkl\")\n",
    "    x1ValRnnS, x2ValRnnS = test[[\"x1\", \"x2\"]].applymap(lambda x: np.asarray(x).astype('float32')).values.T\n",
    "    yValRnnS = test[\"y\"].astype('float32')\n",
    "    del train\n",
    "    del test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdcd664",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e10db6",
   "metadata": {},
   "source": [
    "# Build model, load weights and evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "968d57af",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function  # The decorator converts `cosine_similarity` into a tensolflow `Function`.\n",
    "def cosine_similarity(vects: tf.TensorArray) -> tf.TensorArray:\n",
    "    '''Cosine similarity to be calculated as sum(x*y)/(sqrt(sum(x))*sqrt(sum(y))).\n",
    "    This is achieved through Tensorflow functions to retain performance.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    vects: tf.TensorArray\n",
    "        \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    cosine_distance: tf.TensorArray\n",
    "       The result of the cosine similarity between the vectors.    \n",
    "    '''\n",
    "    x, y = vects\n",
    "    return tf.math.divide(tf.reduce_sum(tf.multiply(x,y), axis=1, keepdims=True), tf.multiply(tf.norm(x, ord=2, axis=1, keepdims=True), tf.norm(y, ord=2, axis=1, keepdims=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ff560c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function  # The decorator converts `cosine_distance` into a tensolflow `Function`.\n",
    "def cosine_distance(vects: tf.TensorArray) -> tf.TensorArray:\n",
    "    '''Cosine distance to be calculated as 1-(cosine similarity).\n",
    "    Where cosine similarity equals sum(x*y)/(sqrt(sum(x))*sqrt(sum(y))).\n",
    "    This is achieved through Tensorflow functions to retain performance.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    vects: tf.TensorArray\n",
    "        \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    cosine_distance: tf.TensorArray\n",
    "        The result of 1-cosine similarity between the vectors. \n",
    "    '''\n",
    "    x, y = vects\n",
    "    return 1 - tf.math.divide(tf.reduce_sum(tf.multiply(x,y), axis=1, keepdims=True), tf.multiply(tf.norm(x, ord=2, axis=1, keepdims=True), tf.norm(y, ord=2, axis=1, keepdims=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a90470b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(margin=1):\n",
    "    def contrastive_loss(y_true, y_pred):\n",
    "        square_pred = tf.math.square(y_pred)\n",
    "        margin_square = tf.math.square(tf.math.maximum(margin - (y_pred), 0))\n",
    "        return tf.math.reduce_mean(\n",
    "            (1 - y_true) * square_pred + (y_true) * margin_square\n",
    "        )\n",
    "\n",
    "    return contrastive_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6f49b548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(model_type, embedding_dim, num_rnn_node, num_dense_node, num_layer, activation_fn, learning_rate, optimizer, margin):\n",
    "    input_x = tf.keras.layers.Input(MAXLEN)\n",
    "    input_1 = tf.keras.layers.Input(MAXLEN)\n",
    "    input_2 = tf.keras.layers.Input(MAXLEN)\n",
    "    embedding = tf.keras.layers.Embedding(input_dim=28, output_dim=embedding_dim, mask_zero=True)\n",
    "    x = embedding(input_x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "    if model_type == \"lstm\":\n",
    "        x = tf.keras.layers.LSTM(num_rnn_node)(x)\n",
    "    elif model_type==\"gru\":\n",
    "        x = tf.keras.layers.GRU(num_rnn_node)(x)\n",
    " \n",
    "    num = num_dense_node\n",
    "    for _ in range(num_layer):\n",
    "        x = tf.keras.layers.Dense(num, activation=activation_fn)(x)\n",
    "        num /= 2\n",
    "        \n",
    "    embedding_network = tf.keras.Model(input_x, x)\n",
    "\n",
    "    tower_1 = embedding_network(input_1)\n",
    "    tower_2 = embedding_network(input_2)\n",
    "\n",
    "    merge_layer = tf.keras.layers.Lambda(cosine_similarity)([tower_1, tower_2])\n",
    "    normal_layer = tf.keras.layers.BatchNormalization()(merge_layer)\n",
    "    output_layer = tf.keras.layers.Dense(1, activation=\"sigmoid\")(normal_layer)\n",
    "    contr = tf.keras.Model(inputs=[input_1, input_2], outputs=output_layer)\n",
    "    \n",
    "    if optimizer == \"Adam\":\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer ==\"RMSprop\":                \n",
    "        opt = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "    contr.compile(loss=loss(margin= margin), optimizer=opt, metrics=[\"accuracy\"])\n",
    "    \n",
    "    return contr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8f2a61af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model2(model_type = \"lstm\", embedding_dim = 256, num_rnn_node = 248, num_dense_node = 124, num_layer = 1, activation_fn = \"tanh\", learning_rate = 2e-4, optimizer= \"Adam\", margin = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "549ed13a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_14 (InputLayer)          [(None, 65)]         0           []                               \n",
      "                                                                                                  \n",
      " input_15 (InputLayer)          [(None, 65)]         0           []                               \n",
      "                                                                                                  \n",
      " model_8 (Functional)           (None, 124)          540028      ['input_14[0][0]',               \n",
      "                                                                  'input_15[0][0]']               \n",
      "                                                                                                  \n",
      " lambda_4 (Lambda)              (None, 1)            0           ['model_8[0][0]',                \n",
      "                                                                  'model_8[1][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 1)           4           ['lambda_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1)            2           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 540,034\n",
      "Trainable params: 539,520\n",
      "Non-trainable params: 514\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model.load_weights(\"../exp3-hyperparameter-tuning/alstm-22-0.01.hdf5\")\n",
    "model.load_weights(\"../ModelCheckpointSaves/best_model.h5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "170a71eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-29 22:35:01.907456: E tensorflow/stream_executor/cuda/cuda_dnn.cc:389] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2022-07-29 22:35:01.907501: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at cudnn_rnn_ops.cc:1553 : UNKNOWN: Fail to find the dnn implementation.\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nDetected at node 'cond/CudnnRNNV3' defined at (most recent call last):\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n      app.start()\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/asyncio/base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/asyncio/base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_198503/4002307798.py\", line 2, in <cell line: 2>\n      predicts = model.predict([np.tile(padded_xTest.loc[i], (dUnique_df['dUnique_seq_padded'].shape[0],1)), np.stack(dUnique_df['dUnique_seq_padded'])])\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 2033, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 1845, in predict_function\n      return step_function(self, iterator)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 1834, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 1823, in run_step\n      outputs = model.predict_step(data)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 1791, in predict_step\n      return self(x, training=False)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/layers/rnn/base_rnn.py\", line 515, in __call__\n      return super(RNN, self).__call__(inputs, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/layers/rnn/lstm.py\", line 673, in call\n      runtime) = lstm_with_backend_selection(**normal_lstm_kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/layers/rnn/lstm.py\", line 1184, in lstm_with_backend_selection\n      gru_lstm_utils.function_register(defun_gpu_lstm, **params)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/layers/rnn/gru_lstm_utils.py\", line 244, in function_register\n      concrete_func = func.get_concrete_function(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/layers/rnn/lstm.py\", line 1149, in gpu_lstm_with_fallback\n      return tf.cond(\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/layers/rnn/lstm.py\", line 1121, in cudnn_lstm_fn\n      return gpu_lstm(\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/layers/rnn/lstm.py\", line 997, in gpu_lstm\n      outputs, h, c, _, _ = tf.raw_ops.CudnnRNNV3(\nNode: 'cond/CudnnRNNV3'\nFail to find the dnn implementation.\n\t [[{{node cond/CudnnRNNV3}}]]\n\t [[model_9/model_8/lstm_4/PartitionedCall]] [Op:__inference_predict_function_40574]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [74]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m i \u001b[38;5;241m=\u001b[39m padded_xTest\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m predicts \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpadded_xTest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdUnique_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdUnique_seq_padded\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdUnique_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdUnique_seq_padded\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m argsort \u001b[38;5;241m=\u001b[39m predicts\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39margsort()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Top-5 smalles distances\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nDetected at node 'cond/CudnnRNNV3' defined at (most recent call last):\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n      app.start()\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/asyncio/base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/asyncio/base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_198503/4002307798.py\", line 2, in <cell line: 2>\n      predicts = model.predict([np.tile(padded_xTest.loc[i], (dUnique_df['dUnique_seq_padded'].shape[0],1)), np.stack(dUnique_df['dUnique_seq_padded'])])\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 2033, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 1845, in predict_function\n      return step_function(self, iterator)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 1834, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 1823, in run_step\n      outputs = model.predict_step(data)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 1791, in predict_step\n      return self(x, training=False)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/layers/rnn/base_rnn.py\", line 515, in __call__\n      return super(RNN, self).__call__(inputs, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/layers/rnn/lstm.py\", line 673, in call\n      runtime) = lstm_with_backend_selection(**normal_lstm_kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/layers/rnn/lstm.py\", line 1184, in lstm_with_backend_selection\n      gru_lstm_utils.function_register(defun_gpu_lstm, **params)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/layers/rnn/gru_lstm_utils.py\", line 244, in function_register\n      concrete_func = func.get_concrete_function(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/layers/rnn/lstm.py\", line 1149, in gpu_lstm_with_fallback\n      return tf.cond(\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/layers/rnn/lstm.py\", line 1121, in cudnn_lstm_fn\n      return gpu_lstm(\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/layers/rnn/lstm.py\", line 997, in gpu_lstm\n      outputs, h, c, _, _ = tf.raw_ops.CudnnRNNV3(\nNode: 'cond/CudnnRNNV3'\nFail to find the dnn implementation.\n\t [[{{node cond/CudnnRNNV3}}]]\n\t [[model_9/model_8/lstm_4/PartitionedCall]] [Op:__inference_predict_function_40574]"
     ]
    }
   ],
   "source": [
    "i = padded_xTest.index[0]\n",
    "predicts = model.predict([np.tile(padded_xTest.loc[i], (dUnique_df['dUnique_seq_padded'].shape[0],1)), np.stack(dUnique_df['dUnique_seq_padded'])])\n",
    "argsort = predicts.flatten().argsort()\n",
    "# Top-5 smalles distances\n",
    "test.loc[i, 'rank1_drug'] = dUnique_df['dUnique_label'][np.where(argsort == 0)[0][0]]\n",
    "test.loc[i, 'rank2_drug'] = dUnique_df['dUnique_label'][np.where(argsort == 1)[0][0]]\n",
    "test.loc[i, 'rank3_drug'] = dUnique_df['dUnique_label'][np.where(argsort == 2)[0][0]]\n",
    "test.loc[i, 'rank4_drug'] = dUnique_df['dUnique_label'][np.where(argsort == 3)[0][0]]\n",
    "test.loc[i, 'rank5_drug'] = dUnique_df['dUnique_label'][np.where(argsort == 4)[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "caf4f49a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FAERS_drug_match</th>\n",
       "      <th>lookup_value</th>\n",
       "      <th>rank1_drug</th>\n",
       "      <th>rank2_drug</th>\n",
       "      <th>rank3_drug</th>\n",
       "      <th>rank4_drug</th>\n",
       "      <th>rank5_drug</th>\n",
       "      <th>lookup_rank</th>\n",
       "      <th>lookup_rank_related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>SAW PELMETTO</td>\n",
       "      <td>SCRUB-PALMETTO</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2969</th>\n",
       "      <td>FLAXSEED (LINUM USIATISSIMUM SEED OIL)</td>\n",
       "      <td>LINUM USITATISSIMUM</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>GINGERAID</td>\n",
       "      <td>GINGER</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674</th>\n",
       "      <td>UHE RED YEAST RICE CRANBERRY</td>\n",
       "      <td>RED YEAST RICE</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>QUEEN CITY HEMP 500MG (CBD)</td>\n",
       "      <td>HEMP EXTRACT</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            FAERS_drug_match         lookup_value rank1_drug  \\\n",
       "1633                            SAW PELMETTO       SCRUB-PALMETTO              \n",
       "2969  FLAXSEED (LINUM USIATISSIMUM SEED OIL)  LINUM USITATISSIMUM              \n",
       "518                                GINGERAID               GINGER              \n",
       "2674            UHE RED YEAST RICE CRANBERRY       RED YEAST RICE              \n",
       "755              QUEEN CITY HEMP 500MG (CBD)         HEMP EXTRACT              \n",
       "\n",
       "     rank2_drug rank3_drug rank4_drug rank5_drug  lookup_rank  \\\n",
       "1633                                                      inf   \n",
       "2969                                                      inf   \n",
       "518                                                       inf   \n",
       "2674                                                      inf   \n",
       "755                                                       inf   \n",
       "\n",
       "      lookup_rank_related  \n",
       "1633                  inf  \n",
       "2969                  inf  \n",
       "518                   inf  \n",
       "2674                  inf  \n",
       "755                   inf  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba7cdd8",
   "metadata": {},
   "source": [
    "# Evaluating on test data - NP names only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "78e3e2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.assign(rank1_drug=\"\", rank2_drug=\"\", rank3_drug=\"\", rank4_drug=\"\", rank5_drug=\"\", lookup_rank= np.Inf, lookup_rank_related = np.Inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1a88ac91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 958 entries, 0 to 957\n",
      "Data columns (total 4 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   latin_binomial        958 non-null    object\n",
      " 1   common_name           958 non-null    object\n",
      " 2   latin_binomial_clean  958 non-null    object\n",
      " 3   common_name_clean     958 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 30.1+ KB\n"
     ]
    }
   ],
   "source": [
    "vocab = pd.read_csv('../data/lb_to_common_names.csv')\n",
    "vocab.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd04131",
   "metadata": {},
   "source": [
    "# Evaluation of drug name predictions\n",
    "### Find ranks 1-n from the predicted similarities for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f1f57363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1633    [19, 1, 23, 27, 16, 5, 12, 13, 5, 20, 20, 15, ...\n",
       "2969    [6, 12, 1, 24, 19, 5, 5, 4, 27, 12, 9, 14, 21,...\n",
       "518     [7, 9, 14, 7, 5, 18, 1, 9, 4, 0, 0, 0, 0, 0, 0...\n",
       "2674    [21, 8, 5, 27, 18, 5, 4, 27, 25, 5, 1, 19, 20,...\n",
       "755     [17, 21, 5, 5, 14, 27, 3, 9, 20, 25, 27, 8, 5,...\n",
       "Name: FAERS_drug_match, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_xTest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bd185121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FAERS_drug_match</th>\n",
       "      <th>lookup_value</th>\n",
       "      <th>rank1_drug</th>\n",
       "      <th>rank2_drug</th>\n",
       "      <th>rank3_drug</th>\n",
       "      <th>rank4_drug</th>\n",
       "      <th>rank5_drug</th>\n",
       "      <th>lookup_rank</th>\n",
       "      <th>lookup_rank_related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>SAW PELMETTO</td>\n",
       "      <td>SCRUB-PALMETTO</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2969</th>\n",
       "      <td>FLAXSEED (LINUM USIATISSIMUM SEED OIL)</td>\n",
       "      <td>LINUM USITATISSIMUM</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>GINGERAID</td>\n",
       "      <td>GINGER</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674</th>\n",
       "      <td>UHE RED YEAST RICE CRANBERRY</td>\n",
       "      <td>RED YEAST RICE</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>QUEEN CITY HEMP 500MG (CBD)</td>\n",
       "      <td>HEMP EXTRACT</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            FAERS_drug_match         lookup_value rank1_drug  \\\n",
       "1633                            SAW PELMETTO       SCRUB-PALMETTO              \n",
       "2969  FLAXSEED (LINUM USIATISSIMUM SEED OIL)  LINUM USITATISSIMUM              \n",
       "518                                GINGERAID               GINGER              \n",
       "2674            UHE RED YEAST RICE CRANBERRY       RED YEAST RICE              \n",
       "755              QUEEN CITY HEMP 500MG (CBD)         HEMP EXTRACT              \n",
       "\n",
       "     rank2_drug rank3_drug rank4_drug rank5_drug  lookup_rank  \\\n",
       "1633                                                      inf   \n",
       "2969                                                      inf   \n",
       "518                                                       inf   \n",
       "2674                                                      inf   \n",
       "755                                                       inf   \n",
       "\n",
       "      lookup_rank_related  \n",
       "1633                  inf  \n",
       "2969                  inf  \n",
       "518                   inf  \n",
       "2674                  inf  \n",
       "755                   inf  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6219f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ranks(model: tf.keras.Model) -> pd.DataFrame:\n",
    "    \"\"\"For each row in the test set (input), use the model to predict if the 'FAERS_drug_match' entry matches any of the 'lookup_value' entries.\n",
    "       This is done at the encoded sequence level for both name all unique drugnames\n",
    "       \n",
    "         Parameters\n",
    "    ----------\n",
    "    model : tf.keras.Model\n",
    "        A Keras model based Siamese Network that takes three inputs. \n",
    "        Namely, two input sequeces and a third input binary target specifying wether the two sequeces match.\n",
    "    y : pd.Series\n",
    "        A pandas Series containing the clean encoded 'lookup_value' column.\n",
    "      \n",
    "    Returns\n",
    "    -------\n",
    "    x : pd.Series\n",
    "        Returns the padded 'FAERS_drug_match' series.\n",
    "    y : pd.Series \n",
    "        Returns the padded 'lookup_value' series.\n",
    "    \n",
    "    \"\"\"\n",
    "    for i in padded_xTest.index:\n",
    "        predicts = model.predict([np.tile(padded_xTest.loc[i], (dUnique_df['dUnique_seq_padded'].shape[0],1)), np.stack(dUnique_df['dUnique_seq_padded'])])\n",
    "        argsort = predicts.flatten().argsort()\n",
    "        # Top-5 smalles distances\n",
    "        test.loc[i, 'rank1_drug'] = dUnique_df['dUnique_label'][np.where(argsort == 0)[0][0]]\n",
    "        test.loc[i, 'rank2_drug'] = dUnique_df['dUnique_label'][np.where(argsort == 1)[0][0]]\n",
    "        test.loc[i, 'rank3_drug'] = dUnique_df['dUnique_label'][np.where(argsort == 2)[0][0]]\n",
    "        test.loc[i, 'rank4_drug'] = dUnique_df['dUnique_label'][np.where(argsort == 3)[0][0]]\n",
    "        test.loc[i, 'rank5_drug'] = dUnique_df['dUnique_label'][np.where(argsort == 4)[0][0]]\n",
    "        # Does any of them match\n",
    "        lookup_clean = test.loc[i]['lookup_value']\n",
    "        predicted_rank = test.loc[i][['rank1_drug', 'rank2_drug', 'rank3_drug', 'rank4_drug', 'rank5_drug']].eq(lookup_clean).to_numpy().nonzero()\n",
    "        \n",
    "        lookup_rank = np.Inf    \n",
    "        if len(predicted_rank[0]) > 0 :\n",
    "            lookup_rank = predicted_rank[0][0] + 1\n",
    "            test.loc[i, 'lookup_rank'] = lookup_rank\n",
    "        \n",
    "        # Let's compare to latin binomial\n",
    "        lb_res = vocab.loc[vocab['latin_binomial_clean'] == lookup_clean]\n",
    "        common_res = vocab.loc[vocab['common_name_clean'] == lookup_clean]\n",
    "        lookup_result = ''\n",
    "        if len(lb_res) > 0:\n",
    "            lookup_result = lb_res.common_name_clean.values[0]\n",
    "        elif len(common_res) > 0:\n",
    "            lookup_result = common_res.latin_binomial_clean.values[0]\n",
    "        \n",
    "        related_rank = np.Inf\n",
    "        if lookup_result != '':\n",
    "            annotated_rank = test.loc[i][['rank1_drug', 'rank2_drug', 'rank3_drug', 'rank4_drug', 'rank5_drug']].eq(lookup_result).to_numpy().nonzero()\n",
    "            if len(annotated_rank[0]) > 0: \n",
    "                related_rank = annotated_rank[0][0] + 1\n",
    "        \n",
    "\n",
    "        #find related mappings to lookup value in predicted values \n",
    "        test.loc[i, 'lookup_rank_related'] = min(lookup_rank, related_rank)\n",
    "    \n",
    "    test.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b25c100f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = padded_xTest.index[0]\n",
    "# predicts = model.predict([np.tile(padded_xTest.loc[i], (dUnique_df['dUnique_seq_padded'].shape[0],1)), np.stack(dUnique_df['dUnique_seq_padded'])])\n",
    "# argsort = predicts.flatten().argsort()\n",
    "# predicts.flatten()\n",
    "# argsort\n",
    "# dUnique_df[['dUnique_label','dUnique_seq_padded']]\n",
    "# dUnique_df.iloc[6][['dUnique_label','dUnique_seq_padded']]\n",
    "# dUnique_df['dUnique_label'][np.where(argsort == 3)[0][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37cc942",
   "metadata": {},
   "source": [
    "## Assing ranks to the matching \n",
    "matches are assigned their corresponding rank\n",
    "non-matches are left null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cfdbf207",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-29 22:31:15.094515: E tensorflow/stream_executor/cuda/cuda_dnn.cc:389] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2022-07-29 22:31:15.094547: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at cudnn_rnn_ops.cc:1553 : UNKNOWN: Fail to find the dnn implementation.\n",
      "2022-07-29 22:31:15.095277: E tensorflow/stream_executor/cuda/cuda_dnn.cc:389] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2022-07-29 22:31:15.095294: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at cudnn_rnn_ops.cc:1553 : UNKNOWN: Fail to find the dnn implementation.\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nDetected at node 'cond/CudnnRNNV3' defined at (most recent call last):\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n      app.start()\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/asyncio/base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/asyncio/base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_198503/3028911184.py\", line 2, in <cell line: 1>\n      predicts = model.predict([np.tile(padded_xTest.loc[i], (dUnique_df['dUnique_seq_padded'].shape[0],1)), np.stack(dUnique_df['dUnique_seq_padded'])])\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 2033, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 1845, in predict_function\n      return step_function(self, iterator)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 1834, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 1823, in run_step\n      outputs = model.predict_step(data)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 1791, in predict_step\n      return self(x, training=False)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/layers/rnn/base_rnn.py\", line 515, in __call__\n      return super(RNN, self).__call__(inputs, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/layers/rnn/lstm.py\", line 673, in call\n      runtime) = lstm_with_backend_selection(**normal_lstm_kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/layers/rnn/lstm.py\", line 1184, in lstm_with_backend_selection\n      gru_lstm_utils.function_register(defun_gpu_lstm, **params)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/layers/rnn/gru_lstm_utils.py\", line 244, in function_register\n      concrete_func = func.get_concrete_function(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/layers/rnn/lstm.py\", line 1149, in gpu_lstm_with_fallback\n      return tf.cond(\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/layers/rnn/lstm.py\", line 1121, in cudnn_lstm_fn\n      return gpu_lstm(\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/layers/rnn/lstm.py\", line 997, in gpu_lstm\n      outputs, h, c, _, _ = tf.raw_ops.CudnnRNNV3(\nNode: 'cond/CudnnRNNV3'\nFail to find the dnn implementation.\n\t [[{{node cond/CudnnRNNV3}}]]\n\t [[model_1/model/lstm/PartitionedCall_1]] [Op:__inference_predict_function_8748]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [55]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfind_ranks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [53]\u001b[0m, in \u001b[0;36mfind_ranks\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m\"\"\"For each row in the test set (input), use the model to predict if the 'FAERS_drug_match' entry matches any of the 'lookup_value' entries.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m   This is done at the encoded sequence level for both name all unique drugnames\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m   \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m padded_xTest\u001b[38;5;241m.\u001b[39mindex:\n\u001b[0;32m---> 22\u001b[0m     predicts \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpadded_xTest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdUnique_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdUnique_seq_padded\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdUnique_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdUnique_seq_padded\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     argsort \u001b[38;5;241m=\u001b[39m predicts\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39margsort()\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# Top-5 smalles distances\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nDetected at node 'cond/CudnnRNNV3' defined at (most recent call last):\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n      app.start()\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/asyncio/base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/asyncio/base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_198503/3028911184.py\", line 2, in <cell line: 1>\n      predicts = model.predict([np.tile(padded_xTest.loc[i], (dUnique_df['dUnique_seq_padded'].shape[0],1)), np.stack(dUnique_df['dUnique_seq_padded'])])\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 2033, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 1845, in predict_function\n      return step_function(self, iterator)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 1834, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 1823, in run_step\n      outputs = model.predict_step(data)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 1791, in predict_step\n      return self(x, training=False)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/layers/rnn/base_rnn.py\", line 515, in __call__\n      return super(RNN, self).__call__(inputs, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/layers/rnn/lstm.py\", line 673, in call\n      runtime) = lstm_with_backend_selection(**normal_lstm_kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/layers/rnn/lstm.py\", line 1184, in lstm_with_backend_selection\n      gru_lstm_utils.function_register(defun_gpu_lstm, **params)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/layers/rnn/gru_lstm_utils.py\", line 244, in function_register\n      concrete_func = func.get_concrete_function(*args, **kwargs)\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/layers/rnn/lstm.py\", line 1149, in gpu_lstm_with_fallback\n      return tf.cond(\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/layers/rnn/lstm.py\", line 1121, in cudnn_lstm_fn\n      return gpu_lstm(\n    File \"/home/israel/anaconda3/envs/tf/lib/python3.10/site-packages/keras/layers/rnn/lstm.py\", line 997, in gpu_lstm\n      outputs, h, c, _, _ = tf.raw_ops.CudnnRNNV3(\nNode: 'cond/CudnnRNNV3'\nFail to find the dnn implementation.\n\t [[{{node cond/CudnnRNNV3}}]]\n\t [[model_1/model/lstm/PartitionedCall_1]] [Op:__inference_predict_function_8748]"
     ]
    }
   ],
   "source": [
    "find_ranks(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b294d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3284f86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.to_csv(\"../evaluation/test_siamese_evaluation_lstm_model_np_name.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684b8088",
   "metadata": {},
   "source": [
    "# Add related mappings rank to test set evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6040061",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"test\" not in locals():\n",
    "    test = pd.read_csv('../evaluation/test_siamese_evaluation_lstm_model_np_name.csv')\n",
    "    test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23257b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mrr = test[['FAERS_drug_match', 'lookup_rank', 'lookup_rank_related']]\n",
    "test_mrr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e7a440",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mrr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72e80c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of 0 relevant results\n",
    "test_mrr.loc[test_mrr['lookup_rank'].isna()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5049dd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mrr.loc[test_mrr['lookup_rank_related'].isna()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3029e99f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_mrr_exact = test_mrr[test_mrr['lookup_rank'].notna()]\n",
    "test_mrr_exact = test_mrr_exact.drop(['lookup_rank_related'], axis=1)\n",
    "test_mrr_exact.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa7d846",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mrr_rel = test_mrr[test_mrr['lookup_rank_related'].notna()]\n",
    "test_mrr_rel = test_mrr_rel.drop(['lookup_rank'], axis=1)\n",
    "test_mrr_rel.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0c2544",
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_reciprocal = 1/test_mrr_exact['lookup_rank']\n",
    "test_mrr_exact['reciprocal_rank'] = exact_reciprocal\n",
    "test_mrr_exact.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4129cdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##get the mean of reciprocal ranks for exact matches\n",
    "test_mrr_exact.reciprocal_rank.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babb2c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get median and stdev\n",
    "test_mrr_exact.lookup_rank.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1cf7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mrr_exact.reciprocal_rank.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b669c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mrr_exact.lookup_rank.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4fb593",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mrr_exact.reciprocal_rank.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb45d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_reciprocal = 1/test_mrr_rel['lookup_rank_related']\n",
    "test_mrr_rel['reciprocal_rank'] = rel_reciprocal\n",
    "test_mrr_rel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152a261b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mrr_rel.reciprocal_rank.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86934c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mrr_rel.reciprocal_rank.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9dcb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mrr_rel.reciprocal_rank.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075fe985",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mrr_rel.lookup_rank_related.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f55998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mrr_rel.lookup_rank_related.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68af1b5a",
   "metadata": {},
   "source": [
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a0149b",
   "metadata": {},
   "source": [
    "# Average NP name length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1ca196",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dataset = preprocessInput(fName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4419b161",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = main_dataset['FAERS_drug_match'].apply(len).describe()\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0788f124",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats[\"mean\"] + stats[\"std\"] * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6904091",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dataset['lookup_value'].apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d0a838",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dataset['FAERS_drug_match'].apply(len).sort_values(ascending=False)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e59896",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dataset['FAERS_drug_match'].apply(len).gt(80).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c7ba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gt 65:\", 5358 - 4984)\n",
    "print(\"Gt 70:\", 5358 - 5212)\n",
    "print(\"Gt 80:\", 5358 - 5238)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230f7d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "main_dataset['FAERS_drug_match'].apply(len).hist(bins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a7a120",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dataset.iloc[5132]['FAERS_drug_match']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44814ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dataset.iloc[5132]['FAERS_drug_match']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c194eebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfneg2['FAERS_drug_match'].apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631c3e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfneg2['lookup_value'].apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd64bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dUnique_df['dUnique_label'].apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f82fdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "dUnique_df['dUnique_seq'].apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a034cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfneg2['FAERS_drug_match'].apply(len).idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d61d771",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfneg2.iloc[8183]['FAERS_drug_match']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da48bed4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
