{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9bf7ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, clear_output\n",
    "import re\n",
    "import skopt\n",
    "from skopt import BayesSearchCV\n",
    "from skopt import gp_minimize, forest_minimize\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.plots import plot_convergence\n",
    "from skopt.plots import plot_objective, plot_evaluations\n",
    "from skopt.plots import plot_histogram, plot_objective_2D\n",
    "from skopt.utils import use_named_args\n",
    "from tqdm import tqdm\n",
    "#!pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cc0f615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5358 entries, 0 to 5357\n",
      "Data columns (total 2 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   FAERS_drug_match  5358 non-null   object\n",
      " 1   lookup_value      5358 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 83.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#if starting from preprocess, load the drugs directly\n",
    "df = pd.read_csv('data/NP_FAERS_mapped_20220215.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94858ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make all casing upper\n",
    "df['FAERS_drug_match'] = df['FAERS_drug_match'].str.upper()\n",
    "df['lookup_value'] = df['lookup_value'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7acb74a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-01 21:15:22.111304: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import string\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32a68b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how i add noise \n",
    "# string w \n",
    "# proportion of noise added \n",
    "# uniform random from [0,1]\n",
    "# if <1/3 edit one position with new random character, else if <2/3 delete one position, else add one random character \n",
    "def add_noise(w, percent):\n",
    "  ''' edit, del, add'''\n",
    "  positions = random.choices(range(len(w)), k=int(percent*len(w)))\n",
    "  for p in positions:\n",
    "    r = random.random()\n",
    "    if r <= 0.3333: # edit\n",
    "      w = w[:p] + random.choice(string.ascii_uppercase) + w[p+1:]\n",
    "    elif r<= 0.6667: # delete\n",
    "      w = w[:p] + w[p+1:]\n",
    "    elif r<=1: # add\n",
    "      w = w[:p] + random.choice(string.ascii_uppercase) + w[p:]\n",
    "  return w\n",
    "\n",
    "def clean(text):\n",
    "    #remove all non-ascii, special characters and keep alphabets and space only. Can also use isalpha()\n",
    "    #convert to uppercase\n",
    "    #remove extra spaces\n",
    "    regex = re.compile('[^a-zA-Z ]')\n",
    "    r = regex.sub('', text)\n",
    "    result = re.sub(' +', ' ', r)\n",
    "    result = result.strip()\n",
    "    return result.upper()\n",
    "def clean_dataset(data):\n",
    "  x = []\n",
    "  y = []\n",
    "  for i in range(data.shape[0]):\n",
    "    w = clean(data.FAERS_drug_match.iloc[i])\n",
    "    v = clean(data.lookup_value.iloc[i])\n",
    "    x.append(w)\n",
    "    y.append(v)\n",
    "  return x,y\n",
    "\n",
    "def encode_dataset(x,y):\n",
    "  encode_dict = {l:i+1 for i,l in enumerate(string.ascii_uppercase + \" \")}\n",
    "  Xtrain = [[encode_dict[m] for m in n] for n in x]\n",
    "  Ytrain = [[encode_dict[m] for m in n] for n in y]\n",
    "  return Xtrain, Ytrain\n",
    "\n",
    "def clean_encode_padding(q, maxlen):\n",
    "  q = clean(q)\n",
    "  encode_dict = {l:i+1 for i,l in enumerate(string.ascii_uppercase + \" \")}\n",
    "  return tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    [encode_dict[m] for m in q] , padding=\"post\", maxlen=maxlen)\n",
    "\n",
    "def padding_dataset(X,Y,maxlen):\n",
    "  padded_y = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    Y, padding=\"post\", maxlen=maxlen)\n",
    "  padded_x = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      X, padding=\"post\", maxlen=maxlen)\n",
    "  return padded_x, padded_y\n",
    "\n",
    "def cosine_distance(vects):\n",
    "    x, y = vects\n",
    "    return 1-tf.reduce_sum(tf.multiply(x,y),axis=1, keepdims=True)/(tf.norm(x,axis=1,keepdims=True)*tf.norm(y,axis=1,keepdims=True))\n",
    "\n",
    "def loss(margin=1):\n",
    "    def contrastive_loss(y_true, y_pred):\n",
    "        square_pred = tf.math.square(y_pred)\n",
    "        margin_square = tf.math.square(tf.math.maximum(margin - (y_pred), 0))\n",
    "        return tf.math.reduce_mean(\n",
    "            (1 - y_true) * square_pred + (y_true) * margin_square\n",
    "        )\n",
    "\n",
    "    return contrastive_loss\n",
    "\n",
    "def plt_metric(history, metric, title, has_valid=True):\n",
    "    \"\"\"Plots the given 'metric' from 'history'.\n",
    "\n",
    "    Arguments:\n",
    "        history: history attribute of History object returned from Model.fit.\n",
    "        metric: Metric to plot, a string value present as key in 'history'.\n",
    "        title: A string to be used as title of plot.\n",
    "        has_valid: Boolean, true if valid data was passed to Model.fit else false.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    plt.plot(history[metric])\n",
    "    if has_valid:\n",
    "        plt.plot(history[\"val_\" + metric])\n",
    "        plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "    plt.title(title)\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5dcb0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ddeb146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4286, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d720a75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1072, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31ef8e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#padding length = maxlen\n",
    "maxlen = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "547a283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest, ytest = clean_dataset(test)\n",
    "Xtest, Ytest = encode_dataset(xtest,ytest)\n",
    "padded_xTest, padded_yTest = padding_dataset(Xtest,Ytest,maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d3b2586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1072, 400)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_xTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17f469fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#without noise \n",
    "x, y = clean_dataset(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72b1b518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4286"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94ee3ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_dict = {l:i+1 for i,l in enumerate(string.ascii_uppercase + \" \")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ec49f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = [[encode_dict[m] for m in n] for n in x]\n",
    "Ytrain = [[encode_dict[m] for m in n] for n in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ef740e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4286\n",
      "4286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tab219/.conda/envs/py39/lib/python3.9/site-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(125,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(Xtrain))\n",
    "print(len(Ytrain))\n",
    "np.unique(Ytrain).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7659c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19  5 18 ...  0  0  0]\n",
      " [15 16  8 ...  0  0  0]\n",
      " [ 3  9 14 ...  0  0  0]\n",
      " ...\n",
      " [ 1 12 12 ...  0  0  0]\n",
      " [ 1 12 12 ...  0  0  0]\n",
      " [ 8  5 13 ...  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "padded_y = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    Ytrain, padding=\"post\", maxlen=maxlen\n",
    ")\n",
    "padded_x = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    Xtrain, padding=\"post\", maxlen=maxlen\n",
    ")\n",
    "\n",
    "print(padded_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1dbfd826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encode_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c1a4a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dUnique_label</th>\n",
       "      <th>dUnique_seq</th>\n",
       "      <th>dUnique_seq_padded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACTAEA RACEMOSA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AESCULUS HIPPOCASTANUM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALLIUM SATIVUM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALOE VERA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANGELICA SINENSIS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            dUnique_label dUnique_seq dUnique_seq_padded\n",
       "0         ACTAEA RACEMOSA         NaN                NaN\n",
       "1  AESCULUS HIPPOCASTANUM         NaN                NaN\n",
       "2          ALLIUM SATIVUM         NaN                NaN\n",
       "3               ALOE VERA         NaN                NaN\n",
       "4       ANGELICA SINENSIS         NaN                NaN"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dUnique_df = pd.DataFrame(columns = ['dUnique_label','dUnique_seq', 'dUnique_seq_padded'])\n",
    "dUnique_df['dUnique_label'] = np.unique(y)\n",
    "dUnique_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6de2b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dUnique_seq_list = [[encode_dict[m] for m in n] for n in dUnique_df['dUnique_label'].tolist()]\n",
    "len(dUnique_seq_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3b8eede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dUnique_label</th>\n",
       "      <th>dUnique_seq</th>\n",
       "      <th>dUnique_seq_padded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACTAEA RACEMOSA</td>\n",
       "      <td>[1, 3, 20, 1, 5, 1, 27, 18, 1, 3, 5, 13, 15, 1...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AESCULUS HIPPOCASTANUM</td>\n",
       "      <td>[1, 5, 19, 3, 21, 12, 21, 19, 27, 8, 9, 16, 16...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALLIUM SATIVUM</td>\n",
       "      <td>[1, 12, 12, 9, 21, 13, 27, 19, 1, 20, 9, 22, 2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALOE VERA</td>\n",
       "      <td>[1, 12, 15, 5, 27, 22, 5, 18, 1]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANGELICA SINENSIS</td>\n",
       "      <td>[1, 14, 7, 5, 12, 9, 3, 1, 27, 19, 9, 14, 5, 1...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            dUnique_label                                        dUnique_seq  \\\n",
       "0         ACTAEA RACEMOSA  [1, 3, 20, 1, 5, 1, 27, 18, 1, 3, 5, 13, 15, 1...   \n",
       "1  AESCULUS HIPPOCASTANUM  [1, 5, 19, 3, 21, 12, 21, 19, 27, 8, 9, 16, 16...   \n",
       "2          ALLIUM SATIVUM  [1, 12, 12, 9, 21, 13, 27, 19, 1, 20, 9, 22, 2...   \n",
       "3               ALOE VERA                   [1, 12, 15, 5, 27, 22, 5, 18, 1]   \n",
       "4       ANGELICA SINENSIS  [1, 14, 7, 5, 12, 9, 3, 1, 27, 19, 9, 14, 5, 1...   \n",
       "\n",
       "  dUnique_seq_padded  \n",
       "0                NaN  \n",
       "1                NaN  \n",
       "2                NaN  \n",
       "3                NaN  \n",
       "4                NaN  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(dUnique_df.index)):\n",
    "    dUnique_df.at[i, 'dUnique_seq'] = np.array(dUnique_seq_list[i])\n",
    "dUnique_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa10decf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9242 entries, 0 to 9241\n",
      "Data columns (total 2 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   FAERS_drug_match  9242 non-null   object\n",
      " 1   lookup_value      9242 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 144.5+ KB\n"
     ]
    }
   ],
   "source": [
    "#setup negative pairs\n",
    "dfneg = pd.read_csv('data/NP_FAERS_negative_pairs_20220222.csv')\n",
    "dfneg.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e078706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode negative pairs and add padding\n",
    "xneg, yneg = clean_dataset(dfneg)\n",
    "Xneg, Yneg = encode_dataset(xneg,yneg)\n",
    "padded_xneg, padded_yneg = padding_dataset(Xneg,Yneg,maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef18203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dUnique = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    list(dUnique_df['dUnique_seq']), padding=\"post\", maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c531f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_unique = dUnique_df.dUnique_label.tolist()\n",
    "len(np_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf602f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4286 4286 4286\n"
     ]
    }
   ],
   "source": [
    "#add positive pairs\n",
    "x1TrainRNN = []\n",
    "x2TrainRNN = []\n",
    "yTrainRNN = []\n",
    "for i in range(len(padded_x)):\n",
    "    yTrainRNN.append(1)\n",
    "    x1TrainRNN.append(padded_x[i])\n",
    "    x2TrainRNN.append(padded_y[i])\n",
    "print(len(x1TrainRNN), len(x2TrainRNN), len(yTrainRNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e10f643a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>FAERS_drug_match</th>\n",
       "      <th>lookup_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3956</td>\n",
       "      <td>SERENOA REPENS/SERENOA REPENS EXTRACT/SERENOA ...</td>\n",
       "      <td>SERENOA REPENS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4408</td>\n",
       "      <td>CORDYCEPS</td>\n",
       "      <td>OPHIOCORDYCEPS SINENSIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120</td>\n",
       "      <td>CINNAMON (CINNAMOUM VERUM) (CAPSULES)</td>\n",
       "      <td>CINNAMON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3311</td>\n",
       "      <td>CHROMIUM PICOLINATE WITH GREEN TEA</td>\n",
       "      <td>CAMELLIA SINENSIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1921</td>\n",
       "      <td>BARLEY.</td>\n",
       "      <td>BARLEY GRASS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                   FAERS_drug_match  \\\n",
       "0   3956  SERENOA REPENS/SERENOA REPENS EXTRACT/SERENOA ...   \n",
       "1   4408                                          CORDYCEPS   \n",
       "2    120              CINNAMON (CINNAMOUM VERUM) (CAPSULES)   \n",
       "3   3311                 CHROMIUM PICOLINATE WITH GREEN TEA   \n",
       "4   1921                                            BARLEY.   \n",
       "\n",
       "              lookup_value  \n",
       "0           SERENOA REPENS  \n",
       "1  OPHIOCORDYCEPS SINENSIS  \n",
       "2                 CINNAMON  \n",
       "3        CAMELLIA SINENSIS  \n",
       "4             BARLEY GRASS  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_res = train.reset_index()\n",
    "train_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a532277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16916"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take negative pairs from training data\n",
    "faers_match = []\n",
    "lookup = []\n",
    "for i in range(len(train_res)):\n",
    "    np_name = train_res.at[i, 'FAERS_drug_match']\n",
    "    for j in random.choices(range(len(np_unique)), k=4):\n",
    "        np_temp = np_unique[j]\n",
    "        np_match = train_res.loc[train_res['FAERS_drug_match'] == np_name].lookup_value.tolist()\n",
    "        if np_temp not in np_match:\n",
    "            faers_match.append(np_name)\n",
    "            lookup.append(np_temp)\n",
    "len(faers_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e93d2461",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfneg2 = pd.DataFrame(columns=['FAERS_drug_match', 'lookup_value'])\n",
    "dfneg2['FAERS_drug_match'] = faers_match\n",
    "dfneg2['lookup_value'] = lookup\n",
    "xneg2, yneg2 = clean_dataset(dfneg2)\n",
    "Xneg2, Yneg2 = encode_dataset(xneg2,yneg2)\n",
    "padded_xneg2, padded_yneg2 = padding_dataset(Xneg2,Yneg2,maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "859b01bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21202 21202 21202\n"
     ]
    }
   ],
   "source": [
    "##add negative pairs from training data\n",
    "for j in range(len(padded_xneg2)):\n",
    "    yTrainRNN.append(0)\n",
    "    x1TrainRNN.append(padded_xneg2[j])\n",
    "    x2TrainRNN.append(padded_yneg2[j])\n",
    "print(len(x1TrainRNN), len(x2TrainRNN), len(yTrainRNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a581f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30444 30444 30444\n"
     ]
    }
   ],
   "source": [
    "##add negative pairs from reference set\n",
    "for j in range(len(padded_xneg)):\n",
    "    yTrainRNN.append(0)\n",
    "    x1TrainRNN.append(padded_xneg[j])\n",
    "    x2TrainRNN.append(padded_yneg[j])\n",
    "print(len(x1TrainRNN), len(x2TrainRNN), len(yTrainRNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c8bd255a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dUnique_label</th>\n",
       "      <th>dUnique_seq</th>\n",
       "      <th>dUnique_seq_padded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACTAEA RACEMOSA</td>\n",
       "      <td>[1, 3, 20, 1, 5, 1, 27, 18, 1, 3, 5, 13, 15, 1...</td>\n",
       "      <td>[1, 3, 20, 1, 5, 1, 27, 18, 1, 3, 5, 13, 15, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AESCULUS HIPPOCASTANUM</td>\n",
       "      <td>[1, 5, 19, 3, 21, 12, 21, 19, 27, 8, 9, 16, 16...</td>\n",
       "      <td>[1, 5, 19, 3, 21, 12, 21, 19, 27, 8, 9, 16, 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALLIUM SATIVUM</td>\n",
       "      <td>[1, 12, 12, 9, 21, 13, 27, 19, 1, 20, 9, 22, 2...</td>\n",
       "      <td>[1, 12, 12, 9, 21, 13, 27, 19, 1, 20, 9, 22, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALOE VERA</td>\n",
       "      <td>[1, 12, 15, 5, 27, 22, 5, 18, 1]</td>\n",
       "      <td>[1, 12, 15, 5, 27, 22, 5, 18, 1, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANGELICA SINENSIS</td>\n",
       "      <td>[1, 14, 7, 5, 12, 9, 3, 1, 27, 19, 9, 14, 5, 1...</td>\n",
       "      <td>[1, 14, 7, 5, 12, 9, 3, 1, 27, 19, 9, 14, 5, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            dUnique_label                                        dUnique_seq  \\\n",
       "0         ACTAEA RACEMOSA  [1, 3, 20, 1, 5, 1, 27, 18, 1, 3, 5, 13, 15, 1...   \n",
       "1  AESCULUS HIPPOCASTANUM  [1, 5, 19, 3, 21, 12, 21, 19, 27, 8, 9, 16, 16...   \n",
       "2          ALLIUM SATIVUM  [1, 12, 12, 9, 21, 13, 27, 19, 1, 20, 9, 22, 2...   \n",
       "3               ALOE VERA                   [1, 12, 15, 5, 27, 22, 5, 18, 1]   \n",
       "4       ANGELICA SINENSIS  [1, 14, 7, 5, 12, 9, 3, 1, 27, 19, 9, 14, 5, 1...   \n",
       "\n",
       "                                  dUnique_seq_padded  \n",
       "0  [1, 3, 20, 1, 5, 1, 27, 18, 1, 3, 5, 13, 15, 1...  \n",
       "1  [1, 5, 19, 3, 21, 12, 21, 19, 27, 8, 9, 16, 16...  \n",
       "2  [1, 12, 12, 9, 21, 13, 27, 19, 1, 20, 9, 22, 2...  \n",
       "3  [1, 12, 15, 5, 27, 22, 5, 18, 1, 0, 0, 0, 0, 0...  \n",
       "4  [1, 14, 7, 5, 12, 9, 3, 1, 27, 19, 9, 14, 5, 1...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(dUnique_df.index)):\n",
    "    dUnique_df.at[i, 'dUnique_seq_padded'] = dUnique[i]\n",
    "dUnique_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe76098f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1TrainRnnS, x1ValRnnS, x2TrainRnnS, x2ValRnnS, yTrainRnnS, yValRnnS = train_test_split(x1TrainRNN, x2TrainRNN, yTrainRNN, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93a0074",
   "metadata": {},
   "source": [
    "## build model and hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a1de919b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-01 21:15:56.772717: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-01 21:15:56.774302: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-03-01 21:15:56.860193: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:af:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2022-03-01 21:15:56.860256: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-03-01 21:15:56.863138: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-03-01 21:15:56.863241: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-03-01 21:15:56.866004: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-03-01 21:15:56.866468: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-03-01 21:15:56.869523: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-03-01 21:15:56.871260: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-03-01 21:15:56.877947: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-03-01 21:15:56.878608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16e583fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model_type, embedding_dim, num_rnn_node, num_dense_node, num_layer, activation_fn, learning_rate, optimizer, margin):\n",
    "    input_x = tf.keras.layers.Input(maxlen)\n",
    "    input_1 = tf.keras.layers.Input(maxlen)\n",
    "    input_2 = tf.keras.layers.Input(maxlen)\n",
    "    embedding = tf.keras.layers.Embedding(input_dim=28, output_dim=embedding_dim, mask_zero=True)\n",
    "    x = embedding(input_x)\n",
    "    \n",
    "    if model_type == \"lstm\":\n",
    "        x = tf.keras.layers.LSTM(num_rnn_node)(x)\n",
    "    elif model_type==\"gru\":\n",
    "        x = tf.keras.layers.GRU(num_rnn_node)(x)\n",
    " \n",
    "    num = num_dense_node\n",
    "    for _ in range(num_layer):\n",
    "        x = tf.keras.layers.Dense(num, activation=activation_fn)(x)\n",
    "        num /= 2\n",
    "        \n",
    "    embedding_network = tf.keras.Model(input_x, x)\n",
    "\n",
    "    tower_1 = embedding_network(input_1)\n",
    "    tower_2 = embedding_network(input_2)\n",
    "\n",
    "    merge_layer = tf.keras.layers.Lambda(cosine_distance)([tower_1, tower_2])\n",
    "    output_layer = tf.keras.layers.Dense(1, activation=\"sigmoid\")(merge_layer)\n",
    "    contr = tf.keras.Model(inputs=[input_1, input_2], outputs=output_layer)\n",
    "    \n",
    "    if optimizer == \"Adam\":\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer ==\"RMSprop\":                \n",
    "        opt = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    contr.compile(loss=loss(margin= margin), optimizer=opt, metrics=[\"accuracy\"])\n",
    "    return contr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c0d3c08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_model = Categorical(categories=[\"lstm\", \"gru\"], name=\"model_type\")\n",
    "dim_embedding = Integer(low=64, high=512, prior=\"log-uniform\", base=2, name=\"embedding_dim\")\n",
    "dim_rnn_node = Integer(low=128, high=1024, prior=\"log-uniform\", base=2, name=\"num_rnn_node\")\n",
    "dim_num_dense_nodes = Integer(low=64, high=512, prior=\"log-uniform\", base=2, name=\"num_dense_node\")\n",
    "dim_num_layer = Integer(low=1, high=5, prior=\"uniform\", name=\"num_layer\")\n",
    "dim_activation = Categorical(categories=['tanh', 'relu'], name=\"activation_fn\")\n",
    "dim_lr = Real(low=1e-5, high=1e-1, prior=\"log-uniform\", base=10, name=\"learning_rate\")\n",
    "dim_opt = Categorical(categories=['Adam', 'RMSprop'], name=\"optimizer\")\n",
    "dim_margin = Real(low=1e-1, high=1, prior=\"uniform\", name=\"margin\")\n",
    "dim_batch_size = Integer(low=4, high=64, prior=\"log-uniform\", base=2, name=\"batch_size\")\n",
    "dims = [dim_model, dim_embedding, dim_rnn_node, dim_num_dense_nodes, dim_num_layer, dim_activation, dim_lr, dim_opt, dim_margin, dim_batch_size]\n",
    "default_params = [\"gru\", 64, 128, 64, 2, \"tanh\", 1e-3, \"RMSprop\", 1, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c937781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_dir_name(a):\n",
    "    o = \"\"\n",
    "    for n in a:\n",
    "        o+= str(n)+\"_\"\n",
    "    return o+\".log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "63ccff91",
   "metadata": {},
   "outputs": [],
   "source": [
    "@use_named_args(dimensions=dims)\n",
    "def fitness(model_type, embedding_dim, num_rnn_node, num_dense_node, num_layer, activation_fn, learning_rate, optimizer, margin, batch_size):\n",
    "    \n",
    "    print(\"model:\", model_type)\n",
    "    print(\"embedding_dim:\", embedding_dim)\n",
    "    print(\"num_rnn_node:\", num_rnn_node)\n",
    "    print(\"num_dense_node:\", num_dense_node)\n",
    "    print(\"num_layer:\", num_layer)\n",
    "    print(\"activation_fn:\", activation_fn)\n",
    "    print(\"learning rate: {:.1e}\".format(learning_rate))\n",
    "    print(\"optimizer:\", optimizer)\n",
    "    print(\"margin:\", margin)\n",
    "    print(\"batch_size:\", batch_size)\n",
    "\n",
    "    model = build_model(model_type, embedding_dim, num_rnn_node, num_dense_node, num_layer, activation_fn, learning_rate, optimizer, margin)\n",
    "    params = [model_type, embedding_dim, num_rnn_node, num_dense_node, num_layer, activation_fn, learning_rate, optimizer, margin, batch_size]\n",
    "   \n",
    "    history = model.fit(x=[np.array(x1TrainRnnS), np.array(x2TrainRnnS)],\n",
    "                        y=np.array(yTrainRnnS, dtype=np.float32),\n",
    "#                         epochs=35,\n",
    "                        epochs=200,\n",
    "                        batch_size=batch_size,\n",
    "                        validation_data=([np.array(x1ValRnnS), np.array(x2ValRnnS)], np.array(yValRnnS, dtype=np.float32)),\n",
    "                        )\n",
    "    \n",
    "    loss = history.history['val_loss'][-1]\n",
    "    print(\"Val loss: {0:.6%}\".format(loss))\n",
    "    model_name = \"_\".join([str(a) for a in params]) + f\"{str(loss).replace('.', '_')}.h5\"\n",
    "    model.save(f\"exp3_model/{model_name}\")\n",
    "    del model    \n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "23a01312",
   "metadata": {},
   "outputs": [],
   "source": [
    "@use_named_args(dimensions=dims)\n",
    "def fitness2(model_type, embedding_dim, num_rnn_node, num_dense_node, num_layer, activation_fn, learning_rate, optimizer, margin, batch_size):\n",
    "    \n",
    "    print(\"model:\", model_type)\n",
    "    print(\"embedding_dim:\", embedding_dim)\n",
    "    print(\"num_rnn_node:\", num_rnn_node)\n",
    "    print(\"num_dense_node:\", num_dense_node)\n",
    "    print(\"num_layer:\", num_layer)\n",
    "    print(\"activation_fn:\", activation_fn)\n",
    "    print(\"learning rate: {:.1e}\".format(learning_rate))\n",
    "    print(\"optimizer:\", optimizer)\n",
    "    print(\"margin:\", margin)\n",
    "    print(\"batch_size:\", batch_size)\n",
    "\n",
    "    model = build_model(model_type, embedding_dim, num_rnn_node, num_dense_node, num_layer, activation_fn, learning_rate, optimizer, margin)\n",
    "    params = [model_type, embedding_dim, num_rnn_node, num_dense_node, num_layer, activation_fn, learning_rate, optimizer, margin, batch_size]\n",
    "   \n",
    "    history = model.fit(x=[np.array(x1TrainRnnS), np.array(x2TrainRnnS)],\n",
    "                        y=np.array(yTrainRnnS, dtype=np.float32),\n",
    "#                         epochs=35,\n",
    "                        epochs=50,\n",
    "                        batch_size=batch_size,\n",
    "                        validation_data=([np.array(x1ValRnnS), np.array(x2ValRnnS)], np.array(yValRnnS, dtype=np.float32)),\n",
    "                        callbacks=[save_model])\n",
    "    \n",
    "    loss = history.history['val_loss'][-1]\n",
    "    print(\"Val loss: {0:.6%}\".format(loss))\n",
    "    model_name = \"_\".join([str(a) for a in params]) + f\"{str(loss).replace('.', '_')}.h5\"\n",
    "    model.save(f\"exp3_model/{model_name}\")\n",
    "    del model    \n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "990a418b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = tf.keras.callbacks.ModelCheckpoint(\n",
    "      filepath= \"exp3_model/alstm\" + \"-{epoch:02d}-{val_loss:.2f}.hdf5\",\n",
    "      save_weights_only=True,\n",
    "      monitor='val_loss',\n",
    "      verbose=1,\n",
    "      save_best_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ad79f26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: gru\n",
      "embedding_dim: 64\n",
      "num_rnn_node: 128\n",
      "num_dense_node: 64\n",
      "num_layer: 2\n",
      "activation_fn: tanh\n",
      "learning rate: 1.0e-03\n",
      "optimizer: RMSprop\n",
      "margin: 1\n",
      "batch_size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-01 21:18:44.689736: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-01 21:18:44.691683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:af:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2022-03-01 21:18:44.691776: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-03-01 21:18:44.691811: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-03-01 21:18:44.691834: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-03-01 21:18:44.691856: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-03-01 21:18:44.691877: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-03-01 21:18:44.691899: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-03-01 21:18:44.691920: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-03-01 21:18:44.691943: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-03-01 21:18:44.692461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-03-01 21:18:44.692515: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-03-01 21:18:45.634664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-03-01 21:18:45.634707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-03-01 21:18:45.634717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-03-01 21:18:45.635725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10075 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:af:00.0, compute capability: 7.5)\n",
      "2022-03-01 21:18:45.636234: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-03-01 21:18:48.908629: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-03-01 21:18:48.927342: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 1700000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-01 21:18:56.833596: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-03-01 21:18:57.615030: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/762 [============================>.] - ETA: 0s - loss: 0.1394 - accuracy: 0.8616"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12093/570638347.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfitness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/skopt/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0;31m# Call the wrapped objective function with the named arguments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mobjective_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0marg_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobjective_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_12093/2947689868.py\u001b[0m in \u001b[0;36mfitness\u001b[0;34m(model_type, embedding_dim, num_rnn_node, num_dense_node, num_layer, activation_fn, learning_rate, optimizer, margin, batch_size)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rnn_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_dense_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     history = model.fit(x=[np.array(x1TrainRnnS), np.array(x2TrainRnnS)],\n\u001b[0m\u001b[1;32m     19\u001b[0m                         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myTrainRnnS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1129\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[0;32m-> 1131\u001b[0;31m           val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1132\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m               \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 725\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    726\u001b[0m             *args, **kwds))\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    964\u001b[0m           \u001b[0;31m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m             return autograph.converted_call(\n\u001b[0m\u001b[1;32m    967\u001b[0m                 \u001b[0moriginal_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__test_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    477\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1225\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m   1226\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1257\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1258\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1259\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2728\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2729\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2730\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2732\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3415\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3416\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3417\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3419\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `test_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtest_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1181\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_x_y_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m     \u001b[0;31m# Updates stateful loss metrics.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m     self.compiled_loss(\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \"\"\"\n\u001b[0;32m--> 424\u001b[0;31m     return self._run_internal_graph(\n\u001b[0m\u001b[1;32m    425\u001b[0m         inputs, training=training, mask=mask)\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \"\"\"\n\u001b[0;32m--> 424\u001b[0;31m     return self._run_internal_graph(\n\u001b[0m\u001b[1;32m    425\u001b[0m         inputs, training=training, mask=mask)\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m    468\u001b[0m       \u001b[0mruntime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_runtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_RUNTIME_UNKNOWN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m       last_output, outputs, runtime, states = self._defun_gru_call(\n\u001b[0m\u001b[1;32m    471\u001b[0m           inputs, initial_state, training, mask, row_lengths)\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36m_defun_gru_call\u001b[0;34m(self, inputs, initial_state, training, mask, sequence_lengths)\u001b[0m\n\u001b[1;32m    544\u001b[0m               **normal_gru_kwargs)\n\u001b[1;32m    545\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m         last_output, outputs, new_h, runtime = gru_with_backend_selection(\n\u001b[0m\u001b[1;32m    547\u001b[0m             **normal_gru_kwargs)\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mgru_with_backend_selection\u001b[0;34m(inputs, init_h, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask)\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0;31m# grappler will kick in during session execution to optimize the graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m     \u001b[0mlast_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefun_standard_gru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m     \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefun_gpu_gru\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mlast_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mregister\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3388\u001b[0m   \u001b[0mconcrete_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3389\u001b[0m   \u001b[0mconcrete_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3390\u001b[0;31m   \u001b[0mconcrete_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_gradient_functions_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3391\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mconcrete_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36madd_gradient_functions_to_graph\u001b[0;34m(self, g)\u001b[0m\n\u001b[1;32m   2055\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2056\u001b[0m     forward_function, backward_function = (\n\u001b[0;32m-> 2057\u001b[0;31m         self._delayed_rewrite_functions.forward_backward())\n\u001b[0m\u001b[1;32m   2058\u001b[0m     \u001b[0mforward_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2059\u001b[0m     \u001b[0mbackward_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mforward_backward\u001b[0;34m(self, num_doutputs)\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mforward_backward\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mforward_backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m     \u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_forward_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_doutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_function_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_doutputs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_construct_forward_backward\u001b[0;34m(self, num_doutputs)\u001b[0m\n\u001b[1;32m    672\u001b[0m       backwards_graph = func_graph_module.FuncGraph(\n\u001b[1;32m    673\u001b[0m           _backward_name(self._func_graph.name))\n\u001b[0;32m--> 674\u001b[0;31m       func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    675\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackwards_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m           \u001b[0mpython_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_backprop_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_backprop_function\u001b[0;34m(*grad_ys)\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_backprop_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrad_ys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m         return gradients_util._GradientsHelper(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    666\u001b[0m             \u001b[0mtrainable_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;31m# If grad_fn was found, do not use SymbolicGradient even for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0m\u001b[1;32m    684\u001b[0m                                          lambda: grad_fn(op, *out_grads))\n\u001b[1;32m    685\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Exit early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m   \u001b[0;31m# If the gradients are supposed to be compiled separately, we give them a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    682\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 684\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    685\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/ops/cond_v2.py\u001b[0m in \u001b[0;36m_IfGrad\u001b[0;34m(op, *grads)\u001b[0m\n\u001b[1;32m    124\u001b[0m   true_grad_graph = _create_grad_func(\n\u001b[1;32m    125\u001b[0m       true_graph, grads, util.unique_grad_fn_name(true_graph.name))\n\u001b[0;32m--> 126\u001b[0;31m   false_grad_graph = _create_grad_func(\n\u001b[0m\u001b[1;32m    127\u001b[0m       false_graph, grads, util.unique_grad_fn_name(false_graph.name))\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/ops/cond_v2.py\u001b[0m in \u001b[0;36m_create_grad_func\u001b[0;34m(func_graph, grads, name)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_create_grad_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m   \u001b[0;34m\"\"\"Returns the FuncGraph representation of _grad_fn.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m   return func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    419\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m       \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_grad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/ops/cond_v2.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    418\u001b[0m   return func_graph_module.func_graph_from_py_func(\n\u001b[1;32m    419\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m       \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_grad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m       func_graph=_CondGradFuncGraph(name, func_graph))\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/ops/cond_v2.py\u001b[0m in \u001b[0;36m_grad_fn\u001b[0;34m(func_graph, grads)\u001b[0m\n\u001b[1;32m    407\u001b[0m   \u001b[0;31m# func_graph. The captured func_graph tensors are resolved to external tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m   \u001b[0;31m# in _resolve_grad_inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m   result = gradients_util._GradientsHelper(\n\u001b[0m\u001b[1;32m    410\u001b[0m       \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_ys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_ys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m       src_graph=func_graph)\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Note: we don't filter out eager inputs here because the inputs need to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0;31m# line up with in_grads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_grad\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_Inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0min_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m             if (isinstance(in_grad, ops.Tensor) and\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_Inputs\u001b[0;34m(op, xs_set)\u001b[0m\n\u001b[1;32m    452\u001b[0m       \u001b[0;31m# direct input to op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxs_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_MaybeCaptured\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m       \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fitness(x=default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1913c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://colab.research.google.com/github/Hvass-Labs/TensorFlow-Tutorials/blob/master/19_Hyper-Parameters.ipynb#scrollTo=FuSgyvM5UMhy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f4a56f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: gru\n",
      "embedding_dim: 64\n",
      "num_rnn_node: 128\n",
      "num_dense_node: 64\n",
      "num_layer: 2\n",
      "activation_fn: tanh\n",
      "learning rate: 1.0e-03\n",
      "optimizer: RMSprop\n",
      "margin: 1\n",
      "batch_size: 32\n",
      "Epoch 1/35\n",
      "762/762 [==============================] - 26s 21ms/step - loss: 0.1135 - accuracy: 0.8569 - val_loss: 0.0903 - val_accuracy: 0.8625\n",
      "Epoch 2/35\n",
      "762/762 [==============================] - 13s 17ms/step - loss: 0.0903 - accuracy: 0.8599 - val_loss: 0.0828 - val_accuracy: 0.8696\n",
      "Epoch 3/35\n",
      "762/762 [==============================] - 13s 18ms/step - loss: 0.0801 - accuracy: 0.8895 - val_loss: 0.0712 - val_accuracy: 0.9207\n",
      "Epoch 4/35\n",
      "762/762 [==============================] - 13s 18ms/step - loss: 0.0703 - accuracy: 0.9223 - val_loss: 0.0623 - val_accuracy: 0.9369\n",
      "Epoch 5/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0587 - accuracy: 0.9395 - val_loss: 0.0562 - val_accuracy: 0.9404\n",
      "Epoch 6/35\n",
      "762/762 [==============================] - 13s 18ms/step - loss: 0.0518 - accuracy: 0.9469 - val_loss: 0.0480 - val_accuracy: 0.9476\n",
      "Epoch 7/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0435 - accuracy: 0.9538 - val_loss: 0.0427 - val_accuracy: 0.9547\n",
      "Epoch 8/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0394 - accuracy: 0.9588 - val_loss: 0.0388 - val_accuracy: 0.9576\n",
      "Epoch 9/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0321 - accuracy: 0.9658 - val_loss: 0.0359 - val_accuracy: 0.9609\n",
      "Epoch 10/35\n",
      "762/762 [==============================] - 13s 18ms/step - loss: 0.0280 - accuracy: 0.9700 - val_loss: 0.0294 - val_accuracy: 0.9676\n",
      "Epoch 11/35\n",
      "762/762 [==============================] - 13s 17ms/step - loss: 0.0239 - accuracy: 0.9760 - val_loss: 0.0272 - val_accuracy: 0.9708\n",
      "Epoch 12/35\n",
      "762/762 [==============================] - 13s 18ms/step - loss: 0.0196 - accuracy: 0.9805 - val_loss: 0.0252 - val_accuracy: 0.9726\n",
      "Epoch 13/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0186 - accuracy: 0.9826 - val_loss: 0.0227 - val_accuracy: 0.9759\n",
      "Epoch 14/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0153 - accuracy: 0.9856 - val_loss: 0.0217 - val_accuracy: 0.9764\n",
      "Epoch 15/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0130 - accuracy: 0.9881 - val_loss: 0.0201 - val_accuracy: 0.9775\n",
      "Epoch 16/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0116 - accuracy: 0.9890 - val_loss: 0.0217 - val_accuracy: 0.9767\n",
      "Epoch 17/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0113 - accuracy: 0.9891 - val_loss: 0.0185 - val_accuracy: 0.9782\n",
      "Epoch 18/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0110 - accuracy: 0.9890 - val_loss: 0.0181 - val_accuracy: 0.9808\n",
      "Epoch 19/35\n",
      "762/762 [==============================] - 13s 18ms/step - loss: 0.0098 - accuracy: 0.9898 - val_loss: 0.0184 - val_accuracy: 0.9793\n",
      "Epoch 20/35\n",
      "762/762 [==============================] - 13s 17ms/step - loss: 0.0090 - accuracy: 0.9910 - val_loss: 0.0189 - val_accuracy: 0.9788\n",
      "Epoch 21/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0088 - accuracy: 0.9909 - val_loss: 0.0171 - val_accuracy: 0.9805\n",
      "Epoch 22/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0084 - accuracy: 0.9907 - val_loss: 0.0174 - val_accuracy: 0.9800\n",
      "Epoch 23/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0081 - accuracy: 0.9916 - val_loss: 0.0166 - val_accuracy: 0.9816\n",
      "Epoch 24/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0083 - accuracy: 0.9911 - val_loss: 0.0166 - val_accuracy: 0.9809\n",
      "Epoch 25/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0073 - accuracy: 0.9923 - val_loss: 0.0164 - val_accuracy: 0.9800\n",
      "Epoch 26/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0072 - accuracy: 0.9922 - val_loss: 0.0159 - val_accuracy: 0.9805\n",
      "Epoch 27/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0072 - accuracy: 0.9920 - val_loss: 0.0148 - val_accuracy: 0.9816\n",
      "Epoch 28/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0065 - accuracy: 0.9927 - val_loss: 0.0149 - val_accuracy: 0.9831\n",
      "Epoch 29/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0066 - accuracy: 0.9929 - val_loss: 0.0159 - val_accuracy: 0.9816\n",
      "Epoch 30/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0062 - accuracy: 0.9927 - val_loss: 0.0150 - val_accuracy: 0.9819\n",
      "Epoch 31/35\n",
      "762/762 [==============================] - 16s 20ms/step - loss: 0.0062 - accuracy: 0.9924 - val_loss: 0.0152 - val_accuracy: 0.9824\n",
      "Epoch 32/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0055 - accuracy: 0.9938 - val_loss: 0.0153 - val_accuracy: 0.9819\n",
      "Epoch 33/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0062 - accuracy: 0.9924 - val_loss: 0.0146 - val_accuracy: 0.9811\n",
      "Epoch 34/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0060 - accuracy: 0.9932 - val_loss: 0.0144 - val_accuracy: 0.9828\n",
      "Epoch 35/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0056 - accuracy: 0.9934 - val_loss: 0.0146 - val_accuracy: 0.9821\n",
      "Val loss: 1.458742%\n",
      "model: gru\n",
      "embedding_dim: 341\n",
      "num_rnn_node: 812\n",
      "num_dense_node: 104\n",
      "num_layer: 3\n",
      "activation_fn: tanh\n",
      "learning rate: 1.3e-05\n",
      "optimizer: Adam\n",
      "margin: 0.7641258929556295\n",
      "batch_size: 27\n",
      "Epoch 1/35\n",
      "903/903 [==============================] - 43s 37ms/step - loss: 0.0796 - accuracy: 0.8570 - val_loss: 0.0732 - val_accuracy: 0.8625\n",
      "Epoch 2/35\n",
      "903/903 [==============================] - 31s 34ms/step - loss: 0.0708 - accuracy: 0.8585 - val_loss: 0.0703 - val_accuracy: 0.8625\n",
      "Epoch 3/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0694 - accuracy: 0.8555 - val_loss: 0.0694 - val_accuracy: 0.8625\n",
      "Epoch 4/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0669 - accuracy: 0.8582 - val_loss: 0.0674 - val_accuracy: 0.8625\n",
      "Epoch 5/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0653 - accuracy: 0.8604 - val_loss: 0.0667 - val_accuracy: 0.8625\n",
      "Epoch 6/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0642 - accuracy: 0.8604 - val_loss: 0.0649 - val_accuracy: 0.8625\n",
      "Epoch 7/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0633 - accuracy: 0.8569 - val_loss: 0.0640 - val_accuracy: 0.8625\n",
      "Epoch 8/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0607 - accuracy: 0.8641 - val_loss: 0.0627 - val_accuracy: 0.8625\n",
      "Epoch 9/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0605 - accuracy: 0.8580 - val_loss: 0.0610 - val_accuracy: 0.8625\n",
      "Epoch 10/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0585 - accuracy: 0.8656 - val_loss: 0.0597 - val_accuracy: 0.8625\n",
      "Epoch 11/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0583 - accuracy: 0.8568 - val_loss: 0.0584 - val_accuracy: 0.8625\n",
      "Epoch 12/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0581 - accuracy: 0.8563 - val_loss: 0.0584 - val_accuracy: 0.8625\n",
      "Epoch 13/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0563 - accuracy: 0.8573 - val_loss: 0.0563 - val_accuracy: 0.8625\n",
      "Epoch 14/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0549 - accuracy: 0.8584 - val_loss: 0.0556 - val_accuracy: 0.8625\n",
      "Epoch 15/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0532 - accuracy: 0.8602 - val_loss: 0.0552 - val_accuracy: 0.8625\n",
      "Epoch 16/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0544 - accuracy: 0.8557 - val_loss: 0.0537 - val_accuracy: 0.8625\n",
      "Epoch 17/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0509 - accuracy: 0.8613 - val_loss: 0.0523 - val_accuracy: 0.8625\n",
      "Epoch 18/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0505 - accuracy: 0.8631 - val_loss: 0.0516 - val_accuracy: 0.8625\n",
      "Epoch 19/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0503 - accuracy: 0.8601 - val_loss: 0.0513 - val_accuracy: 0.8625\n",
      "Epoch 20/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0500 - accuracy: 0.8586 - val_loss: 0.0503 - val_accuracy: 0.8625\n",
      "Epoch 21/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0495 - accuracy: 0.8557 - val_loss: 0.0497 - val_accuracy: 0.8625\n",
      "Epoch 22/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0502 - accuracy: 0.8534 - val_loss: 0.0495 - val_accuracy: 0.8625\n",
      "Epoch 23/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0476 - accuracy: 0.8609 - val_loss: 0.0488 - val_accuracy: 0.8625\n",
      "Epoch 24/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0480 - accuracy: 0.8578 - val_loss: 0.0486 - val_accuracy: 0.8625\n",
      "Epoch 25/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0460 - accuracy: 0.8626 - val_loss: 0.0481 - val_accuracy: 0.8625\n",
      "Epoch 26/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0470 - accuracy: 0.8592 - val_loss: 0.0474 - val_accuracy: 0.8625\n",
      "Epoch 27/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0465 - accuracy: 0.8584 - val_loss: 0.0474 - val_accuracy: 0.8625\n",
      "Epoch 28/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0466 - accuracy: 0.8559 - val_loss: 0.0467 - val_accuracy: 0.8625\n",
      "Epoch 29/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0460 - accuracy: 0.8592 - val_loss: 0.0464 - val_accuracy: 0.8625\n",
      "Epoch 30/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0453 - accuracy: 0.8583 - val_loss: 0.0465 - val_accuracy: 0.8625\n",
      "Epoch 31/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0451 - accuracy: 0.8545 - val_loss: 0.0463 - val_accuracy: 0.8625\n",
      "Epoch 32/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0447 - accuracy: 0.8594 - val_loss: 0.0458 - val_accuracy: 0.8625\n",
      "Epoch 33/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0438 - accuracy: 0.8601 - val_loss: 0.0454 - val_accuracy: 0.8625\n",
      "Epoch 34/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0436 - accuracy: 0.8591 - val_loss: 0.0458 - val_accuracy: 0.8625\n",
      "Epoch 35/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0440 - accuracy: 0.8611 - val_loss: 0.0448 - val_accuracy: 0.8625\n",
      "Val loss: 4.478208%\n",
      "model: gru\n",
      "embedding_dim: 100\n",
      "num_rnn_node: 288\n",
      "num_dense_node: 86\n",
      "num_layer: 2\n",
      "activation_fn: relu\n",
      "learning rate: 7.2e-05\n",
      "optimizer: Adam\n",
      "margin: 0.3399274385625292\n",
      "batch_size: 13\n",
      "Epoch 1/35\n",
      "1874/1874 [==============================] - 41s 17ms/step - loss: nan - accuracy: 0.8595 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 2/35\n",
      "1874/1874 [==============================] - 29s 15ms/step - loss: nan - accuracy: 0.8621 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 3/35\n",
      "1874/1874 [==============================] - 28s 15ms/step - loss: nan - accuracy: 0.8589 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 4/35\n",
      "1874/1874 [==============================] - 28s 15ms/step - loss: nan - accuracy: 0.8589 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 5/35\n",
      "1874/1874 [==============================] - 29s 15ms/step - loss: nan - accuracy: 0.8551 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 6/35\n",
      "1874/1874 [==============================] - 28s 15ms/step - loss: nan - accuracy: 0.8544 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 7/35\n",
      "1874/1874 [==============================] - 28s 15ms/step - loss: nan - accuracy: 0.8581 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 8/35\n",
      "1874/1874 [==============================] - 28s 15ms/step - loss: nan - accuracy: 0.8587 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 9/35\n",
      "1874/1874 [==============================] - 28s 15ms/step - loss: nan - accuracy: 0.8592 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 10/35\n",
      "1874/1874 [==============================] - 28s 15ms/step - loss: nan - accuracy: 0.8582 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 11/35\n",
      "1874/1874 [==============================] - 28s 15ms/step - loss: nan - accuracy: 0.8607 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 12/35\n",
      "1874/1874 [==============================] - 28s 15ms/step - loss: nan - accuracy: 0.8614 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 13/35\n",
      "1874/1874 [==============================] - 29s 15ms/step - loss: nan - accuracy: 0.8583 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 14/35\n",
      "1874/1874 [==============================] - 28s 15ms/step - loss: nan - accuracy: 0.8565 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 15/35\n",
      "1874/1874 [==============================] - 29s 15ms/step - loss: nan - accuracy: 0.8582 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 16/35\n",
      "1874/1874 [==============================] - 29s 15ms/step - loss: nan - accuracy: 0.8593 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 17/35\n",
      "1874/1874 [==============================] - 29s 15ms/step - loss: nan - accuracy: 0.8589 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 18/35\n",
      "1874/1874 [==============================] - 28s 15ms/step - loss: nan - accuracy: 0.8574 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 19/35\n",
      "1874/1874 [==============================] - 28s 15ms/step - loss: nan - accuracy: 0.8598 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 20/35\n",
      "1874/1874 [==============================] - 29s 15ms/step - loss: nan - accuracy: 0.8575 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 21/35\n",
      "1874/1874 [==============================] - 29s 15ms/step - loss: nan - accuracy: 0.8570 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 22/35\n",
      "1874/1874 [==============================] - 28s 15ms/step - loss: nan - accuracy: 0.8599 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 23/35\n",
      "1874/1874 [==============================] - 28s 15ms/step - loss: nan - accuracy: 0.8571 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 24/35\n",
      "1874/1874 [==============================] - 29s 15ms/step - loss: nan - accuracy: 0.8549 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 25/35\n",
      "1874/1874 [==============================] - 28s 15ms/step - loss: nan - accuracy: 0.8621 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 26/35\n",
      "1874/1874 [==============================] - 29s 15ms/step - loss: nan - accuracy: 0.8611 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 27/35\n",
      "1874/1874 [==============================] - 29s 15ms/step - loss: nan - accuracy: 0.8591 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 28/35\n",
      "1874/1874 [==============================] - 29s 15ms/step - loss: nan - accuracy: 0.8565 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 29/35\n",
      "1874/1874 [==============================] - 28s 15ms/step - loss: nan - accuracy: 0.8610 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 30/35\n",
      "1874/1874 [==============================] - 29s 15ms/step - loss: nan - accuracy: 0.8579 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 31/35\n",
      "1874/1874 [==============================] - 29s 15ms/step - loss: nan - accuracy: 0.8568 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 32/35\n",
      "1874/1874 [==============================] - 29s 15ms/step - loss: nan - accuracy: 0.8615 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 33/35\n",
      "1874/1874 [==============================] - 29s 15ms/step - loss: nan - accuracy: 0.8571 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 34/35\n",
      "1874/1874 [==============================] - 29s 15ms/step - loss: nan - accuracy: 0.8584 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 35/35\n",
      "1874/1874 [==============================] - 28s 15ms/step - loss: nan - accuracy: 0.8656 - val_loss: nan - val_accuracy: 0.8625\n",
      "Val loss: nan%\n",
      "model: gru\n",
      "embedding_dim: 186\n",
      "num_rnn_node: 960\n",
      "num_dense_node: 138\n",
      "num_layer: 5\n",
      "activation_fn: relu\n",
      "learning rate: 2.4e-02\n",
      "optimizer: RMSprop\n",
      "margin: 0.34085568379006337\n",
      "batch_size: 22\n",
      "Epoch 1/35\n",
      "1108/1108 [==============================] - 43s 29ms/step - loss: nan - accuracy: 0.8595 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 2/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8589 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 3/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8542 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 4/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8580 - val_loss: nan - val_accuracy: 0.8625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8550 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 6/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8616 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 7/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8584 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 8/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8591 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 9/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8547 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 10/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8608 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 11/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8611 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 12/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8576 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 13/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8603 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 14/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8555 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 15/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8571 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 16/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8595 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 17/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8600 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 18/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8567 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 19/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8619 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 20/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8553 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 21/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8555 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 22/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8565 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 23/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8605 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 24/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8605 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 25/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8558 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 26/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8537 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 27/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8572 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 28/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8571 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 29/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8586 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 30/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8553 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 31/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8566 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 32/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8528 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 33/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8565 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 34/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8567 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 35/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8620 - val_loss: nan - val_accuracy: 0.8625\n",
      "Val loss: nan%\n",
      "model: gru\n",
      "embedding_dim: 298\n",
      "num_rnn_node: 487\n",
      "num_dense_node: 296\n",
      "num_layer: 5\n",
      "activation_fn: tanh\n",
      "learning rate: 1.2e-05\n",
      "optimizer: RMSprop\n",
      "margin: 0.7410748244368253\n",
      "batch_size: 7\n",
      "Epoch 1/35\n",
      "3480/3480 [==============================] - 74s 18ms/step - loss: 0.2231 - accuracy: 0.7327 - val_loss: 0.2154 - val_accuracy: 0.8625\n",
      "Epoch 2/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.2118 - accuracy: 0.8538 - val_loss: 0.2074 - val_accuracy: 0.8625\n",
      "Epoch 3/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.2051 - accuracy: 0.8604 - val_loss: 0.1996 - val_accuracy: 0.8625\n",
      "Epoch 4/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.1968 - accuracy: 0.8562 - val_loss: 0.1921 - val_accuracy: 0.8625\n",
      "Epoch 5/35\n",
      "3480/3480 [==============================] - 61s 18ms/step - loss: 0.1899 - accuracy: 0.8597 - val_loss: 0.1849 - val_accuracy: 0.8625\n",
      "Epoch 6/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.1826 - accuracy: 0.8582 - val_loss: 0.1779 - val_accuracy: 0.8625\n",
      "Epoch 7/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.1757 - accuracy: 0.8573 - val_loss: 0.1712 - val_accuracy: 0.8625\n",
      "Epoch 8/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.1692 - accuracy: 0.8590 - val_loss: 0.1647 - val_accuracy: 0.8625\n",
      "Epoch 9/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.1632 - accuracy: 0.8629 - val_loss: 0.1585 - val_accuracy: 0.8625\n",
      "Epoch 10/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.1567 - accuracy: 0.8577 - val_loss: 0.1526 - val_accuracy: 0.8625\n",
      "Epoch 11/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.1510 - accuracy: 0.8601 - val_loss: 0.1469 - val_accuracy: 0.8625\n",
      "Epoch 12/35\n",
      "3480/3480 [==============================] - 61s 18ms/step - loss: 0.1456 - accuracy: 0.8654 - val_loss: 0.1415 - val_accuracy: 0.8625\n",
      "Epoch 13/35\n",
      "3480/3480 [==============================] - 61s 18ms/step - loss: 0.1401 - accuracy: 0.8578 - val_loss: 0.1363 - val_accuracy: 0.8625\n",
      "Epoch 14/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.1351 - accuracy: 0.8573 - val_loss: 0.1314 - val_accuracy: 0.8625\n",
      "Epoch 15/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.1303 - accuracy: 0.8599 - val_loss: 0.1268 - val_accuracy: 0.8625\n",
      "Epoch 16/35\n",
      "3480/3480 [==============================] - 61s 18ms/step - loss: 0.1258 - accuracy: 0.8599 - val_loss: 0.1224 - val_accuracy: 0.8625\n",
      "Epoch 17/35\n",
      "3480/3480 [==============================] - 61s 18ms/step - loss: 0.1216 - accuracy: 0.8569 - val_loss: 0.1182 - val_accuracy: 0.8625\n",
      "Epoch 18/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.1172 - accuracy: 0.8621 - val_loss: 0.1143 - val_accuracy: 0.8625\n",
      "Epoch 19/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.1136 - accuracy: 0.8589 - val_loss: 0.1106 - val_accuracy: 0.8625\n",
      "Epoch 20/35\n",
      "3480/3480 [==============================] - 61s 18ms/step - loss: 0.1100 - accuracy: 0.8589 - val_loss: 0.1071 - val_accuracy: 0.8625\n",
      "Epoch 21/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.1071 - accuracy: 0.8540 - val_loss: 0.1038 - val_accuracy: 0.8625\n",
      "Epoch 22/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.1030 - accuracy: 0.8627 - val_loss: 0.1007 - val_accuracy: 0.8625\n",
      "Epoch 23/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.1005 - accuracy: 0.8590 - val_loss: 0.0979 - val_accuracy: 0.8625\n",
      "Epoch 24/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.0975 - accuracy: 0.8600 - val_loss: 0.0952 - val_accuracy: 0.8625\n",
      "Epoch 25/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.0956 - accuracy: 0.8553 - val_loss: 0.0927 - val_accuracy: 0.8625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.0924 - accuracy: 0.8608 - val_loss: 0.0904 - val_accuracy: 0.8625\n",
      "Epoch 27/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.0903 - accuracy: 0.8599 - val_loss: 0.0883 - val_accuracy: 0.8625\n",
      "Epoch 28/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.0884 - accuracy: 0.8592 - val_loss: 0.0863 - val_accuracy: 0.8625\n",
      "Epoch 29/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.0862 - accuracy: 0.8606 - val_loss: 0.0845 - val_accuracy: 0.8625\n",
      "Epoch 30/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.0854 - accuracy: 0.8557 - val_loss: 0.0828 - val_accuracy: 0.8625\n",
      "Epoch 31/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.0826 - accuracy: 0.8616 - val_loss: 0.0812 - val_accuracy: 0.8625\n",
      "Epoch 32/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.0821 - accuracy: 0.8567 - val_loss: 0.0797 - val_accuracy: 0.8625\n",
      "Epoch 33/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.0802 - accuracy: 0.8589 - val_loss: 0.0784 - val_accuracy: 0.8625\n",
      "Epoch 34/35\n",
      "3480/3480 [==============================] - 61s 18ms/step - loss: 0.0801 - accuracy: 0.8537 - val_loss: 0.0772 - val_accuracy: 0.8625\n",
      "Epoch 35/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.0784 - accuracy: 0.8564 - val_loss: 0.0761 - val_accuracy: 0.8625\n",
      "Val loss: 7.608715%\n",
      "model: lstm\n",
      "embedding_dim: 86\n",
      "num_rnn_node: 367\n",
      "num_dense_node: 82\n",
      "num_layer: 1\n",
      "activation_fn: relu\n",
      "learning rate: 6.9e-03\n",
      "optimizer: RMSprop\n",
      "margin: 0.46990900738124386\n",
      "batch_size: 9\n",
      "Epoch 1/35\n",
      "2707/2707 [==============================] - 54s 17ms/step - loss: nan - accuracy: 0.8575 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 2/35\n",
      "2707/2707 [==============================] - 42s 16ms/step - loss: nan - accuracy: 0.8588 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 3/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8567 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 4/35\n",
      "2707/2707 [==============================] - 42s 16ms/step - loss: nan - accuracy: 0.8614 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 5/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8581 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 6/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8593 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 7/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8577 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 8/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8572 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 9/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8606 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 10/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8596 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 11/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8550 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 12/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8598 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 13/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8602 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 14/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8555 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 15/35\n",
      "2707/2707 [==============================] - 42s 16ms/step - loss: nan - accuracy: 0.8596 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 16/35\n",
      "2707/2707 [==============================] - 42s 16ms/step - loss: nan - accuracy: 0.8592 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 17/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8535 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 18/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8584 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 19/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8596 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 20/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8649 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 21/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8606 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 22/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8626 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 23/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8620 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 24/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8594 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 25/35\n",
      "2707/2707 [==============================] - 42s 16ms/step - loss: nan - accuracy: 0.8576 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 26/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8542 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 27/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8563 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 28/35\n",
      "2707/2707 [==============================] - 42s 16ms/step - loss: nan - accuracy: 0.8578 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 29/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8538 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 30/35\n",
      "2707/2707 [==============================] - 42s 16ms/step - loss: nan - accuracy: 0.8589 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 31/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8566 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 32/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8576 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 33/35\n",
      "2707/2707 [==============================] - 42s 16ms/step - loss: nan - accuracy: 0.8578 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 34/35\n",
      "2707/2707 [==============================] - 42s 16ms/step - loss: nan - accuracy: 0.8565 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 35/35\n",
      "2707/2707 [==============================] - 42s 16ms/step - loss: nan - accuracy: 0.8590 - val_loss: nan - val_accuracy: 0.8625\n",
      "Val loss: nan%\n",
      "model: lstm\n",
      "embedding_dim: 245\n",
      "num_rnn_node: 302\n",
      "num_dense_node: 282\n",
      "num_layer: 1\n",
      "activation_fn: tanh\n",
      "learning rate: 2.2e-04\n",
      "optimizer: Adam\n",
      "margin: 0.8154229123971033\n",
      "batch_size: 4\n",
      "Epoch 1/35\n",
      "6089/6089 [==============================] - 94s 14ms/step - loss: 0.1839 - accuracy: 0.8339 - val_loss: 0.1025 - val_accuracy: 0.8625\n",
      "Epoch 2/35\n",
      "6089/6089 [==============================] - 81s 13ms/step - loss: 0.0951 - accuracy: 0.8592 - val_loss: 0.0816 - val_accuracy: 0.8625\n",
      "Epoch 3/35\n",
      "6089/6089 [==============================] - 81s 13ms/step - loss: 0.0839 - accuracy: 0.8547 - val_loss: 0.0792 - val_accuracy: 0.8625\n",
      "Epoch 4/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0794 - accuracy: 0.8620 - val_loss: 0.0789 - val_accuracy: 0.8625\n",
      "Epoch 5/35\n",
      "6089/6089 [==============================] - 81s 13ms/step - loss: 0.0809 - accuracy: 0.8582 - val_loss: 0.0789 - val_accuracy: 0.8625\n",
      "Epoch 6/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0817 - accuracy: 0.8564 - val_loss: 0.0776 - val_accuracy: 0.8625\n",
      "Epoch 7/35\n",
      "6089/6089 [==============================] - 81s 13ms/step - loss: 0.0797 - accuracy: 0.8559 - val_loss: 0.0752 - val_accuracy: 0.8625\n",
      "Epoch 8/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0786 - accuracy: 0.8601 - val_loss: 0.0785 - val_accuracy: 0.8625\n",
      "Epoch 9/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0808 - accuracy: 0.8563 - val_loss: 0.0738 - val_accuracy: 0.8625\n",
      "Epoch 10/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0749 - accuracy: 0.8586 - val_loss: 0.0739 - val_accuracy: 0.8625\n",
      "Epoch 11/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0764 - accuracy: 0.8588 - val_loss: 0.0770 - val_accuracy: 0.8625\n",
      "Epoch 12/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0727 - accuracy: 0.8651 - val_loss: 0.0690 - val_accuracy: 0.8730\n",
      "Epoch 13/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0709 - accuracy: 0.8691 - val_loss: 0.0720 - val_accuracy: 0.8666\n",
      "Epoch 14/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0708 - accuracy: 0.8683 - val_loss: 0.0660 - val_accuracy: 0.8822\n",
      "Epoch 15/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0669 - accuracy: 0.8754 - val_loss: 0.0647 - val_accuracy: 0.8877\n",
      "Epoch 16/35\n",
      "6089/6089 [==============================] - 82s 14ms/step - loss: 0.0652 - accuracy: 0.8800 - val_loss: 0.0625 - val_accuracy: 0.8801\n",
      "Epoch 17/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0635 - accuracy: 0.8830 - val_loss: 0.0615 - val_accuracy: 0.8890\n",
      "Epoch 18/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0614 - accuracy: 0.8907 - val_loss: 0.0601 - val_accuracy: 0.8852\n",
      "Epoch 19/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0579 - accuracy: 0.8978 - val_loss: 0.0584 - val_accuracy: 0.8982\n",
      "Epoch 20/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0561 - accuracy: 0.9023 - val_loss: 0.0555 - val_accuracy: 0.8993\n",
      "Epoch 21/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0530 - accuracy: 0.9072 - val_loss: 0.0549 - val_accuracy: 0.9031\n",
      "Epoch 22/35\n",
      "6089/6089 [==============================] - 81s 13ms/step - loss: 0.0505 - accuracy: 0.9127 - val_loss: 0.0518 - val_accuracy: 0.9113\n",
      "Epoch 23/35\n",
      "6089/6089 [==============================] - 81s 13ms/step - loss: 0.0481 - accuracy: 0.9200 - val_loss: 0.0501 - val_accuracy: 0.9136\n",
      "Epoch 24/35\n",
      "6089/6089 [==============================] - 81s 13ms/step - loss: 0.0472 - accuracy: 0.9223 - val_loss: 0.0496 - val_accuracy: 0.9208\n",
      "Epoch 25/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0436 - accuracy: 0.9277 - val_loss: 0.0475 - val_accuracy: 0.9194\n",
      "Epoch 26/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0414 - accuracy: 0.9324 - val_loss: 0.0466 - val_accuracy: 0.9159\n",
      "Epoch 27/35\n",
      "6089/6089 [==============================] - 81s 13ms/step - loss: 0.0389 - accuracy: 0.9362 - val_loss: 0.0474 - val_accuracy: 0.9261\n",
      "Epoch 28/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0377 - accuracy: 0.9384 - val_loss: 0.0455 - val_accuracy: 0.9277\n",
      "Epoch 29/35\n",
      "6089/6089 [==============================] - 81s 13ms/step - loss: 0.0348 - accuracy: 0.9445 - val_loss: 0.0439 - val_accuracy: 0.9277\n",
      "Epoch 30/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0353 - accuracy: 0.9427 - val_loss: 0.0429 - val_accuracy: 0.9272\n",
      "Epoch 31/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0331 - accuracy: 0.9476 - val_loss: 0.0419 - val_accuracy: 0.9341\n",
      "Epoch 32/35\n",
      "6089/6089 [==============================] - 83s 14ms/step - loss: 0.0316 - accuracy: 0.9503 - val_loss: 0.0411 - val_accuracy: 0.9337\n",
      "Epoch 33/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0293 - accuracy: 0.9543 - val_loss: 0.0407 - val_accuracy: 0.9320\n",
      "Epoch 34/35\n",
      "6089/6089 [==============================] - 82s 14ms/step - loss: 0.0278 - accuracy: 0.9575 - val_loss: 0.0396 - val_accuracy: 0.9348\n",
      "Epoch 35/35\n",
      "6089/6089 [==============================] - 82s 14ms/step - loss: 0.0275 - accuracy: 0.9596 - val_loss: 0.0382 - val_accuracy: 0.9374\n",
      "Val loss: 3.824718%\n",
      "model: lstm\n",
      "embedding_dim: 227\n",
      "num_rnn_node: 453\n",
      "num_dense_node: 79\n",
      "num_layer: 5\n",
      "activation_fn: relu\n",
      "learning rate: 2.1e-05\n",
      "optimizer: Adam\n",
      "margin: 0.7813060982585048\n",
      "batch_size: 26\n",
      "Epoch 1/35\n",
      "937/937 [==============================] - 36s 28ms/step - loss: 0.2244 - accuracy: 0.8003 - val_loss: 0.2227 - val_accuracy: 0.8625\n",
      "Epoch 2/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.2214 - accuracy: 0.8600 - val_loss: 0.2190 - val_accuracy: 0.8625\n",
      "Epoch 3/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.2179 - accuracy: 0.8610 - val_loss: 0.2154 - val_accuracy: 0.8625\n",
      "Epoch 4/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.2143 - accuracy: 0.8613 - val_loss: 0.2118 - val_accuracy: 0.8625\n",
      "Epoch 5/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.2098 - accuracy: 0.8544 - val_loss: 0.2083 - val_accuracy: 0.8625\n",
      "Epoch 6/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.2066 - accuracy: 0.8561 - val_loss: 0.2048 - val_accuracy: 0.8625\n",
      "Epoch 7/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.2034 - accuracy: 0.8578 - val_loss: 0.2014 - val_accuracy: 0.8625\n",
      "Epoch 8/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.2006 - accuracy: 0.8631 - val_loss: 0.1980 - val_accuracy: 0.8625\n",
      "Epoch 9/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1963 - accuracy: 0.8549 - val_loss: 0.1947 - val_accuracy: 0.8625\n",
      "Epoch 10/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1934 - accuracy: 0.8575 - val_loss: 0.1914 - val_accuracy: 0.8625\n",
      "Epoch 11/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1900 - accuracy: 0.8565 - val_loss: 0.1882 - val_accuracy: 0.8625\n",
      "Epoch 12/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1875 - accuracy: 0.8632 - val_loss: 0.1850 - val_accuracy: 0.8625\n",
      "Epoch 13/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1839 - accuracy: 0.8579 - val_loss: 0.1819 - val_accuracy: 0.8625\n",
      "Epoch 14/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1807 - accuracy: 0.8569 - val_loss: 0.1789 - val_accuracy: 0.8625\n",
      "Epoch 15/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1778 - accuracy: 0.8583 - val_loss: 0.1759 - val_accuracy: 0.8625\n",
      "Epoch 16/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1749 - accuracy: 0.8593 - val_loss: 0.1729 - val_accuracy: 0.8625\n",
      "Epoch 17/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1720 - accuracy: 0.8585 - val_loss: 0.1700 - val_accuracy: 0.8625\n",
      "Epoch 18/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1691 - accuracy: 0.8577 - val_loss: 0.1672 - val_accuracy: 0.8625\n",
      "Epoch 19/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1664 - accuracy: 0.8614 - val_loss: 0.1644 - val_accuracy: 0.8625\n",
      "Epoch 20/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1636 - accuracy: 0.8602 - val_loss: 0.1616 - val_accuracy: 0.8625\n",
      "Epoch 21/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1608 - accuracy: 0.8573 - val_loss: 0.1589 - val_accuracy: 0.8625\n",
      "Epoch 22/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1582 - accuracy: 0.8554 - val_loss: 0.1563 - val_accuracy: 0.8625\n",
      "Epoch 23/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1556 - accuracy: 0.8575 - val_loss: 0.1537 - val_accuracy: 0.8625\n",
      "Epoch 24/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1531 - accuracy: 0.8579 - val_loss: 0.1512 - val_accuracy: 0.8625\n",
      "Epoch 25/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1506 - accuracy: 0.8588 - val_loss: 0.1487 - val_accuracy: 0.8625\n",
      "Epoch 26/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1482 - accuracy: 0.8588 - val_loss: 0.1463 - val_accuracy: 0.8625\n",
      "Epoch 27/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1458 - accuracy: 0.8594 - val_loss: 0.1439 - val_accuracy: 0.8625\n",
      "Epoch 28/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1434 - accuracy: 0.8611 - val_loss: 0.1416 - val_accuracy: 0.8625\n",
      "Epoch 29/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1412 - accuracy: 0.8584 - val_loss: 0.1393 - val_accuracy: 0.8625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1389 - accuracy: 0.8583 - val_loss: 0.1371 - val_accuracy: 0.8625\n",
      "Epoch 31/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1366 - accuracy: 0.8610 - val_loss: 0.1349 - val_accuracy: 0.8625\n",
      "Epoch 32/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1346 - accuracy: 0.8595 - val_loss: 0.1328 - val_accuracy: 0.8625\n",
      "Epoch 33/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1326 - accuracy: 0.8575 - val_loss: 0.1308 - val_accuracy: 0.8625\n",
      "Epoch 34/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1305 - accuracy: 0.8586 - val_loss: 0.1287 - val_accuracy: 0.8625\n",
      "Epoch 35/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1284 - accuracy: 0.8611 - val_loss: 0.1268 - val_accuracy: 0.8625\n",
      "Val loss: 12.677984%\n",
      "model: gru\n",
      "embedding_dim: 112\n",
      "num_rnn_node: 144\n",
      "num_dense_node: 88\n",
      "num_layer: 4\n",
      "activation_fn: relu\n",
      "learning rate: 8.0e-03\n",
      "optimizer: Adam\n",
      "margin: 0.5770310679648518\n",
      "batch_size: 38\n",
      "Epoch 1/35\n",
      "641/641 [==============================] - 26s 27ms/step - loss: 0.1065 - accuracy: 0.8455 - val_loss: 0.0410 - val_accuracy: 0.8625\n",
      "Epoch 2/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0412 - accuracy: 0.8585 - val_loss: 0.0396 - val_accuracy: 0.8625\n",
      "Epoch 3/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0398 - accuracy: 0.8614 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 4/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0405 - accuracy: 0.8585 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 5/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0397 - accuracy: 0.8615 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 6/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0403 - accuracy: 0.8591 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 7/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0415 - accuracy: 0.8542 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 8/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0409 - accuracy: 0.8567 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 9/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0406 - accuracy: 0.8579 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 10/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0411 - accuracy: 0.8556 - val_loss: 0.0390 - val_accuracy: 0.8625\n",
      "Epoch 11/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0413 - accuracy: 0.8529 - val_loss: 0.0391 - val_accuracy: 0.8625\n",
      "Epoch 12/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0401 - accuracy: 0.8582 - val_loss: 0.0390 - val_accuracy: 0.8625\n",
      "Epoch 13/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0397 - accuracy: 0.8603 - val_loss: 0.0391 - val_accuracy: 0.8625\n",
      "Epoch 14/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0403 - accuracy: 0.8577 - val_loss: 0.0390 - val_accuracy: 0.8625\n",
      "Epoch 15/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0392 - accuracy: 0.8616 - val_loss: 0.0390 - val_accuracy: 0.8625\n",
      "Epoch 16/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0411 - accuracy: 0.8550 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 17/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0408 - accuracy: 0.8572 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 18/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0397 - accuracy: 0.8615 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 19/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0407 - accuracy: 0.8576 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 20/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0396 - accuracy: 0.8619 - val_loss: 0.0396 - val_accuracy: 0.8625\n",
      "Epoch 21/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0406 - accuracy: 0.8581 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 22/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0407 - accuracy: 0.8572 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 23/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0402 - accuracy: 0.8593 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 24/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0398 - accuracy: 0.8612 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 25/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0400 - accuracy: 0.8604 - val_loss: 0.0382 - val_accuracy: 0.8625\n",
      "Epoch 26/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0406 - accuracy: 0.8581 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 27/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0395 - accuracy: 0.8626 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 28/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0407 - accuracy: 0.8573 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 29/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0402 - accuracy: 0.8594 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 30/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0407 - accuracy: 0.8573 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 31/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0400 - accuracy: 0.8595 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 32/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0404 - accuracy: 0.8588 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 33/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0404 - accuracy: 0.8587 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 34/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0409 - accuracy: 0.8566 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 35/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0412 - accuracy: 0.8553 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Val loss: 3.947924%\n",
      "model: gru\n",
      "embedding_dim: 100\n",
      "num_rnn_node: 410\n",
      "num_dense_node: 90\n",
      "num_layer: 4\n",
      "activation_fn: tanh\n",
      "learning rate: 4.5e-05\n",
      "optimizer: RMSprop\n",
      "margin: 0.6536159322682215\n",
      "batch_size: 11\n",
      "Epoch 1/35\n",
      "2215/2215 [==============================] - 47s 17ms/step - loss: 0.2155 - accuracy: 0.7605 - val_loss: 0.1991 - val_accuracy: 0.8625\n",
      "Epoch 2/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.1940 - accuracy: 0.8603 - val_loss: 0.1808 - val_accuracy: 0.8625\n",
      "Epoch 3/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.1760 - accuracy: 0.8592 - val_loss: 0.1639 - val_accuracy: 0.8625\n",
      "Epoch 4/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.1598 - accuracy: 0.8613 - val_loss: 0.1484 - val_accuracy: 0.8625\n",
      "Epoch 5/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.1445 - accuracy: 0.8590 - val_loss: 0.1344 - val_accuracy: 0.8625\n",
      "Epoch 6/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.1310 - accuracy: 0.8590 - val_loss: 0.1218 - val_accuracy: 0.8625\n",
      "Epoch 7/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.1188 - accuracy: 0.8587 - val_loss: 0.1106 - val_accuracy: 0.8625\n",
      "Epoch 8/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.1080 - accuracy: 0.8568 - val_loss: 0.1008 - val_accuracy: 0.8625\n",
      "Epoch 9/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0986 - accuracy: 0.8595 - val_loss: 0.0921 - val_accuracy: 0.8625\n",
      "Epoch 10/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0906 - accuracy: 0.8543 - val_loss: 0.0847 - val_accuracy: 0.8625\n",
      "Epoch 11/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0833 - accuracy: 0.8589 - val_loss: 0.0784 - val_accuracy: 0.8625\n",
      "Epoch 12/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0776 - accuracy: 0.8562 - val_loss: 0.0730 - val_accuracy: 0.8625\n",
      "Epoch 13/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0721 - accuracy: 0.8599 - val_loss: 0.0685 - val_accuracy: 0.8625\n",
      "Epoch 14/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0680 - accuracy: 0.8588 - val_loss: 0.0648 - val_accuracy: 0.8625\n",
      "Epoch 15/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0650 - accuracy: 0.8558 - val_loss: 0.0617 - val_accuracy: 0.8625\n",
      "Epoch 16/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0624 - accuracy: 0.8550 - val_loss: 0.0593 - val_accuracy: 0.8625\n",
      "Epoch 17/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0594 - accuracy: 0.8593 - val_loss: 0.0574 - val_accuracy: 0.8625\n",
      "Epoch 18/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0575 - accuracy: 0.8598 - val_loss: 0.0558 - val_accuracy: 0.8625\n",
      "Epoch 19/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0559 - accuracy: 0.8605 - val_loss: 0.0546 - val_accuracy: 0.8625\n",
      "Epoch 20/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0560 - accuracy: 0.8554 - val_loss: 0.0537 - val_accuracy: 0.8625\n",
      "Epoch 21/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0536 - accuracy: 0.8614 - val_loss: 0.0524 - val_accuracy: 0.8625\n",
      "Epoch 22/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0532 - accuracy: 0.8584 - val_loss: 0.0519 - val_accuracy: 0.8625\n",
      "Epoch 23/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0518 - accuracy: 0.8621 - val_loss: 0.0512 - val_accuracy: 0.8625\n",
      "Epoch 24/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0519 - accuracy: 0.8578 - val_loss: 0.0492 - val_accuracy: 0.8625\n",
      "Epoch 25/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0506 - accuracy: 0.8560 - val_loss: 0.0473 - val_accuracy: 0.8625\n",
      "Epoch 26/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0487 - accuracy: 0.8579 - val_loss: 0.0468 - val_accuracy: 0.8625\n",
      "Epoch 27/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0485 - accuracy: 0.8559 - val_loss: 0.0465 - val_accuracy: 0.8625\n",
      "Epoch 28/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0477 - accuracy: 0.8598 - val_loss: 0.0461 - val_accuracy: 0.8625\n",
      "Epoch 29/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0475 - accuracy: 0.8573 - val_loss: 0.0458 - val_accuracy: 0.8625\n",
      "Epoch 30/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0471 - accuracy: 0.8568 - val_loss: 0.0456 - val_accuracy: 0.8625\n",
      "Epoch 31/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0469 - accuracy: 0.8582 - val_loss: 0.0452 - val_accuracy: 0.8625\n",
      "Epoch 32/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0464 - accuracy: 0.8582 - val_loss: 0.0451 - val_accuracy: 0.8625\n",
      "Epoch 33/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0463 - accuracy: 0.8591 - val_loss: 0.0449 - val_accuracy: 0.8625\n",
      "Epoch 34/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0462 - accuracy: 0.8595 - val_loss: 0.0450 - val_accuracy: 0.8625\n",
      "Epoch 35/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0455 - accuracy: 0.8602 - val_loss: 0.0449 - val_accuracy: 0.8625\n",
      "Val loss: 4.489307%\n",
      "model: rnn\n",
      "embedding_dim: 230\n",
      "num_rnn_node: 224\n",
      "num_dense_node: 68\n",
      "num_layer: 4\n",
      "activation_fn: tanh\n",
      "learning rate: 1.1e-05\n",
      "optimizer: RMSprop\n",
      "margin: 0.4908491299482388\n",
      "batch_size: 4\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "('`cell` should have a `call` method. The RNN was passed:', 224)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12093/1552977908.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msearch_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgp_minimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macq_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'EI'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/skopt/optimizer/gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    257\u001b[0m             noise=noise)\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m     return base_minimize(\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0macq_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0macq_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_calls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0mnext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/skopt/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0;31m# Call the wrapped objective function with the named arguments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mobjective_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0marg_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobjective_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_12093/1905092735.py\u001b[0m in \u001b[0;36mfitness\u001b[0;34m(model_type, embedding_dim, num_rnn_node, num_dense_node, num_layer, activation_fn, learning_rate, optimizer, margin, batch_size)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"batch_size:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rnn_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_dense_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rnn_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_dense_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_12093/1546879728.py\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(model_type, embedding_dim, num_rnn_node, num_dense_node, num_layer, activation_fn, learning_rate, optimizer, margin)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_rnn_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"rnn\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_rnn_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_dense_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cell, return_sequences, return_state, go_backwards, stateful, unroll, time_major, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStackedRNNCells\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m'call'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m       raise ValueError('`cell` should have a `call` method. '\n\u001b[0m\u001b[1;32m    405\u001b[0m                        'The RNN was passed:', cell)\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m'state_size'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: ('`cell` should have a `call` method. The RNN was passed:', 224)"
     ]
    }
   ],
   "source": [
    "search_result = gp_minimize(func=fitness, dimensions=dims, acq_func='EI', n_calls=40, x0=default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "26b84816",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = [dim_model, dim_embedding, dim_rnn_node, dim_num_dense_nodes, dim_num_layer, dim_activation, dim_lr, dim_opt, dim_margin, dim_batch_size]\n",
    "default_params = [\"gru\", 64, 128, 64, 2, \"tanh\", 1e-3, \"RMSprop\", 1, 32]\n",
    "best_params = [\"lstm\", 256, 512, 256, 1, \"tanh\", 2e-4, \"Adam\", 0.8, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17effd31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: lstm\n",
      "embedding_dim: 256\n",
      "num_rnn_node: 512\n",
      "num_dense_node: 256\n",
      "num_layer: 1\n",
      "activation_fn: tanh\n",
      "learning rate: 2.0e-04\n",
      "optimizer: Adam\n",
      "margin: 0.8\n",
      "batch_size: 4\n",
      "Epoch 1/50\n",
      "6089/6089 [==============================] - 95s 14ms/step - loss: 0.0707 - accuracy: 0.8619 - val_loss: 0.0555 - val_accuracy: 0.8625\n",
      "\n",
      "Epoch 00001: saving model to exp3_model/alstm-01-0.06.hdf5\n",
      "Epoch 2/50\n",
      "6089/6089 [==============================] - 84s 14ms/step - loss: 0.0529 - accuracy: 0.8632 - val_loss: 0.0542 - val_accuracy: 0.8625\n",
      "\n",
      "Epoch 00002: saving model to exp3_model/alstm-02-0.05.hdf5\n",
      "Epoch 3/50\n",
      "6089/6089 [==============================] - 84s 14ms/step - loss: 0.0489 - accuracy: 0.8606 - val_loss: 0.0418 - val_accuracy: 0.8625\n",
      "\n",
      "Epoch 00003: saving model to exp3_model/alstm-03-0.04.hdf5\n",
      "Epoch 4/50\n",
      "6089/6089 [==============================] - 82s 14ms/step - loss: 0.0415 - accuracy: 0.8727 - val_loss: 0.0368 - val_accuracy: 0.9107\n",
      "\n",
      "Epoch 00004: saving model to exp3_model/alstm-04-0.04.hdf5\n",
      "Epoch 5/50\n",
      "2828/6089 [============>.................] - ETA: 42s - loss: 0.0338 - accuracy: 0.9223"
     ]
    }
   ],
   "source": [
    "fitness2(x=best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "95dcdb1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'search_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12093/4180237896.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_convergence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'search_result' is not defined"
     ]
    }
   ],
   "source": [
    "plot_convergence(search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280775e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_result.x\n",
    "space = search_result.space\n",
    "space.point_to_dict(search_result.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b25bc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(zip(search_result.func_vals, search_result.x_iters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b7289a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_objective_2D(result=search_result,\n",
    "                        dimension_name1='learning_rate',\n",
    "                        dimension_name2='num_rnn_node',\n",
    "                        levels=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ab76d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_names = ['learning_rate', 'num_dense_nodes', 'num_dense_layers']\n",
    "fig, ax = plot_objective(result=search_result, dimension_names=dim_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247dcc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_names = ['learning_rate', 'num_dense_nodes', 'num_dense_layers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa3df3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# siamese.save('models/NP_siamese_exp2_20220216.h5')\n",
    "# siamese.save('models/NP_siamese_exp2_20220216')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
<<<<<<< HEAD
   "display_name": "py39",
   "language": "python",
   "name": "py39"
=======
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
>>>>>>> c24a6e4fa6e3c4fe04f3698d8d480f4809adc573
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.9.7"
=======
   "version": "3.8.0"
>>>>>>> c24a6e4fa6e3c4fe04f3698d8d480f4809adc573
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
