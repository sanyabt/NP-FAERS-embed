{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9bf7ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, clear_output\n",
    "import re\n",
    "import skopt\n",
    "from skopt import BayesSearchCV\n",
    "from skopt import gp_minimize, forest_minimize\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.plots import plot_convergence\n",
    "from skopt.plots import plot_objective, plot_evaluations\n",
    "from skopt.plots import plot_histogram, plot_objective_2D\n",
    "from skopt.utils import use_named_args\n",
    "from tqdm import tqdm\n",
    "#!pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cc0f615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5358 entries, 0 to 5357\n",
      "Data columns (total 2 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   FAERS_drug_match  5358 non-null   object\n",
      " 1   lookup_value      5358 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 83.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#if starting from preprocess, load the drugs directly\n",
    "df = pd.read_csv('../data/NP_FAERS_mapped_20220215.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94858ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make all casing upper\n",
    "df['FAERS_drug_match'] = df['FAERS_drug_match'].str.upper()\n",
    "df['lookup_value'] = df['lookup_value'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7acb74a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import string\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32a68b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how i add noise \n",
    "# string w \n",
    "# proportion of noise added \n",
    "# uniform random from [0,1]\n",
    "# if <1/3 edit one position with new random character, else if <2/3 delete one position, else add one random character \n",
    "def add_noise(w, percent):\n",
    "  ''' edit, del, add'''\n",
    "  positions = random.choices(range(len(w)), k=int(percent*len(w)))\n",
    "  for p in positions:\n",
    "    r = random.random()\n",
    "    if r <= 0.3333: # edit\n",
    "      w = w[:p] + random.choice(string.ascii_uppercase) + w[p+1:]\n",
    "    elif r<= 0.6667: # delete\n",
    "      w = w[:p] + w[p+1:]\n",
    "    elif r<=1: # add\n",
    "      w = w[:p] + random.choice(string.ascii_uppercase) + w[p:]\n",
    "  return w\n",
    "\n",
    "def clean(text):\n",
    "    #remove all non-ascii, special characters and keep alphabets and space only. Can also use isalpha()\n",
    "    #convert to uppercase\n",
    "    #remove extra spaces\n",
    "    regex = re.compile('[^a-zA-Z ]')\n",
    "    r = regex.sub('', text)\n",
    "    result = re.sub(' +', ' ', r)\n",
    "    result = result.strip()\n",
    "    return result.upper()\n",
    "def clean_dataset(data):\n",
    "  x = []\n",
    "  y = []\n",
    "  for i in range(data.shape[0]):\n",
    "    w = clean(data.FAERS_drug_match.iloc[i])\n",
    "    v = clean(data.lookup_value.iloc[i])\n",
    "    x.append(w)\n",
    "    y.append(v)\n",
    "  return x,y\n",
    "\n",
    "def encode_dataset(x,y):\n",
    "  encode_dict = {l:i+1 for i,l in enumerate(string.ascii_uppercase + \" \")}\n",
    "  Xtrain = [[encode_dict[m] for m in n] for n in x]\n",
    "  Ytrain = [[encode_dict[m] for m in n] for n in y]\n",
    "  return Xtrain, Ytrain\n",
    "\n",
    "def clean_encode_padding(q, maxlen):\n",
    "  q = clean(q)\n",
    "  encode_dict = {l:i+1 for i,l in enumerate(string.ascii_uppercase + \" \")}\n",
    "  return tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    [encode_dict[m] for m in q] , padding=\"post\", maxlen=maxlen)\n",
    "\n",
    "def padding_dataset(X,Y,maxlen):\n",
    "  padded_y = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    Y, padding=\"post\", maxlen=maxlen)\n",
    "  padded_x = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      X, padding=\"post\", maxlen=maxlen)\n",
    "  return padded_x, padded_y\n",
    "\n",
    "def cosine_distance(vects):\n",
    "    x, y = vects\n",
    "    return 1-tf.reduce_sum(tf.multiply(x,y),axis=1, keepdims=True)/(tf.norm(x,axis=1,keepdims=True)*tf.norm(y,axis=1,keepdims=True))\n",
    "\n",
    "def loss(margin=1):\n",
    "    def contrastive_loss(y_true, y_pred):\n",
    "        square_pred = tf.math.square(y_pred)\n",
    "        margin_square = tf.math.square(tf.math.maximum(margin - (y_pred), 0))\n",
    "        return tf.math.reduce_mean(\n",
    "            (1 - y_true) * square_pred + (y_true) * margin_square\n",
    "        )\n",
    "\n",
    "    return contrastive_loss\n",
    "\n",
    "def plt_metric(history, metric, title, has_valid=True):\n",
    "    \"\"\"Plots the given 'metric' from 'history'.\n",
    "\n",
    "    Arguments:\n",
    "        history: history attribute of History object returned from Model.fit.\n",
    "        metric: Metric to plot, a string value present as key in 'history'.\n",
    "        title: A string to be used as title of plot.\n",
    "        has_valid: Boolean, true if valid data was passed to Model.fit else false.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    plt.plot(history[metric])\n",
    "    if has_valid:\n",
    "        plt.plot(history[\"val_\" + metric])\n",
    "        plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "    plt.title(title)\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5dcb0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ddeb146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4286, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d720a75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1072, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31ef8e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#padding length = maxlen\n",
    "maxlen = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "547a283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest, ytest = clean_dataset(test)\n",
    "Xtest, Ytest = encode_dataset(xtest,ytest)\n",
    "padded_xTest, padded_yTest = padding_dataset(Xtest,Ytest,maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d3b2586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1072, 400)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_xTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17f469fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#without noise \n",
    "x, y = clean_dataset(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72b1b518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4286"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94ee3ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_dict = {l:i+1 for i,l in enumerate(string.ascii_uppercase + \" \")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ec49f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = [[encode_dict[m] for m in n] for n in x]\n",
    "Ytrain = [[encode_dict[m] for m in n] for n in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ef740e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4286\n",
      "4286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanup\\AppData\\Local\\Continuum\\anaconda3\\envs\\clock\\lib\\site-packages\\numpy\\core\\_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(125,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(Xtrain))\n",
    "print(len(Ytrain))\n",
    "np.unique(Ytrain).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7659c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19  5 18 ...  0  0  0]\n",
      " [15 16  8 ...  0  0  0]\n",
      " [ 3  9 14 ...  0  0  0]\n",
      " ...\n",
      " [ 1 12 12 ...  0  0  0]\n",
      " [ 1 12 12 ...  0  0  0]\n",
      " [ 8  5 13 ...  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "padded_y = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    Ytrain, padding=\"post\", maxlen=maxlen\n",
    ")\n",
    "padded_x = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    Xtrain, padding=\"post\", maxlen=maxlen\n",
    ")\n",
    "\n",
    "print(padded_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1dbfd826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encode_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c1a4a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dUnique_label</th>\n",
       "      <th>dUnique_seq</th>\n",
       "      <th>dUnique_seq_padded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACTAEA RACEMOSA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AESCULUS HIPPOCASTANUM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALLIUM SATIVUM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALOE VERA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANGELICA SINENSIS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            dUnique_label dUnique_seq dUnique_seq_padded\n",
       "0         ACTAEA RACEMOSA         NaN                NaN\n",
       "1  AESCULUS HIPPOCASTANUM         NaN                NaN\n",
       "2          ALLIUM SATIVUM         NaN                NaN\n",
       "3               ALOE VERA         NaN                NaN\n",
       "4       ANGELICA SINENSIS         NaN                NaN"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dUnique_df = pd.DataFrame(columns = ['dUnique_label','dUnique_seq', 'dUnique_seq_padded'])\n",
    "dUnique_df['dUnique_label'] = np.unique(y)\n",
    "dUnique_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6de2b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dUnique_seq_list = [[encode_dict[m] for m in n] for n in dUnique_df['dUnique_label'].tolist()]\n",
    "len(dUnique_seq_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3b8eede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dUnique_label</th>\n",
       "      <th>dUnique_seq</th>\n",
       "      <th>dUnique_seq_padded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACTAEA RACEMOSA</td>\n",
       "      <td>[1, 3, 20, 1, 5, 1, 27, 18, 1, 3, 5, 13, 15, 1...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AESCULUS HIPPOCASTANUM</td>\n",
       "      <td>[1, 5, 19, 3, 21, 12, 21, 19, 27, 8, 9, 16, 16...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALLIUM SATIVUM</td>\n",
       "      <td>[1, 12, 12, 9, 21, 13, 27, 19, 1, 20, 9, 22, 2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALOE VERA</td>\n",
       "      <td>[1, 12, 15, 5, 27, 22, 5, 18, 1]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANGELICA SINENSIS</td>\n",
       "      <td>[1, 14, 7, 5, 12, 9, 3, 1, 27, 19, 9, 14, 5, 1...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            dUnique_label                                        dUnique_seq  \\\n",
       "0         ACTAEA RACEMOSA  [1, 3, 20, 1, 5, 1, 27, 18, 1, 3, 5, 13, 15, 1...   \n",
       "1  AESCULUS HIPPOCASTANUM  [1, 5, 19, 3, 21, 12, 21, 19, 27, 8, 9, 16, 16...   \n",
       "2          ALLIUM SATIVUM  [1, 12, 12, 9, 21, 13, 27, 19, 1, 20, 9, 22, 2...   \n",
       "3               ALOE VERA                   [1, 12, 15, 5, 27, 22, 5, 18, 1]   \n",
       "4       ANGELICA SINENSIS  [1, 14, 7, 5, 12, 9, 3, 1, 27, 19, 9, 14, 5, 1...   \n",
       "\n",
       "  dUnique_seq_padded  \n",
       "0                NaN  \n",
       "1                NaN  \n",
       "2                NaN  \n",
       "3                NaN  \n",
       "4                NaN  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(dUnique_df.index)):\n",
    "    dUnique_df.at[i, 'dUnique_seq'] = np.array(dUnique_seq_list[i])\n",
    "dUnique_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa10decf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9242 entries, 0 to 9241\n",
      "Data columns (total 2 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   FAERS_drug_match  9242 non-null   object\n",
      " 1   lookup_value      9242 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 144.5+ KB\n"
     ]
    }
   ],
   "source": [
    "#setup negative pairs\n",
    "dfneg = pd.read_csv('../data/NP_FAERS_negative_pairs_20220222.csv')\n",
    "dfneg.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e078706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode negative pairs and add padding\n",
    "xneg, yneg = clean_dataset(dfneg)\n",
    "Xneg, Yneg = encode_dataset(xneg,yneg)\n",
    "padded_xneg, padded_yneg = padding_dataset(Xneg,Yneg,maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef18203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dUnique = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    list(dUnique_df['dUnique_seq']), padding=\"post\", maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3c531f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_unique = dUnique_df.dUnique_label.tolist()\n",
    "len(np_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cf602f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4286 4286 4286\n"
     ]
    }
   ],
   "source": [
    "#add positive pairs\n",
    "x1TrainRNN = []\n",
    "x2TrainRNN = []\n",
    "yTrainRNN = []\n",
    "for i in range(len(padded_x)):\n",
    "    yTrainRNN.append(1)\n",
    "    x1TrainRNN.append(padded_x[i])\n",
    "    x2TrainRNN.append(padded_y[i])\n",
    "print(len(x1TrainRNN), len(x2TrainRNN), len(yTrainRNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e10f643a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>FAERS_drug_match</th>\n",
       "      <th>lookup_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3956</td>\n",
       "      <td>SERENOA REPENS/SERENOA REPENS EXTRACT/SERENOA ...</td>\n",
       "      <td>SERENOA REPENS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4408</td>\n",
       "      <td>CORDYCEPS</td>\n",
       "      <td>OPHIOCORDYCEPS SINENSIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120</td>\n",
       "      <td>CINNAMON (CINNAMOUM VERUM) (CAPSULES)</td>\n",
       "      <td>CINNAMON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3311</td>\n",
       "      <td>CHROMIUM PICOLINATE WITH GREEN TEA</td>\n",
       "      <td>CAMELLIA SINENSIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1921</td>\n",
       "      <td>BARLEY.</td>\n",
       "      <td>BARLEY GRASS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                   FAERS_drug_match  \\\n",
       "0   3956  SERENOA REPENS/SERENOA REPENS EXTRACT/SERENOA ...   \n",
       "1   4408                                          CORDYCEPS   \n",
       "2    120              CINNAMON (CINNAMOUM VERUM) (CAPSULES)   \n",
       "3   3311                 CHROMIUM PICOLINATE WITH GREEN TEA   \n",
       "4   1921                                            BARLEY.   \n",
       "\n",
       "              lookup_value  \n",
       "0           SERENOA REPENS  \n",
       "1  OPHIOCORDYCEPS SINENSIS  \n",
       "2                 CINNAMON  \n",
       "3        CAMELLIA SINENSIS  \n",
       "4             BARLEY GRASS  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_res = train.reset_index()\n",
    "train_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3a532277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16912"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take negative pairs from training data\n",
    "faers_match = []\n",
    "lookup = []\n",
    "for i in range(len(train_res)):\n",
    "    np_name = train_res.at[i, 'FAERS_drug_match']\n",
    "    for j in random.choices(range(len(np_unique)), k=4):\n",
    "        np_temp = np_unique[j]\n",
    "        np_match = train_res.loc[train_res['FAERS_drug_match'] == np_name].lookup_value.tolist()\n",
    "        if np_temp not in np_match:\n",
    "            faers_match.append(np_name)\n",
    "            lookup.append(np_temp)\n",
    "len(faers_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e93d2461",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfneg2 = pd.DataFrame(columns=['FAERS_drug_match', 'lookup_value'])\n",
    "dfneg2['FAERS_drug_match'] = faers_match\n",
    "dfneg2['lookup_value'] = lookup\n",
    "xneg2, yneg2 = clean_dataset(dfneg2)\n",
    "Xneg2, Yneg2 = encode_dataset(xneg2,yneg2)\n",
    "padded_xneg2, padded_yneg2 = padding_dataset(Xneg2,Yneg2,maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "859b01bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21198 21198 21198\n"
     ]
    }
   ],
   "source": [
    "##add negative pairs from training data\n",
    "for j in range(len(padded_xneg2)):\n",
    "    yTrainRNN.append(0)\n",
    "    x1TrainRNN.append(padded_xneg2[j])\n",
    "    x2TrainRNN.append(padded_yneg2[j])\n",
    "print(len(x1TrainRNN), len(x2TrainRNN), len(yTrainRNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9a581f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30440 30440 30440\n"
     ]
    }
   ],
   "source": [
    "##add negative pairs from reference set\n",
    "for j in range(len(padded_xneg)):\n",
    "    yTrainRNN.append(0)\n",
    "    x1TrainRNN.append(padded_xneg[j])\n",
    "    x2TrainRNN.append(padded_yneg[j])\n",
    "print(len(x1TrainRNN), len(x2TrainRNN), len(yTrainRNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c8bd255a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dUnique_label</th>\n",
       "      <th>dUnique_seq</th>\n",
       "      <th>dUnique_seq_padded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACTAEA RACEMOSA</td>\n",
       "      <td>[1, 3, 20, 1, 5, 1, 27, 18, 1, 3, 5, 13, 15, 1...</td>\n",
       "      <td>[1, 3, 20, 1, 5, 1, 27, 18, 1, 3, 5, 13, 15, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AESCULUS HIPPOCASTANUM</td>\n",
       "      <td>[1, 5, 19, 3, 21, 12, 21, 19, 27, 8, 9, 16, 16...</td>\n",
       "      <td>[1, 5, 19, 3, 21, 12, 21, 19, 27, 8, 9, 16, 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALLIUM SATIVUM</td>\n",
       "      <td>[1, 12, 12, 9, 21, 13, 27, 19, 1, 20, 9, 22, 2...</td>\n",
       "      <td>[1, 12, 12, 9, 21, 13, 27, 19, 1, 20, 9, 22, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALOE VERA</td>\n",
       "      <td>[1, 12, 15, 5, 27, 22, 5, 18, 1]</td>\n",
       "      <td>[1, 12, 15, 5, 27, 22, 5, 18, 1, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANGELICA SINENSIS</td>\n",
       "      <td>[1, 14, 7, 5, 12, 9, 3, 1, 27, 19, 9, 14, 5, 1...</td>\n",
       "      <td>[1, 14, 7, 5, 12, 9, 3, 1, 27, 19, 9, 14, 5, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            dUnique_label                                        dUnique_seq  \\\n",
       "0         ACTAEA RACEMOSA  [1, 3, 20, 1, 5, 1, 27, 18, 1, 3, 5, 13, 15, 1...   \n",
       "1  AESCULUS HIPPOCASTANUM  [1, 5, 19, 3, 21, 12, 21, 19, 27, 8, 9, 16, 16...   \n",
       "2          ALLIUM SATIVUM  [1, 12, 12, 9, 21, 13, 27, 19, 1, 20, 9, 22, 2...   \n",
       "3               ALOE VERA                   [1, 12, 15, 5, 27, 22, 5, 18, 1]   \n",
       "4       ANGELICA SINENSIS  [1, 14, 7, 5, 12, 9, 3, 1, 27, 19, 9, 14, 5, 1...   \n",
       "\n",
       "                                  dUnique_seq_padded  \n",
       "0  [1, 3, 20, 1, 5, 1, 27, 18, 1, 3, 5, 13, 15, 1...  \n",
       "1  [1, 5, 19, 3, 21, 12, 21, 19, 27, 8, 9, 16, 16...  \n",
       "2  [1, 12, 12, 9, 21, 13, 27, 19, 1, 20, 9, 22, 2...  \n",
       "3  [1, 12, 15, 5, 27, 22, 5, 18, 1, 0, 0, 0, 0, 0...  \n",
       "4  [1, 14, 7, 5, 12, 9, 3, 1, 27, 19, 9, 14, 5, 1...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(dUnique_df.index)):\n",
    "    dUnique_df.at[i, 'dUnique_seq_padded'] = dUnique[i]\n",
    "dUnique_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fe76098f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1TrainRnnS, x1ValRnnS, x2TrainRnnS, x2ValRnnS, yTrainRnnS, yValRnnS = train_test_split(x1TrainRNN, x2TrainRNN, yTrainRNN, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93a0074",
   "metadata": {},
   "source": [
    "## build model and hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a1de919b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "16e583fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model_type, embedding_dim, num_rnn_node, num_dense_node, num_layer, activation_fn, learning_rate, optimizer, margin):\n",
    "    input_x = tf.keras.layers.Input(maxlen)\n",
    "    input_1 = tf.keras.layers.Input(maxlen)\n",
    "    input_2 = tf.keras.layers.Input(maxlen)\n",
    "    embedding = tf.keras.layers.Embedding(input_dim=28, output_dim=embedding_dim, mask_zero=True)\n",
    "    x = embedding(input_x)\n",
    "    \n",
    "    if model_type == \"lstm\":\n",
    "        x = tf.keras.layers.LSTM(num_rnn_node)(x)\n",
    "    elif model_type==\"gru\":\n",
    "        x = tf.keras.layers.GRU(num_rnn_node)(x)\n",
    " \n",
    "    num = num_dense_node\n",
    "    for _ in range(num_layer):\n",
    "        x = tf.keras.layers.Dense(num, activation=activation_fn)(x)\n",
    "        num /= 2\n",
    "        \n",
    "    embedding_network = tf.keras.Model(input_x, x)\n",
    "\n",
    "    tower_1 = embedding_network(input_1)\n",
    "    tower_2 = embedding_network(input_2)\n",
    "\n",
    "    merge_layer = tf.keras.layers.Lambda(cosine_distance)([tower_1, tower_2])\n",
    "    output_layer = tf.keras.layers.Dense(1, activation=\"sigmoid\")(merge_layer)\n",
    "    contr = tf.keras.Model(inputs=[input_1, input_2], outputs=output_layer)\n",
    "    \n",
    "    if optimizer == \"Adam\":\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer ==\"RMSprop\":                \n",
    "        opt = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    contr.compile(loss=loss(margin= margin), optimizer=opt, metrics=[\"accuracy\"])\n",
    "    return contr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c0d3c08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_model = Categorical(categories=[\"lstm\", \"gru\"], name=\"model_type\")\n",
    "dim_embedding = Integer(low=64, high=512, prior=\"log-uniform\", base=2, name=\"embedding_dim\")\n",
    "dim_rnn_node = Integer(low=128, high=1024, prior=\"log-uniform\", base=2, name=\"num_rnn_node\")\n",
    "dim_num_dense_nodes = Integer(low=64, high=512, prior=\"log-uniform\", base=2, name=\"num_dense_node\")\n",
    "dim_num_layer = Integer(low=1, high=5, prior=\"uniform\", name=\"num_layer\")\n",
    "dim_activation = Categorical(categories=['tanh', 'relu'], name=\"activation_fn\")\n",
    "dim_lr = Real(low=1e-5, high=1e-1, prior=\"log-uniform\", base=10, name=\"learning_rate\")\n",
    "dim_opt = Categorical(categories=['Adam', 'RMSprop'], name=\"optimizer\")\n",
    "dim_margin = Real(low=1e-1, high=1, prior=\"uniform\", name=\"margin\")\n",
    "dim_batch_size = Integer(low=4, high=64, prior=\"log-uniform\", base=2, name=\"batch_size\")\n",
    "dims = [dim_model, dim_embedding, dim_rnn_node, dim_num_dense_nodes, dim_num_layer, dim_activation, dim_lr, dim_opt, dim_margin, dim_batch_size]\n",
    "default_params = [\"gru\", 64, 128, 64, 2, \"tanh\", 1e-3, \"RMSprop\", 1, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c937781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_dir_name(a):\n",
    "    o = \"\"\n",
    "    for n in a:\n",
    "        o+= str(n)+\"_\"\n",
    "    return o+\".log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "63ccff91",
   "metadata": {},
   "outputs": [],
   "source": [
    "@use_named_args(dimensions=dims)\n",
    "def fitness(model_type, embedding_dim, num_rnn_node, num_dense_node, num_layer, activation_fn, learning_rate, optimizer, margin, batch_size):\n",
    "    \n",
    "    print(\"model:\", model_type)\n",
    "    print(\"embedding_dim:\", embedding_dim)\n",
    "    print(\"num_rnn_node:\", num_rnn_node)\n",
    "    print(\"num_dense_node:\", num_dense_node)\n",
    "    print(\"num_layer:\", num_layer)\n",
    "    print(\"activation_fn:\", activation_fn)\n",
    "    print(\"learning rate: {:.1e}\".format(learning_rate))\n",
    "    print(\"optimizer:\", optimizer)\n",
    "    print(\"margin:\", margin)\n",
    "    print(\"batch_size:\", batch_size)\n",
    "\n",
    "    model = build_model(model_type, embedding_dim, num_rnn_node, num_dense_node, num_layer, activation_fn, learning_rate, optimizer, margin)\n",
    "    params = [model_type, embedding_dim, num_rnn_node, num_dense_node, num_layer, activation_fn, learning_rate, optimizer, margin, batch_size]\n",
    "   \n",
    "    history = model.fit(x=[np.array(x1TrainRnnS), np.array(x2TrainRnnS)],\n",
    "                        y=np.array(yTrainRnnS, dtype=np.float32),\n",
    "                        epochs=35,\n",
    "                        batch_size=batch_size,\n",
    "                        validation_data=([np.array(x1ValRnnS), np.array(x2ValRnnS)], np.array(yValRnnS, dtype=np.float32)),\n",
    "                        )\n",
    "    \n",
    "    loss = history.history['val_loss'][-1]\n",
    "    print(\"Val loss: {0:.6%}\".format(loss))\n",
    "    model_name = \"_\".join([str(a) for a in params]) + f\"{str(loss).replace('.', '_')}.h5\"\n",
    "    model.save(f\"exp3_model/{model_name}\")\n",
    "    del model    \n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3ce27f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = tf.keras.callbacks.ModelCheckpoint(\n",
    "      filepath= \"exp3_model/alstm\" + \"-{epoch:02d}-{val_loss:.2f}.hdf5\",\n",
    "      save_weights_only=True,\n",
    "      monitor='val_loss',\n",
    "      verbose=1,\n",
    "      save_best_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7cd78b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@use_named_args(dimensions=dims)\n",
    "def fitness2(model_type, embedding_dim, num_rnn_node, num_dense_node, num_layer, activation_fn, learning_rate, optimizer, margin, batch_size):\n",
    "    \n",
    "    print(\"model:\", model_type)\n",
    "    print(\"embedding_dim:\", embedding_dim)\n",
    "    print(\"num_rnn_node:\", num_rnn_node)\n",
    "    print(\"num_dense_node:\", num_dense_node)\n",
    "    print(\"num_layer:\", num_layer)\n",
    "    print(\"activation_fn:\", activation_fn)\n",
    "    print(\"learning rate: {:.1e}\".format(learning_rate))\n",
    "    print(\"optimizer:\", optimizer)\n",
    "    print(\"margin:\", margin)\n",
    "    print(\"batch_size:\", batch_size)\n",
    "\n",
    "    model = build_model(model_type, embedding_dim, num_rnn_node, num_dense_node, num_layer, activation_fn, learning_rate, optimizer, margin)\n",
    "    params = [model_type, embedding_dim, num_rnn_node, num_dense_node, num_layer, activation_fn, learning_rate, optimizer, margin, batch_size]\n",
    "   \n",
    "    history = model.fit(x=[np.array(x1TrainRnnS), np.array(x2TrainRnnS)],\n",
    "                        y=np.array(yTrainRnnS, dtype=np.float32),\n",
    "#                         epochs=35,\n",
    "                        epochs=50,\n",
    "                        batch_size=batch_size,\n",
    "                        validation_data=([np.array(x1ValRnnS), np.array(x2ValRnnS)], np.array(yValRnnS, dtype=np.float32)),\n",
    "                        callbacks=[save_model])\n",
    "    \n",
    "    loss = history.history['val_loss'][-1]\n",
    "    print(\"Val loss: {0:.6%}\".format(loss))\n",
    "    model_name = \"_\".join([str(a) for a in params]) + f\"{str(loss).replace('.', '_')}.h5\"\n",
    "    model.save(f\"exp3_model/{model_name}\")\n",
    "    del model    \n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ad79f26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: gru\n",
      "embedding_dim: 64\n",
      "num_rnn_node: 128\n",
      "num_dense_node: 64\n",
      "num_layer: 2\n",
      "activation_fn: tanh\n",
      "learning rate: 1.0e-03\n",
      "optimizer: RMSprop\n",
      "margin: 1\n",
      "batch_size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-01 21:18:44.689736: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-01 21:18:44.691683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:af:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2022-03-01 21:18:44.691776: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-03-01 21:18:44.691811: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-03-01 21:18:44.691834: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-03-01 21:18:44.691856: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-03-01 21:18:44.691877: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-03-01 21:18:44.691899: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-03-01 21:18:44.691920: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-03-01 21:18:44.691943: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-03-01 21:18:44.692461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-03-01 21:18:44.692515: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-03-01 21:18:45.634664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-03-01 21:18:45.634707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-03-01 21:18:45.634717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-03-01 21:18:45.635725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10075 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:af:00.0, compute capability: 7.5)\n",
      "2022-03-01 21:18:45.636234: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-03-01 21:18:48.908629: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-03-01 21:18:48.927342: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 1700000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-01 21:18:56.833596: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-03-01 21:18:57.615030: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/762 [============================>.] - ETA: 0s - loss: 0.1394 - accuracy: 0.8616"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12093/570638347.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfitness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/skopt/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0;31m# Call the wrapped objective function with the named arguments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mobjective_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0marg_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobjective_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_12093/2947689868.py\u001b[0m in \u001b[0;36mfitness\u001b[0;34m(model_type, embedding_dim, num_rnn_node, num_dense_node, num_layer, activation_fn, learning_rate, optimizer, margin, batch_size)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rnn_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_dense_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     history = model.fit(x=[np.array(x1TrainRnnS), np.array(x2TrainRnnS)],\n\u001b[0m\u001b[1;32m     19\u001b[0m                         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myTrainRnnS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1129\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[0;32m-> 1131\u001b[0;31m           val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1132\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m               \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 725\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    726\u001b[0m             *args, **kwds))\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    964\u001b[0m           \u001b[0;31m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m             return autograph.converted_call(\n\u001b[0m\u001b[1;32m    967\u001b[0m                 \u001b[0moriginal_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__test_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    477\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1225\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m   1226\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1257\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1258\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1259\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2728\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2729\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2730\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2732\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3415\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3416\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3417\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3419\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `test_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtest_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1181\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_x_y_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m     \u001b[0;31m# Updates stateful loss metrics.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m     self.compiled_loss(\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \"\"\"\n\u001b[0;32m--> 424\u001b[0;31m     return self._run_internal_graph(\n\u001b[0m\u001b[1;32m    425\u001b[0m         inputs, training=training, mask=mask)\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \"\"\"\n\u001b[0;32m--> 424\u001b[0;31m     return self._run_internal_graph(\n\u001b[0m\u001b[1;32m    425\u001b[0m         inputs, training=training, mask=mask)\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m    468\u001b[0m       \u001b[0mruntime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_runtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_RUNTIME_UNKNOWN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m       last_output, outputs, runtime, states = self._defun_gru_call(\n\u001b[0m\u001b[1;32m    471\u001b[0m           inputs, initial_state, training, mask, row_lengths)\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36m_defun_gru_call\u001b[0;34m(self, inputs, initial_state, training, mask, sequence_lengths)\u001b[0m\n\u001b[1;32m    544\u001b[0m               **normal_gru_kwargs)\n\u001b[1;32m    545\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m         last_output, outputs, new_h, runtime = gru_with_backend_selection(\n\u001b[0m\u001b[1;32m    547\u001b[0m             **normal_gru_kwargs)\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mgru_with_backend_selection\u001b[0;34m(inputs, init_h, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask)\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0;31m# grappler will kick in during session execution to optimize the graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m     \u001b[0mlast_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefun_standard_gru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m     \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefun_gpu_gru\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mlast_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mregister\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3388\u001b[0m   \u001b[0mconcrete_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3389\u001b[0m   \u001b[0mconcrete_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3390\u001b[0;31m   \u001b[0mconcrete_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_gradient_functions_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3391\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mconcrete_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36madd_gradient_functions_to_graph\u001b[0;34m(self, g)\u001b[0m\n\u001b[1;32m   2055\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2056\u001b[0m     forward_function, backward_function = (\n\u001b[0;32m-> 2057\u001b[0;31m         self._delayed_rewrite_functions.forward_backward())\n\u001b[0m\u001b[1;32m   2058\u001b[0m     \u001b[0mforward_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2059\u001b[0m     \u001b[0mbackward_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mforward_backward\u001b[0;34m(self, num_doutputs)\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mforward_backward\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mforward_backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m     \u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_forward_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_doutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_function_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_doutputs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_construct_forward_backward\u001b[0;34m(self, num_doutputs)\u001b[0m\n\u001b[1;32m    672\u001b[0m       backwards_graph = func_graph_module.FuncGraph(\n\u001b[1;32m    673\u001b[0m           _backward_name(self._func_graph.name))\n\u001b[0;32m--> 674\u001b[0;31m       func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    675\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackwards_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m           \u001b[0mpython_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_backprop_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_backprop_function\u001b[0;34m(*grad_ys)\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_backprop_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrad_ys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m         return gradients_util._GradientsHelper(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    666\u001b[0m             \u001b[0mtrainable_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;31m# If grad_fn was found, do not use SymbolicGradient even for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0m\u001b[1;32m    684\u001b[0m                                          lambda: grad_fn(op, *out_grads))\n\u001b[1;32m    685\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Exit early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m   \u001b[0;31m# If the gradients are supposed to be compiled separately, we give them a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    682\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 684\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    685\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/ops/cond_v2.py\u001b[0m in \u001b[0;36m_IfGrad\u001b[0;34m(op, *grads)\u001b[0m\n\u001b[1;32m    124\u001b[0m   true_grad_graph = _create_grad_func(\n\u001b[1;32m    125\u001b[0m       true_graph, grads, util.unique_grad_fn_name(true_graph.name))\n\u001b[0;32m--> 126\u001b[0;31m   false_grad_graph = _create_grad_func(\n\u001b[0m\u001b[1;32m    127\u001b[0m       false_graph, grads, util.unique_grad_fn_name(false_graph.name))\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/ops/cond_v2.py\u001b[0m in \u001b[0;36m_create_grad_func\u001b[0;34m(func_graph, grads, name)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_create_grad_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m   \u001b[0;34m\"\"\"Returns the FuncGraph representation of _grad_fn.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m   return func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    419\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m       \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_grad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/ops/cond_v2.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    418\u001b[0m   return func_graph_module.func_graph_from_py_func(\n\u001b[1;32m    419\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m       \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_grad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m       func_graph=_CondGradFuncGraph(name, func_graph))\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/ops/cond_v2.py\u001b[0m in \u001b[0;36m_grad_fn\u001b[0;34m(func_graph, grads)\u001b[0m\n\u001b[1;32m    407\u001b[0m   \u001b[0;31m# func_graph. The captured func_graph tensors are resolved to external tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m   \u001b[0;31m# in _resolve_grad_inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m   result = gradients_util._GradientsHelper(\n\u001b[0m\u001b[1;32m    410\u001b[0m       \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_ys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_ys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m       src_graph=func_graph)\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Note: we don't filter out eager inputs here because the inputs need to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0;31m# line up with in_grads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_grad\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_Inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0min_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m             if (isinstance(in_grad, ops.Tensor) and\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_Inputs\u001b[0;34m(op, xs_set)\u001b[0m\n\u001b[1;32m    452\u001b[0m       \u001b[0;31m# direct input to op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxs_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_MaybeCaptured\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m       \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fitness(x=default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f4a56f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: gru\n",
      "embedding_dim: 64\n",
      "num_rnn_node: 128\n",
      "num_dense_node: 64\n",
      "num_layer: 2\n",
      "activation_fn: tanh\n",
      "learning rate: 1.0e-03\n",
      "optimizer: RMSprop\n",
      "margin: 1\n",
      "batch_size: 32\n",
      "Epoch 1/35\n",
      "762/762 [==============================] - 26s 21ms/step - loss: 0.1135 - accuracy: 0.8569 - val_loss: 0.0903 - val_accuracy: 0.8625\n",
      "Epoch 2/35\n",
      "762/762 [==============================] - 13s 17ms/step - loss: 0.0903 - accuracy: 0.8599 - val_loss: 0.0828 - val_accuracy: 0.8696\n",
      "Epoch 3/35\n",
      "762/762 [==============================] - 13s 18ms/step - loss: 0.0801 - accuracy: 0.8895 - val_loss: 0.0712 - val_accuracy: 0.9207\n",
      "Epoch 4/35\n",
      "762/762 [==============================] - 13s 18ms/step - loss: 0.0703 - accuracy: 0.9223 - val_loss: 0.0623 - val_accuracy: 0.9369\n",
      "Epoch 5/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0587 - accuracy: 0.9395 - val_loss: 0.0562 - val_accuracy: 0.9404\n",
      "Epoch 6/35\n",
      "762/762 [==============================] - 13s 18ms/step - loss: 0.0518 - accuracy: 0.9469 - val_loss: 0.0480 - val_accuracy: 0.9476\n",
      "Epoch 7/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0435 - accuracy: 0.9538 - val_loss: 0.0427 - val_accuracy: 0.9547\n",
      "Epoch 8/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0394 - accuracy: 0.9588 - val_loss: 0.0388 - val_accuracy: 0.9576\n",
      "Epoch 9/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0321 - accuracy: 0.9658 - val_loss: 0.0359 - val_accuracy: 0.9609\n",
      "Epoch 10/35\n",
      "762/762 [==============================] - 13s 18ms/step - loss: 0.0280 - accuracy: 0.9700 - val_loss: 0.0294 - val_accuracy: 0.9676\n",
      "Epoch 11/35\n",
      "762/762 [==============================] - 13s 17ms/step - loss: 0.0239 - accuracy: 0.9760 - val_loss: 0.0272 - val_accuracy: 0.9708\n",
      "Epoch 12/35\n",
      "762/762 [==============================] - 13s 18ms/step - loss: 0.0196 - accuracy: 0.9805 - val_loss: 0.0252 - val_accuracy: 0.9726\n",
      "Epoch 13/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0186 - accuracy: 0.9826 - val_loss: 0.0227 - val_accuracy: 0.9759\n",
      "Epoch 14/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0153 - accuracy: 0.9856 - val_loss: 0.0217 - val_accuracy: 0.9764\n",
      "Epoch 15/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0130 - accuracy: 0.9881 - val_loss: 0.0201 - val_accuracy: 0.9775\n",
      "Epoch 16/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0116 - accuracy: 0.9890 - val_loss: 0.0217 - val_accuracy: 0.9767\n",
      "Epoch 17/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0113 - accuracy: 0.9891 - val_loss: 0.0185 - val_accuracy: 0.9782\n",
      "Epoch 18/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0110 - accuracy: 0.9890 - val_loss: 0.0181 - val_accuracy: 0.9808\n",
      "Epoch 19/35\n",
      "762/762 [==============================] - 13s 18ms/step - loss: 0.0098 - accuracy: 0.9898 - val_loss: 0.0184 - val_accuracy: 0.9793\n",
      "Epoch 20/35\n",
      "762/762 [==============================] - 13s 17ms/step - loss: 0.0090 - accuracy: 0.9910 - val_loss: 0.0189 - val_accuracy: 0.9788\n",
      "Epoch 21/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0088 - accuracy: 0.9909 - val_loss: 0.0171 - val_accuracy: 0.9805\n",
      "Epoch 22/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0084 - accuracy: 0.9907 - val_loss: 0.0174 - val_accuracy: 0.9800\n",
      "Epoch 23/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0081 - accuracy: 0.9916 - val_loss: 0.0166 - val_accuracy: 0.9816\n",
      "Epoch 24/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0083 - accuracy: 0.9911 - val_loss: 0.0166 - val_accuracy: 0.9809\n",
      "Epoch 25/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0073 - accuracy: 0.9923 - val_loss: 0.0164 - val_accuracy: 0.9800\n",
      "Epoch 26/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0072 - accuracy: 0.9922 - val_loss: 0.0159 - val_accuracy: 0.9805\n",
      "Epoch 27/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0072 - accuracy: 0.9920 - val_loss: 0.0148 - val_accuracy: 0.9816\n",
      "Epoch 28/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0065 - accuracy: 0.9927 - val_loss: 0.0149 - val_accuracy: 0.9831\n",
      "Epoch 29/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0066 - accuracy: 0.9929 - val_loss: 0.0159 - val_accuracy: 0.9816\n",
      "Epoch 30/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0062 - accuracy: 0.9927 - val_loss: 0.0150 - val_accuracy: 0.9819\n",
      "Epoch 31/35\n",
      "762/762 [==============================] - 16s 20ms/step - loss: 0.0062 - accuracy: 0.9924 - val_loss: 0.0152 - val_accuracy: 0.9824\n",
      "Epoch 32/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0055 - accuracy: 0.9938 - val_loss: 0.0153 - val_accuracy: 0.9819\n",
      "Epoch 33/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0062 - accuracy: 0.9924 - val_loss: 0.0146 - val_accuracy: 0.9811\n",
      "Epoch 34/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0060 - accuracy: 0.9932 - val_loss: 0.0144 - val_accuracy: 0.9828\n",
      "Epoch 35/35\n",
      "762/762 [==============================] - 14s 18ms/step - loss: 0.0056 - accuracy: 0.9934 - val_loss: 0.0146 - val_accuracy: 0.9821\n",
      "Val loss: 1.458742%\n",
      "model: gru\n",
      "embedding_dim: 341\n",
      "num_rnn_node: 812\n",
      "num_dense_node: 104\n",
      "num_layer: 3\n",
      "activation_fn: tanh\n",
      "learning rate: 1.3e-05\n",
      "optimizer: Adam\n",
      "margin: 0.7641258929556295\n",
      "batch_size: 27\n",
      "Epoch 1/35\n",
      "903/903 [==============================] - 43s 37ms/step - loss: 0.0796 - accuracy: 0.8570 - val_loss: 0.0732 - val_accuracy: 0.8625\n",
      "Epoch 2/35\n",
      "903/903 [==============================] - 31s 34ms/step - loss: 0.0708 - accuracy: 0.8585 - val_loss: 0.0703 - val_accuracy: 0.8625\n",
      "Epoch 3/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0694 - accuracy: 0.8555 - val_loss: 0.0694 - val_accuracy: 0.8625\n",
      "Epoch 4/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0669 - accuracy: 0.8582 - val_loss: 0.0674 - val_accuracy: 0.8625\n",
      "Epoch 5/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0653 - accuracy: 0.8604 - val_loss: 0.0667 - val_accuracy: 0.8625\n",
      "Epoch 6/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0642 - accuracy: 0.8604 - val_loss: 0.0649 - val_accuracy: 0.8625\n",
      "Epoch 7/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0633 - accuracy: 0.8569 - val_loss: 0.0640 - val_accuracy: 0.8625\n",
      "Epoch 8/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0607 - accuracy: 0.8641 - val_loss: 0.0627 - val_accuracy: 0.8625\n",
      "Epoch 9/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0605 - accuracy: 0.8580 - val_loss: 0.0610 - val_accuracy: 0.8625\n",
      "Epoch 10/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0585 - accuracy: 0.8656 - val_loss: 0.0597 - val_accuracy: 0.8625\n",
      "Epoch 11/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0583 - accuracy: 0.8568 - val_loss: 0.0584 - val_accuracy: 0.8625\n",
      "Epoch 12/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0581 - accuracy: 0.8563 - val_loss: 0.0584 - val_accuracy: 0.8625\n",
      "Epoch 13/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0563 - accuracy: 0.8573 - val_loss: 0.0563 - val_accuracy: 0.8625\n",
      "Epoch 14/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0549 - accuracy: 0.8584 - val_loss: 0.0556 - val_accuracy: 0.8625\n",
      "Epoch 15/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0532 - accuracy: 0.8602 - val_loss: 0.0552 - val_accuracy: 0.8625\n",
      "Epoch 16/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0544 - accuracy: 0.8557 - val_loss: 0.0537 - val_accuracy: 0.8625\n",
      "Epoch 17/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0509 - accuracy: 0.8613 - val_loss: 0.0523 - val_accuracy: 0.8625\n",
      "Epoch 18/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0505 - accuracy: 0.8631 - val_loss: 0.0516 - val_accuracy: 0.8625\n",
      "Epoch 19/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0503 - accuracy: 0.8601 - val_loss: 0.0513 - val_accuracy: 0.8625\n",
      "Epoch 20/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0500 - accuracy: 0.8586 - val_loss: 0.0503 - val_accuracy: 0.8625\n",
      "Epoch 21/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0495 - accuracy: 0.8557 - val_loss: 0.0497 - val_accuracy: 0.8625\n",
      "Epoch 22/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0502 - accuracy: 0.8534 - val_loss: 0.0495 - val_accuracy: 0.8625\n",
      "Epoch 23/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0476 - accuracy: 0.8609 - val_loss: 0.0488 - val_accuracy: 0.8625\n",
      "Epoch 24/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0480 - accuracy: 0.8578 - val_loss: 0.0486 - val_accuracy: 0.8625\n",
      "Epoch 25/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0460 - accuracy: 0.8626 - val_loss: 0.0481 - val_accuracy: 0.8625\n",
      "Epoch 26/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0470 - accuracy: 0.8592 - val_loss: 0.0474 - val_accuracy: 0.8625\n",
      "Epoch 27/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0465 - accuracy: 0.8584 - val_loss: 0.0474 - val_accuracy: 0.8625\n",
      "Epoch 28/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0466 - accuracy: 0.8559 - val_loss: 0.0467 - val_accuracy: 0.8625\n",
      "Epoch 29/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0460 - accuracy: 0.8592 - val_loss: 0.0464 - val_accuracy: 0.8625\n",
      "Epoch 30/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0453 - accuracy: 0.8583 - val_loss: 0.0465 - val_accuracy: 0.8625\n",
      "Epoch 31/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0451 - accuracy: 0.8545 - val_loss: 0.0463 - val_accuracy: 0.8625\n",
      "Epoch 32/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0447 - accuracy: 0.8594 - val_loss: 0.0458 - val_accuracy: 0.8625\n",
      "Epoch 33/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0438 - accuracy: 0.8601 - val_loss: 0.0454 - val_accuracy: 0.8625\n",
      "Epoch 34/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0436 - accuracy: 0.8591 - val_loss: 0.0458 - val_accuracy: 0.8625\n",
      "Epoch 35/35\n",
      "903/903 [==============================] - 30s 33ms/step - loss: 0.0440 - accuracy: 0.8611 - val_loss: 0.0448 - val_accuracy: 0.8625\n",
      "Val loss: 4.478208%\n",
      "model: gru\n",
      "embedding_dim: 100\n",
      "num_rnn_node: 288\n",
      "num_dense_node: 86\n",
      "num_layer: 2\n",
      "activation_fn: relu\n",
      "learning rate: 7.2e-05\n",
      "optimizer: Adam\n",
      "margin: 0.3399274385625292\n",
      "batch_size: 13\n",
      "Epoch 1/35\n",
      "1874/1874 [==============================] - 41s 17ms/step - loss: nan - accuracy: 0.8595 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 2/35\n",
      "1874/1874 [==============================] - 29s 15ms/step - loss: nan - accuracy: 0.8621 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 3/35\n",
      "1874/1874 [==============================] - 28s 15ms/step - loss: nan - accuracy: 0.8589 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 4/35\n",
      "1874/1874 [==============================] - 28s 15ms/step - loss: nan - accuracy: 0.8589 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 5/35\n",
      "1874/1874 [==============================] - 29s 15ms/step - loss: nan - accuracy: 0.8551 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 6/35\n",
      "1874/1874 [==============================] - 28s 15ms/step - loss: nan - accuracy: 0.8544 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 7/35\n",
      "1874/1874 [==============================] - 28s 15ms/step - loss: nan - accuracy: 0.8581 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 8/35\n",
      "1874/1874 [==============================] - 28s 15ms/step - loss: nan - accuracy: 0.8587 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 9/35\n",
      "1874/1874 [==============================] - 28s 15ms/step - loss: nan - accuracy: 0.8592 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 10/35\n",
      "1874/1874 [==============================] - 28s 15ms/step - loss: nan - accuracy: 0.8582 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 11/35\n",
      "1874/1874 [==============================] - 28s 15ms/step - loss: nan - accuracy: 0.8607 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 12/35\n",
      "1874/1874 [==============================] - 28s 15ms/step - loss: nan - accuracy: 0.8614 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 13/35\n",
      "1874/1874 [==============================] - 29s 15ms/step - loss: nan - accuracy: 0.8583 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 14/35\n",
      "1874/1874 [==============================] - 28s 15ms/step - loss: nan - accuracy: 0.8565 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 15/35\n",
      "1874/1874 [==============================] - 29s 15ms/step - loss: nan - accuracy: 0.8582 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 16/35\n",
      "1874/1874 [==============================] - 29s 15ms/step - loss: nan - accuracy: 0.8593 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 17/35\n",
      "1874/1874 [==============================] - 29s 15ms/step - loss: nan - accuracy: 0.8589 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 18/35\n",
      "1874/1874 [==============================] - 28s 15ms/step - loss: nan - accuracy: 0.8574 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 19/35\n",
      "1874/1874 [==============================] - 28s 15ms/step - loss: nan - accuracy: 0.8598 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 20/35\n",
      "1874/1874 [==============================] - 29s 15ms/step - loss: nan - accuracy: 0.8575 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 21/35\n",
      "1874/1874 [==============================] - 29s 15ms/step - loss: nan - accuracy: 0.8570 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 22/35\n",
      "1874/1874 [==============================] - 28s 15ms/step - loss: nan - accuracy: 0.8599 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 23/35\n",
      "1874/1874 [==============================] - 28s 15ms/step - loss: nan - accuracy: 0.8571 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 24/35\n",
      "1874/1874 [==============================] - 29s 15ms/step - loss: nan - accuracy: 0.8549 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 25/35\n",
      "1874/1874 [==============================] - 28s 15ms/step - loss: nan - accuracy: 0.8621 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 26/35\n",
      "1874/1874 [==============================] - 29s 15ms/step - loss: nan - accuracy: 0.8611 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 27/35\n",
      "1874/1874 [==============================] - 29s 15ms/step - loss: nan - accuracy: 0.8591 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 28/35\n",
      "1874/1874 [==============================] - 29s 15ms/step - loss: nan - accuracy: 0.8565 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 29/35\n",
      "1874/1874 [==============================] - 28s 15ms/step - loss: nan - accuracy: 0.8610 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 30/35\n",
      "1874/1874 [==============================] - 29s 15ms/step - loss: nan - accuracy: 0.8579 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 31/35\n",
      "1874/1874 [==============================] - 29s 15ms/step - loss: nan - accuracy: 0.8568 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 32/35\n",
      "1874/1874 [==============================] - 29s 15ms/step - loss: nan - accuracy: 0.8615 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 33/35\n",
      "1874/1874 [==============================] - 29s 15ms/step - loss: nan - accuracy: 0.8571 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 34/35\n",
      "1874/1874 [==============================] - 29s 15ms/step - loss: nan - accuracy: 0.8584 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 35/35\n",
      "1874/1874 [==============================] - 28s 15ms/step - loss: nan - accuracy: 0.8656 - val_loss: nan - val_accuracy: 0.8625\n",
      "Val loss: nan%\n",
      "model: gru\n",
      "embedding_dim: 186\n",
      "num_rnn_node: 960\n",
      "num_dense_node: 138\n",
      "num_layer: 5\n",
      "activation_fn: relu\n",
      "learning rate: 2.4e-02\n",
      "optimizer: RMSprop\n",
      "margin: 0.34085568379006337\n",
      "batch_size: 22\n",
      "Epoch 1/35\n",
      "1108/1108 [==============================] - 43s 29ms/step - loss: nan - accuracy: 0.8595 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 2/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8589 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 3/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8542 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 4/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8580 - val_loss: nan - val_accuracy: 0.8625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8550 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 6/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8616 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 7/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8584 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 8/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8591 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 9/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8547 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 10/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8608 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 11/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8611 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 12/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8576 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 13/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8603 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 14/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8555 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 15/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8571 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 16/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8595 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 17/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8600 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 18/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8567 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 19/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8619 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 20/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8553 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 21/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8555 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 22/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8565 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 23/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8605 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 24/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8605 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 25/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8558 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 26/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8537 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 27/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8572 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 28/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8571 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 29/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8586 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 30/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8553 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 31/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8566 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 32/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8528 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 33/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8565 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 34/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8567 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 35/35\n",
      "1108/1108 [==============================] - 30s 27ms/step - loss: nan - accuracy: 0.8620 - val_loss: nan - val_accuracy: 0.8625\n",
      "Val loss: nan%\n",
      "model: gru\n",
      "embedding_dim: 298\n",
      "num_rnn_node: 487\n",
      "num_dense_node: 296\n",
      "num_layer: 5\n",
      "activation_fn: tanh\n",
      "learning rate: 1.2e-05\n",
      "optimizer: RMSprop\n",
      "margin: 0.7410748244368253\n",
      "batch_size: 7\n",
      "Epoch 1/35\n",
      "3480/3480 [==============================] - 74s 18ms/step - loss: 0.2231 - accuracy: 0.7327 - val_loss: 0.2154 - val_accuracy: 0.8625\n",
      "Epoch 2/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.2118 - accuracy: 0.8538 - val_loss: 0.2074 - val_accuracy: 0.8625\n",
      "Epoch 3/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.2051 - accuracy: 0.8604 - val_loss: 0.1996 - val_accuracy: 0.8625\n",
      "Epoch 4/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.1968 - accuracy: 0.8562 - val_loss: 0.1921 - val_accuracy: 0.8625\n",
      "Epoch 5/35\n",
      "3480/3480 [==============================] - 61s 18ms/step - loss: 0.1899 - accuracy: 0.8597 - val_loss: 0.1849 - val_accuracy: 0.8625\n",
      "Epoch 6/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.1826 - accuracy: 0.8582 - val_loss: 0.1779 - val_accuracy: 0.8625\n",
      "Epoch 7/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.1757 - accuracy: 0.8573 - val_loss: 0.1712 - val_accuracy: 0.8625\n",
      "Epoch 8/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.1692 - accuracy: 0.8590 - val_loss: 0.1647 - val_accuracy: 0.8625\n",
      "Epoch 9/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.1632 - accuracy: 0.8629 - val_loss: 0.1585 - val_accuracy: 0.8625\n",
      "Epoch 10/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.1567 - accuracy: 0.8577 - val_loss: 0.1526 - val_accuracy: 0.8625\n",
      "Epoch 11/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.1510 - accuracy: 0.8601 - val_loss: 0.1469 - val_accuracy: 0.8625\n",
      "Epoch 12/35\n",
      "3480/3480 [==============================] - 61s 18ms/step - loss: 0.1456 - accuracy: 0.8654 - val_loss: 0.1415 - val_accuracy: 0.8625\n",
      "Epoch 13/35\n",
      "3480/3480 [==============================] - 61s 18ms/step - loss: 0.1401 - accuracy: 0.8578 - val_loss: 0.1363 - val_accuracy: 0.8625\n",
      "Epoch 14/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.1351 - accuracy: 0.8573 - val_loss: 0.1314 - val_accuracy: 0.8625\n",
      "Epoch 15/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.1303 - accuracy: 0.8599 - val_loss: 0.1268 - val_accuracy: 0.8625\n",
      "Epoch 16/35\n",
      "3480/3480 [==============================] - 61s 18ms/step - loss: 0.1258 - accuracy: 0.8599 - val_loss: 0.1224 - val_accuracy: 0.8625\n",
      "Epoch 17/35\n",
      "3480/3480 [==============================] - 61s 18ms/step - loss: 0.1216 - accuracy: 0.8569 - val_loss: 0.1182 - val_accuracy: 0.8625\n",
      "Epoch 18/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.1172 - accuracy: 0.8621 - val_loss: 0.1143 - val_accuracy: 0.8625\n",
      "Epoch 19/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.1136 - accuracy: 0.8589 - val_loss: 0.1106 - val_accuracy: 0.8625\n",
      "Epoch 20/35\n",
      "3480/3480 [==============================] - 61s 18ms/step - loss: 0.1100 - accuracy: 0.8589 - val_loss: 0.1071 - val_accuracy: 0.8625\n",
      "Epoch 21/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.1071 - accuracy: 0.8540 - val_loss: 0.1038 - val_accuracy: 0.8625\n",
      "Epoch 22/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.1030 - accuracy: 0.8627 - val_loss: 0.1007 - val_accuracy: 0.8625\n",
      "Epoch 23/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.1005 - accuracy: 0.8590 - val_loss: 0.0979 - val_accuracy: 0.8625\n",
      "Epoch 24/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.0975 - accuracy: 0.8600 - val_loss: 0.0952 - val_accuracy: 0.8625\n",
      "Epoch 25/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.0956 - accuracy: 0.8553 - val_loss: 0.0927 - val_accuracy: 0.8625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.0924 - accuracy: 0.8608 - val_loss: 0.0904 - val_accuracy: 0.8625\n",
      "Epoch 27/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.0903 - accuracy: 0.8599 - val_loss: 0.0883 - val_accuracy: 0.8625\n",
      "Epoch 28/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.0884 - accuracy: 0.8592 - val_loss: 0.0863 - val_accuracy: 0.8625\n",
      "Epoch 29/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.0862 - accuracy: 0.8606 - val_loss: 0.0845 - val_accuracy: 0.8625\n",
      "Epoch 30/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.0854 - accuracy: 0.8557 - val_loss: 0.0828 - val_accuracy: 0.8625\n",
      "Epoch 31/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.0826 - accuracy: 0.8616 - val_loss: 0.0812 - val_accuracy: 0.8625\n",
      "Epoch 32/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.0821 - accuracy: 0.8567 - val_loss: 0.0797 - val_accuracy: 0.8625\n",
      "Epoch 33/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.0802 - accuracy: 0.8589 - val_loss: 0.0784 - val_accuracy: 0.8625\n",
      "Epoch 34/35\n",
      "3480/3480 [==============================] - 61s 18ms/step - loss: 0.0801 - accuracy: 0.8537 - val_loss: 0.0772 - val_accuracy: 0.8625\n",
      "Epoch 35/35\n",
      "3480/3480 [==============================] - 62s 18ms/step - loss: 0.0784 - accuracy: 0.8564 - val_loss: 0.0761 - val_accuracy: 0.8625\n",
      "Val loss: 7.608715%\n",
      "model: lstm\n",
      "embedding_dim: 86\n",
      "num_rnn_node: 367\n",
      "num_dense_node: 82\n",
      "num_layer: 1\n",
      "activation_fn: relu\n",
      "learning rate: 6.9e-03\n",
      "optimizer: RMSprop\n",
      "margin: 0.46990900738124386\n",
      "batch_size: 9\n",
      "Epoch 1/35\n",
      "2707/2707 [==============================] - 54s 17ms/step - loss: nan - accuracy: 0.8575 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 2/35\n",
      "2707/2707 [==============================] - 42s 16ms/step - loss: nan - accuracy: 0.8588 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 3/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8567 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 4/35\n",
      "2707/2707 [==============================] - 42s 16ms/step - loss: nan - accuracy: 0.8614 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 5/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8581 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 6/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8593 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 7/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8577 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 8/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8572 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 9/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8606 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 10/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8596 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 11/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8550 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 12/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8598 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 13/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8602 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 14/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8555 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 15/35\n",
      "2707/2707 [==============================] - 42s 16ms/step - loss: nan - accuracy: 0.8596 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 16/35\n",
      "2707/2707 [==============================] - 42s 16ms/step - loss: nan - accuracy: 0.8592 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 17/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8535 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 18/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8584 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 19/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8596 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 20/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8649 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 21/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8606 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 22/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8626 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 23/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8620 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 24/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8594 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 25/35\n",
      "2707/2707 [==============================] - 42s 16ms/step - loss: nan - accuracy: 0.8576 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 26/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8542 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 27/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8563 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 28/35\n",
      "2707/2707 [==============================] - 42s 16ms/step - loss: nan - accuracy: 0.8578 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 29/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8538 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 30/35\n",
      "2707/2707 [==============================] - 42s 16ms/step - loss: nan - accuracy: 0.8589 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 31/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8566 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 32/35\n",
      "2707/2707 [==============================] - 43s 16ms/step - loss: nan - accuracy: 0.8576 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 33/35\n",
      "2707/2707 [==============================] - 42s 16ms/step - loss: nan - accuracy: 0.8578 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 34/35\n",
      "2707/2707 [==============================] - 42s 16ms/step - loss: nan - accuracy: 0.8565 - val_loss: nan - val_accuracy: 0.8625\n",
      "Epoch 35/35\n",
      "2707/2707 [==============================] - 42s 16ms/step - loss: nan - accuracy: 0.8590 - val_loss: nan - val_accuracy: 0.8625\n",
      "Val loss: nan%\n",
      "model: lstm\n",
      "embedding_dim: 245\n",
      "num_rnn_node: 302\n",
      "num_dense_node: 282\n",
      "num_layer: 1\n",
      "activation_fn: tanh\n",
      "learning rate: 2.2e-04\n",
      "optimizer: Adam\n",
      "margin: 0.8154229123971033\n",
      "batch_size: 4\n",
      "Epoch 1/35\n",
      "6089/6089 [==============================] - 94s 14ms/step - loss: 0.1839 - accuracy: 0.8339 - val_loss: 0.1025 - val_accuracy: 0.8625\n",
      "Epoch 2/35\n",
      "6089/6089 [==============================] - 81s 13ms/step - loss: 0.0951 - accuracy: 0.8592 - val_loss: 0.0816 - val_accuracy: 0.8625\n",
      "Epoch 3/35\n",
      "6089/6089 [==============================] - 81s 13ms/step - loss: 0.0839 - accuracy: 0.8547 - val_loss: 0.0792 - val_accuracy: 0.8625\n",
      "Epoch 4/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0794 - accuracy: 0.8620 - val_loss: 0.0789 - val_accuracy: 0.8625\n",
      "Epoch 5/35\n",
      "6089/6089 [==============================] - 81s 13ms/step - loss: 0.0809 - accuracy: 0.8582 - val_loss: 0.0789 - val_accuracy: 0.8625\n",
      "Epoch 6/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0817 - accuracy: 0.8564 - val_loss: 0.0776 - val_accuracy: 0.8625\n",
      "Epoch 7/35\n",
      "6089/6089 [==============================] - 81s 13ms/step - loss: 0.0797 - accuracy: 0.8559 - val_loss: 0.0752 - val_accuracy: 0.8625\n",
      "Epoch 8/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0786 - accuracy: 0.8601 - val_loss: 0.0785 - val_accuracy: 0.8625\n",
      "Epoch 9/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0808 - accuracy: 0.8563 - val_loss: 0.0738 - val_accuracy: 0.8625\n",
      "Epoch 10/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0749 - accuracy: 0.8586 - val_loss: 0.0739 - val_accuracy: 0.8625\n",
      "Epoch 11/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0764 - accuracy: 0.8588 - val_loss: 0.0770 - val_accuracy: 0.8625\n",
      "Epoch 12/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0727 - accuracy: 0.8651 - val_loss: 0.0690 - val_accuracy: 0.8730\n",
      "Epoch 13/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0709 - accuracy: 0.8691 - val_loss: 0.0720 - val_accuracy: 0.8666\n",
      "Epoch 14/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0708 - accuracy: 0.8683 - val_loss: 0.0660 - val_accuracy: 0.8822\n",
      "Epoch 15/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0669 - accuracy: 0.8754 - val_loss: 0.0647 - val_accuracy: 0.8877\n",
      "Epoch 16/35\n",
      "6089/6089 [==============================] - 82s 14ms/step - loss: 0.0652 - accuracy: 0.8800 - val_loss: 0.0625 - val_accuracy: 0.8801\n",
      "Epoch 17/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0635 - accuracy: 0.8830 - val_loss: 0.0615 - val_accuracy: 0.8890\n",
      "Epoch 18/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0614 - accuracy: 0.8907 - val_loss: 0.0601 - val_accuracy: 0.8852\n",
      "Epoch 19/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0579 - accuracy: 0.8978 - val_loss: 0.0584 - val_accuracy: 0.8982\n",
      "Epoch 20/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0561 - accuracy: 0.9023 - val_loss: 0.0555 - val_accuracy: 0.8993\n",
      "Epoch 21/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0530 - accuracy: 0.9072 - val_loss: 0.0549 - val_accuracy: 0.9031\n",
      "Epoch 22/35\n",
      "6089/6089 [==============================] - 81s 13ms/step - loss: 0.0505 - accuracy: 0.9127 - val_loss: 0.0518 - val_accuracy: 0.9113\n",
      "Epoch 23/35\n",
      "6089/6089 [==============================] - 81s 13ms/step - loss: 0.0481 - accuracy: 0.9200 - val_loss: 0.0501 - val_accuracy: 0.9136\n",
      "Epoch 24/35\n",
      "6089/6089 [==============================] - 81s 13ms/step - loss: 0.0472 - accuracy: 0.9223 - val_loss: 0.0496 - val_accuracy: 0.9208\n",
      "Epoch 25/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0436 - accuracy: 0.9277 - val_loss: 0.0475 - val_accuracy: 0.9194\n",
      "Epoch 26/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0414 - accuracy: 0.9324 - val_loss: 0.0466 - val_accuracy: 0.9159\n",
      "Epoch 27/35\n",
      "6089/6089 [==============================] - 81s 13ms/step - loss: 0.0389 - accuracy: 0.9362 - val_loss: 0.0474 - val_accuracy: 0.9261\n",
      "Epoch 28/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0377 - accuracy: 0.9384 - val_loss: 0.0455 - val_accuracy: 0.9277\n",
      "Epoch 29/35\n",
      "6089/6089 [==============================] - 81s 13ms/step - loss: 0.0348 - accuracy: 0.9445 - val_loss: 0.0439 - val_accuracy: 0.9277\n",
      "Epoch 30/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0353 - accuracy: 0.9427 - val_loss: 0.0429 - val_accuracy: 0.9272\n",
      "Epoch 31/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0331 - accuracy: 0.9476 - val_loss: 0.0419 - val_accuracy: 0.9341\n",
      "Epoch 32/35\n",
      "6089/6089 [==============================] - 83s 14ms/step - loss: 0.0316 - accuracy: 0.9503 - val_loss: 0.0411 - val_accuracy: 0.9337\n",
      "Epoch 33/35\n",
      "6089/6089 [==============================] - 82s 13ms/step - loss: 0.0293 - accuracy: 0.9543 - val_loss: 0.0407 - val_accuracy: 0.9320\n",
      "Epoch 34/35\n",
      "6089/6089 [==============================] - 82s 14ms/step - loss: 0.0278 - accuracy: 0.9575 - val_loss: 0.0396 - val_accuracy: 0.9348\n",
      "Epoch 35/35\n",
      "6089/6089 [==============================] - 82s 14ms/step - loss: 0.0275 - accuracy: 0.9596 - val_loss: 0.0382 - val_accuracy: 0.9374\n",
      "Val loss: 3.824718%\n",
      "model: lstm\n",
      "embedding_dim: 227\n",
      "num_rnn_node: 453\n",
      "num_dense_node: 79\n",
      "num_layer: 5\n",
      "activation_fn: relu\n",
      "learning rate: 2.1e-05\n",
      "optimizer: Adam\n",
      "margin: 0.7813060982585048\n",
      "batch_size: 26\n",
      "Epoch 1/35\n",
      "937/937 [==============================] - 36s 28ms/step - loss: 0.2244 - accuracy: 0.8003 - val_loss: 0.2227 - val_accuracy: 0.8625\n",
      "Epoch 2/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.2214 - accuracy: 0.8600 - val_loss: 0.2190 - val_accuracy: 0.8625\n",
      "Epoch 3/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.2179 - accuracy: 0.8610 - val_loss: 0.2154 - val_accuracy: 0.8625\n",
      "Epoch 4/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.2143 - accuracy: 0.8613 - val_loss: 0.2118 - val_accuracy: 0.8625\n",
      "Epoch 5/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.2098 - accuracy: 0.8544 - val_loss: 0.2083 - val_accuracy: 0.8625\n",
      "Epoch 6/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.2066 - accuracy: 0.8561 - val_loss: 0.2048 - val_accuracy: 0.8625\n",
      "Epoch 7/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.2034 - accuracy: 0.8578 - val_loss: 0.2014 - val_accuracy: 0.8625\n",
      "Epoch 8/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.2006 - accuracy: 0.8631 - val_loss: 0.1980 - val_accuracy: 0.8625\n",
      "Epoch 9/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1963 - accuracy: 0.8549 - val_loss: 0.1947 - val_accuracy: 0.8625\n",
      "Epoch 10/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1934 - accuracy: 0.8575 - val_loss: 0.1914 - val_accuracy: 0.8625\n",
      "Epoch 11/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1900 - accuracy: 0.8565 - val_loss: 0.1882 - val_accuracy: 0.8625\n",
      "Epoch 12/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1875 - accuracy: 0.8632 - val_loss: 0.1850 - val_accuracy: 0.8625\n",
      "Epoch 13/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1839 - accuracy: 0.8579 - val_loss: 0.1819 - val_accuracy: 0.8625\n",
      "Epoch 14/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1807 - accuracy: 0.8569 - val_loss: 0.1789 - val_accuracy: 0.8625\n",
      "Epoch 15/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1778 - accuracy: 0.8583 - val_loss: 0.1759 - val_accuracy: 0.8625\n",
      "Epoch 16/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1749 - accuracy: 0.8593 - val_loss: 0.1729 - val_accuracy: 0.8625\n",
      "Epoch 17/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1720 - accuracy: 0.8585 - val_loss: 0.1700 - val_accuracy: 0.8625\n",
      "Epoch 18/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1691 - accuracy: 0.8577 - val_loss: 0.1672 - val_accuracy: 0.8625\n",
      "Epoch 19/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1664 - accuracy: 0.8614 - val_loss: 0.1644 - val_accuracy: 0.8625\n",
      "Epoch 20/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1636 - accuracy: 0.8602 - val_loss: 0.1616 - val_accuracy: 0.8625\n",
      "Epoch 21/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1608 - accuracy: 0.8573 - val_loss: 0.1589 - val_accuracy: 0.8625\n",
      "Epoch 22/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1582 - accuracy: 0.8554 - val_loss: 0.1563 - val_accuracy: 0.8625\n",
      "Epoch 23/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1556 - accuracy: 0.8575 - val_loss: 0.1537 - val_accuracy: 0.8625\n",
      "Epoch 24/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1531 - accuracy: 0.8579 - val_loss: 0.1512 - val_accuracy: 0.8625\n",
      "Epoch 25/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1506 - accuracy: 0.8588 - val_loss: 0.1487 - val_accuracy: 0.8625\n",
      "Epoch 26/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1482 - accuracy: 0.8588 - val_loss: 0.1463 - val_accuracy: 0.8625\n",
      "Epoch 27/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1458 - accuracy: 0.8594 - val_loss: 0.1439 - val_accuracy: 0.8625\n",
      "Epoch 28/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1434 - accuracy: 0.8611 - val_loss: 0.1416 - val_accuracy: 0.8625\n",
      "Epoch 29/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1412 - accuracy: 0.8584 - val_loss: 0.1393 - val_accuracy: 0.8625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1389 - accuracy: 0.8583 - val_loss: 0.1371 - val_accuracy: 0.8625\n",
      "Epoch 31/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1366 - accuracy: 0.8610 - val_loss: 0.1349 - val_accuracy: 0.8625\n",
      "Epoch 32/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1346 - accuracy: 0.8595 - val_loss: 0.1328 - val_accuracy: 0.8625\n",
      "Epoch 33/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1326 - accuracy: 0.8575 - val_loss: 0.1308 - val_accuracy: 0.8625\n",
      "Epoch 34/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1305 - accuracy: 0.8586 - val_loss: 0.1287 - val_accuracy: 0.8625\n",
      "Epoch 35/35\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.1284 - accuracy: 0.8611 - val_loss: 0.1268 - val_accuracy: 0.8625\n",
      "Val loss: 12.677984%\n",
      "model: gru\n",
      "embedding_dim: 112\n",
      "num_rnn_node: 144\n",
      "num_dense_node: 88\n",
      "num_layer: 4\n",
      "activation_fn: relu\n",
      "learning rate: 8.0e-03\n",
      "optimizer: Adam\n",
      "margin: 0.5770310679648518\n",
      "batch_size: 38\n",
      "Epoch 1/35\n",
      "641/641 [==============================] - 26s 27ms/step - loss: 0.1065 - accuracy: 0.8455 - val_loss: 0.0410 - val_accuracy: 0.8625\n",
      "Epoch 2/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0412 - accuracy: 0.8585 - val_loss: 0.0396 - val_accuracy: 0.8625\n",
      "Epoch 3/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0398 - accuracy: 0.8614 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 4/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0405 - accuracy: 0.8585 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 5/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0397 - accuracy: 0.8615 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 6/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0403 - accuracy: 0.8591 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 7/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0415 - accuracy: 0.8542 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 8/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0409 - accuracy: 0.8567 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 9/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0406 - accuracy: 0.8579 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 10/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0411 - accuracy: 0.8556 - val_loss: 0.0390 - val_accuracy: 0.8625\n",
      "Epoch 11/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0413 - accuracy: 0.8529 - val_loss: 0.0391 - val_accuracy: 0.8625\n",
      "Epoch 12/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0401 - accuracy: 0.8582 - val_loss: 0.0390 - val_accuracy: 0.8625\n",
      "Epoch 13/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0397 - accuracy: 0.8603 - val_loss: 0.0391 - val_accuracy: 0.8625\n",
      "Epoch 14/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0403 - accuracy: 0.8577 - val_loss: 0.0390 - val_accuracy: 0.8625\n",
      "Epoch 15/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0392 - accuracy: 0.8616 - val_loss: 0.0390 - val_accuracy: 0.8625\n",
      "Epoch 16/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0411 - accuracy: 0.8550 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 17/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0408 - accuracy: 0.8572 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 18/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0397 - accuracy: 0.8615 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 19/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0407 - accuracy: 0.8576 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 20/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0396 - accuracy: 0.8619 - val_loss: 0.0396 - val_accuracy: 0.8625\n",
      "Epoch 21/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0406 - accuracy: 0.8581 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 22/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0407 - accuracy: 0.8572 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 23/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0402 - accuracy: 0.8593 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 24/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0398 - accuracy: 0.8612 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 25/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0400 - accuracy: 0.8604 - val_loss: 0.0382 - val_accuracy: 0.8625\n",
      "Epoch 26/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0406 - accuracy: 0.8581 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 27/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0395 - accuracy: 0.8626 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 28/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0407 - accuracy: 0.8573 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 29/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0402 - accuracy: 0.8594 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 30/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0407 - accuracy: 0.8573 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 31/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0400 - accuracy: 0.8595 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 32/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0404 - accuracy: 0.8588 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 33/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0404 - accuracy: 0.8587 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 34/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0409 - accuracy: 0.8566 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Epoch 35/35\n",
      "641/641 [==============================] - 14s 22ms/step - loss: 0.0412 - accuracy: 0.8553 - val_loss: 0.0395 - val_accuracy: 0.8625\n",
      "Val loss: 3.947924%\n",
      "model: gru\n",
      "embedding_dim: 100\n",
      "num_rnn_node: 410\n",
      "num_dense_node: 90\n",
      "num_layer: 4\n",
      "activation_fn: tanh\n",
      "learning rate: 4.5e-05\n",
      "optimizer: RMSprop\n",
      "margin: 0.6536159322682215\n",
      "batch_size: 11\n",
      "Epoch 1/35\n",
      "2215/2215 [==============================] - 47s 17ms/step - loss: 0.2155 - accuracy: 0.7605 - val_loss: 0.1991 - val_accuracy: 0.8625\n",
      "Epoch 2/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.1940 - accuracy: 0.8603 - val_loss: 0.1808 - val_accuracy: 0.8625\n",
      "Epoch 3/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.1760 - accuracy: 0.8592 - val_loss: 0.1639 - val_accuracy: 0.8625\n",
      "Epoch 4/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.1598 - accuracy: 0.8613 - val_loss: 0.1484 - val_accuracy: 0.8625\n",
      "Epoch 5/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.1445 - accuracy: 0.8590 - val_loss: 0.1344 - val_accuracy: 0.8625\n",
      "Epoch 6/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.1310 - accuracy: 0.8590 - val_loss: 0.1218 - val_accuracy: 0.8625\n",
      "Epoch 7/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.1188 - accuracy: 0.8587 - val_loss: 0.1106 - val_accuracy: 0.8625\n",
      "Epoch 8/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.1080 - accuracy: 0.8568 - val_loss: 0.1008 - val_accuracy: 0.8625\n",
      "Epoch 9/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0986 - accuracy: 0.8595 - val_loss: 0.0921 - val_accuracy: 0.8625\n",
      "Epoch 10/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0906 - accuracy: 0.8543 - val_loss: 0.0847 - val_accuracy: 0.8625\n",
      "Epoch 11/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0833 - accuracy: 0.8589 - val_loss: 0.0784 - val_accuracy: 0.8625\n",
      "Epoch 12/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0776 - accuracy: 0.8562 - val_loss: 0.0730 - val_accuracy: 0.8625\n",
      "Epoch 13/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0721 - accuracy: 0.8599 - val_loss: 0.0685 - val_accuracy: 0.8625\n",
      "Epoch 14/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0680 - accuracy: 0.8588 - val_loss: 0.0648 - val_accuracy: 0.8625\n",
      "Epoch 15/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0650 - accuracy: 0.8558 - val_loss: 0.0617 - val_accuracy: 0.8625\n",
      "Epoch 16/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0624 - accuracy: 0.8550 - val_loss: 0.0593 - val_accuracy: 0.8625\n",
      "Epoch 17/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0594 - accuracy: 0.8593 - val_loss: 0.0574 - val_accuracy: 0.8625\n",
      "Epoch 18/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0575 - accuracy: 0.8598 - val_loss: 0.0558 - val_accuracy: 0.8625\n",
      "Epoch 19/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0559 - accuracy: 0.8605 - val_loss: 0.0546 - val_accuracy: 0.8625\n",
      "Epoch 20/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0560 - accuracy: 0.8554 - val_loss: 0.0537 - val_accuracy: 0.8625\n",
      "Epoch 21/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0536 - accuracy: 0.8614 - val_loss: 0.0524 - val_accuracy: 0.8625\n",
      "Epoch 22/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0532 - accuracy: 0.8584 - val_loss: 0.0519 - val_accuracy: 0.8625\n",
      "Epoch 23/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0518 - accuracy: 0.8621 - val_loss: 0.0512 - val_accuracy: 0.8625\n",
      "Epoch 24/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0519 - accuracy: 0.8578 - val_loss: 0.0492 - val_accuracy: 0.8625\n",
      "Epoch 25/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0506 - accuracy: 0.8560 - val_loss: 0.0473 - val_accuracy: 0.8625\n",
      "Epoch 26/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0487 - accuracy: 0.8579 - val_loss: 0.0468 - val_accuracy: 0.8625\n",
      "Epoch 27/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0485 - accuracy: 0.8559 - val_loss: 0.0465 - val_accuracy: 0.8625\n",
      "Epoch 28/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0477 - accuracy: 0.8598 - val_loss: 0.0461 - val_accuracy: 0.8625\n",
      "Epoch 29/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0475 - accuracy: 0.8573 - val_loss: 0.0458 - val_accuracy: 0.8625\n",
      "Epoch 30/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0471 - accuracy: 0.8568 - val_loss: 0.0456 - val_accuracy: 0.8625\n",
      "Epoch 31/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0469 - accuracy: 0.8582 - val_loss: 0.0452 - val_accuracy: 0.8625\n",
      "Epoch 32/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0464 - accuracy: 0.8582 - val_loss: 0.0451 - val_accuracy: 0.8625\n",
      "Epoch 33/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0463 - accuracy: 0.8591 - val_loss: 0.0449 - val_accuracy: 0.8625\n",
      "Epoch 34/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0462 - accuracy: 0.8595 - val_loss: 0.0450 - val_accuracy: 0.8625\n",
      "Epoch 35/35\n",
      "2215/2215 [==============================] - 35s 16ms/step - loss: 0.0455 - accuracy: 0.8602 - val_loss: 0.0449 - val_accuracy: 0.8625\n",
      "Val loss: 4.489307%\n",
      "model: rnn\n",
      "embedding_dim: 230\n",
      "num_rnn_node: 224\n",
      "num_dense_node: 68\n",
      "num_layer: 4\n",
      "activation_fn: tanh\n",
      "learning rate: 1.1e-05\n",
      "optimizer: RMSprop\n",
      "margin: 0.4908491299482388\n",
      "batch_size: 4\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "('`cell` should have a `call` method. The RNN was passed:', 224)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12093/1552977908.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msearch_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgp_minimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macq_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'EI'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/skopt/optimizer/gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    257\u001b[0m             noise=noise)\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m     return base_minimize(\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0macq_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0macq_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_calls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0mnext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/skopt/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0;31m# Call the wrapped objective function with the named arguments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mobjective_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0marg_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobjective_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_12093/1905092735.py\u001b[0m in \u001b[0;36mfitness\u001b[0;34m(model_type, embedding_dim, num_rnn_node, num_dense_node, num_layer, activation_fn, learning_rate, optimizer, margin, batch_size)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"batch_size:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rnn_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_dense_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rnn_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_dense_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_12093/1546879728.py\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(model_type, embedding_dim, num_rnn_node, num_dense_node, num_layer, activation_fn, learning_rate, optimizer, margin)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_rnn_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"rnn\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_rnn_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_dense_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cell, return_sequences, return_state, go_backwards, stateful, unroll, time_major, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStackedRNNCells\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m'call'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m       raise ValueError('`cell` should have a `call` method. '\n\u001b[0m\u001b[1;32m    405\u001b[0m                        'The RNN was passed:', cell)\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m'state_size'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: ('`cell` should have a `call` method. The RNN was passed:', 224)"
     ]
    }
   ],
   "source": [
    "search_result = gp_minimize(func=fitness, dimensions=dims, acq_func='EI', n_calls=40, x0=default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "af5a7adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = [dim_model, dim_embedding, dim_rnn_node, dim_num_dense_nodes, dim_num_layer, dim_activation, dim_lr, dim_opt, dim_margin, dim_batch_size]\n",
    "default_params = [\"gru\", 64, 128, 64, 2, \"tanh\", 1e-3, \"RMSprop\", 1, 32]\n",
    "best_params = [\"lstm\", 256, 512, 256, 1, \"tanh\", 2e-4, \"Adam\", 0.8, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "705a3881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: lstm\n",
      "embedding_dim: 256\n",
      "num_rnn_node: 512\n",
      "num_dense_node: 256\n",
      "num_layer: 1\n",
      "activation_fn: tanh\n",
      "learning rate: 2.0e-04\n",
      "optimizer: Adam\n",
      "margin: 0.8\n",
      "batch_size: 4\n",
      "Epoch 1/50\n",
      "6089/6089 [==============================] - 95s 14ms/step - loss: 0.0707 - accuracy: 0.8619 - val_loss: 0.0555 - val_accuracy: 0.8625\n",
      "\n",
      "Epoch 00001: saving model to exp3_model/alstm-01-0.06.hdf5\n",
      "Epoch 2/50\n",
      "6089/6089 [==============================] - 84s 14ms/step - loss: 0.0529 - accuracy: 0.8632 - val_loss: 0.0542 - val_accuracy: 0.8625\n",
      "\n",
      "Epoch 00002: saving model to exp3_model/alstm-02-0.05.hdf5\n",
      "Epoch 3/50\n",
      "6089/6089 [==============================] - 84s 14ms/step - loss: 0.0489 - accuracy: 0.8606 - val_loss: 0.0418 - val_accuracy: 0.8625\n",
      "\n",
      "Epoch 00003: saving model to exp3_model/alstm-03-0.04.hdf5\n",
      "Epoch 4/50\n",
      "6089/6089 [==============================] - 82s 14ms/step - loss: 0.0415 - accuracy: 0.8727 - val_loss: 0.0368 - val_accuracy: 0.9107\n",
      "\n",
      "Epoch 00004: saving model to exp3_model/alstm-04-0.04.hdf5\n",
      "Epoch 5/50\n",
      "6089/6089 [==============================] - 85s 14ms/step - loss: 0.0343 - accuracy: 0.9224 - val_loss: 0.0332 - val_accuracy: 0.9343\n",
      "\n",
      "Epoch 00005: saving model to exp3_model/alstm-05-0.03.hdf5\n",
      "Epoch 6/50\n",
      "6089/6089 [==============================] - 83s 14ms/step - loss: 0.0299 - accuracy: 0.9403 - val_loss: 0.0309 - val_accuracy: 0.9381\n",
      "\n",
      "Epoch 00006: saving model to exp3_model/alstm-06-0.03.hdf5\n",
      "Epoch 7/50\n",
      "6089/6089 [==============================] - 86s 14ms/step - loss: 0.0258 - accuracy: 0.9491 - val_loss: 0.0248 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00007: saving model to exp3_model/alstm-07-0.02.hdf5\n",
      "Epoch 8/50\n",
      "6089/6089 [==============================] - 85s 14ms/step - loss: 0.0204 - accuracy: 0.9626 - val_loss: 0.0201 - val_accuracy: 0.9621\n",
      "\n",
      "Epoch 00008: saving model to exp3_model/alstm-08-0.02.hdf5\n",
      "Epoch 9/50\n",
      "6089/6089 [==============================] - 83s 14ms/step - loss: 0.0168 - accuracy: 0.9717 - val_loss: 0.0186 - val_accuracy: 0.9652\n",
      "\n",
      "Epoch 00009: saving model to exp3_model/alstm-09-0.02.hdf5\n",
      "Epoch 10/50\n",
      "6089/6089 [==============================] - 83s 14ms/step - loss: 0.0135 - accuracy: 0.9758 - val_loss: 0.0172 - val_accuracy: 0.9680\n",
      "\n",
      "Epoch 00010: saving model to exp3_model/alstm-10-0.02.hdf5\n",
      "Epoch 11/50\n",
      "6089/6089 [==============================] - 85s 14ms/step - loss: 0.0115 - accuracy: 0.9798 - val_loss: 0.0131 - val_accuracy: 0.9772\n",
      "\n",
      "Epoch 00011: saving model to exp3_model/alstm-11-0.01.hdf5\n",
      "Epoch 12/50\n",
      "6089/6089 [==============================] - 83s 14ms/step - loss: 0.0091 - accuracy: 0.9847 - val_loss: 0.0118 - val_accuracy: 0.9785\n",
      "\n",
      "Epoch 00012: saving model to exp3_model/alstm-12-0.01.hdf5\n",
      "Epoch 13/50\n",
      "6089/6089 [==============================] - 84s 14ms/step - loss: 0.0080 - accuracy: 0.9861 - val_loss: 0.0112 - val_accuracy: 0.9777\n",
      "\n",
      "Epoch 00013: saving model to exp3_model/alstm-13-0.01.hdf5\n",
      "Epoch 14/50\n",
      "6089/6089 [==============================] - 84s 14ms/step - loss: 0.0076 - accuracy: 0.9866 - val_loss: 0.0103 - val_accuracy: 0.9803\n",
      "\n",
      "Epoch 00014: saving model to exp3_model/alstm-14-0.01.hdf5\n",
      "Epoch 15/50\n",
      "6089/6089 [==============================] - 83s 14ms/step - loss: 0.0061 - accuracy: 0.9896 - val_loss: 0.0100 - val_accuracy: 0.9824\n",
      "\n",
      "Epoch 00015: saving model to exp3_model/alstm-15-0.01.hdf5\n",
      "Epoch 16/50\n",
      "6089/6089 [==============================] - 88s 14ms/step - loss: 0.0051 - accuracy: 0.9910 - val_loss: 0.0092 - val_accuracy: 0.9829\n",
      "\n",
      "Epoch 00016: saving model to exp3_model/alstm-16-0.01.hdf5\n",
      "Epoch 17/50\n",
      "6089/6089 [==============================] - 87s 14ms/step - loss: 0.0052 - accuracy: 0.9903 - val_loss: 0.0093 - val_accuracy: 0.9823\n",
      "\n",
      "Epoch 00017: saving model to exp3_model/alstm-17-0.01.hdf5\n",
      "Epoch 18/50\n",
      "6089/6089 [==============================] - 87s 14ms/step - loss: 0.0051 - accuracy: 0.9902 - val_loss: 0.0088 - val_accuracy: 0.9826\n",
      "\n",
      "Epoch 00018: saving model to exp3_model/alstm-18-0.01.hdf5\n",
      "Epoch 19/50\n",
      "6089/6089 [==============================] - 87s 14ms/step - loss: 0.0042 - accuracy: 0.9926 - val_loss: 0.0088 - val_accuracy: 0.9832\n",
      "\n",
      "Epoch 00019: saving model to exp3_model/alstm-19-0.01.hdf5\n",
      "Epoch 20/50\n",
      "6089/6089 [==============================] - 88s 15ms/step - loss: 0.0044 - accuracy: 0.9912 - val_loss: 0.0085 - val_accuracy: 0.9839\n",
      "\n",
      "Epoch 00020: saving model to exp3_model/alstm-20-0.01.hdf5\n",
      "Epoch 21/50\n",
      "6089/6089 [==============================] - 88s 14ms/step - loss: 0.0036 - accuracy: 0.9932 - val_loss: 0.0092 - val_accuracy: 0.9823\n",
      "\n",
      "Epoch 00021: saving model to exp3_model/alstm-21-0.01.hdf5\n",
      "Epoch 22/50\n",
      "6089/6089 [==============================] - 86s 14ms/step - loss: 0.0036 - accuracy: 0.9923 - val_loss: 0.0083 - val_accuracy: 0.9841\n",
      "\n",
      "Epoch 00022: saving model to exp3_model/alstm-22-0.01.hdf5\n",
      "Epoch 23/50\n",
      "6089/6089 [==============================] - 88s 15ms/step - loss: 0.0033 - accuracy: 0.9928 - val_loss: 0.0087 - val_accuracy: 0.9828\n",
      "\n",
      "Epoch 00023: saving model to exp3_model/alstm-23-0.01.hdf5\n",
      "Epoch 24/50\n",
      "6089/6089 [==============================] - 87s 14ms/step - loss: 0.0028 - accuracy: 0.9940 - val_loss: 0.0087 - val_accuracy: 0.9832\n",
      "\n",
      "Epoch 00024: saving model to exp3_model/alstm-24-0.01.hdf5\n",
      "Epoch 25/50\n",
      "6089/6089 [==============================] - 86s 14ms/step - loss: 0.0027 - accuracy: 0.9943 - val_loss: 0.0087 - val_accuracy: 0.9837\n",
      "\n",
      "Epoch 00025: saving model to exp3_model/alstm-25-0.01.hdf5\n",
      "Epoch 26/50\n",
      "6089/6089 [==============================] - 89s 15ms/step - loss: 0.0029 - accuracy: 0.9942 - val_loss: 0.0083 - val_accuracy: 0.9844\n",
      "\n",
      "Epoch 00026: saving model to exp3_model/alstm-26-0.01.hdf5\n",
      "Epoch 27/50\n",
      "6089/6089 [==============================] - 86s 14ms/step - loss: 0.0028 - accuracy: 0.9938 - val_loss: 0.0082 - val_accuracy: 0.9841\n",
      "\n",
      "Epoch 00027: saving model to exp3_model/alstm-27-0.01.hdf5\n",
      "Epoch 28/50\n",
      "6089/6089 [==============================] - 89s 15ms/step - loss: 0.0027 - accuracy: 0.9943 - val_loss: 0.0094 - val_accuracy: 0.9818\n",
      "\n",
      "Epoch 00028: saving model to exp3_model/alstm-28-0.01.hdf5\n",
      "Epoch 29/50\n",
      "6089/6089 [==============================] - 90s 15ms/step - loss: 0.0030 - accuracy: 0.9935 - val_loss: 0.0085 - val_accuracy: 0.9837\n",
      "\n",
      "Epoch 00029: saving model to exp3_model/alstm-29-0.01.hdf5\n",
      "Epoch 30/50\n",
      "6089/6089 [==============================] - 93s 15ms/step - loss: 0.0026 - accuracy: 0.9944 - val_loss: 0.0084 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00030: saving model to exp3_model/alstm-30-0.01.hdf5\n",
      "Epoch 31/50\n",
      "6089/6089 [==============================] - 93s 15ms/step - loss: 0.0025 - accuracy: 0.9944 - val_loss: 0.0084 - val_accuracy: 0.9842\n",
      "\n",
      "Epoch 00031: saving model to exp3_model/alstm-31-0.01.hdf5\n",
      "Epoch 32/50\n",
      "6089/6089 [==============================] - 92s 15ms/step - loss: 0.0028 - accuracy: 0.9939 - val_loss: 0.0083 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00032: saving model to exp3_model/alstm-32-0.01.hdf5\n",
      "Epoch 33/50\n",
      "6089/6089 [==============================] - 93s 15ms/step - loss: 0.0027 - accuracy: 0.9940 - val_loss: 0.0083 - val_accuracy: 0.9834\n",
      "\n",
      "Epoch 00033: saving model to exp3_model/alstm-33-0.01.hdf5\n",
      "Epoch 34/50\n",
      "6089/6089 [==============================] - 93s 15ms/step - loss: 0.0028 - accuracy: 0.9939 - val_loss: 0.0081 - val_accuracy: 0.9849\n",
      "\n",
      "Epoch 00034: saving model to exp3_model/alstm-34-0.01.hdf5\n",
      "Epoch 35/50\n",
      "6089/6089 [==============================] - 92s 15ms/step - loss: 0.0022 - accuracy: 0.9950 - val_loss: 0.0084 - val_accuracy: 0.9826\n",
      "\n",
      "Epoch 00035: saving model to exp3_model/alstm-35-0.01.hdf5\n",
      "Epoch 36/50\n",
      "6089/6089 [==============================] - 92s 15ms/step - loss: 0.0020 - accuracy: 0.9954 - val_loss: 0.0083 - val_accuracy: 0.9837\n",
      "\n",
      "Epoch 00036: saving model to exp3_model/alstm-36-0.01.hdf5\n",
      "Epoch 37/50\n",
      " 934/6089 [===>..........................] - ETA: 1:12 - loss: 0.0018 - accuracy: 0.9936"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12093/1860783807.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfitness2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/skopt/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0;31m# Call the wrapped objective function with the named arguments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mobjective_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0marg_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobjective_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_12093/3426048739.py\u001b[0m in \u001b[0;36mfitness2\u001b[0;34m(model_type, embedding_dim, num_rnn_node, num_dense_node, num_layer, activation_fn, learning_rate, optimizer, margin, batch_size)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rnn_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_dense_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     history = model.fit(x=[np.array(x1TrainRnnS), np.array(x2TrainRnnS)],\n\u001b[0m\u001b[1;32m     19\u001b[0m                         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myTrainRnnS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#                         epochs=35,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fitness2(x=best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356eb905",
   "metadata": {},
   "source": [
    "## build_model2   (build and load_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f2a2d68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(model_type, embedding_dim, num_rnn_node, num_dense_node, num_layer, activation_fn, learning_rate, optimizer, margin):\n",
    "    input_x = tf.keras.layers.Input(maxlen)\n",
    "    input_1 = tf.keras.layers.Input(maxlen)\n",
    "    input_2 = tf.keras.layers.Input(maxlen)\n",
    "    embedding = tf.keras.layers.Embedding(input_dim=28, output_dim=embedding_dim, mask_zero=True)\n",
    "    x = embedding(input_x)\n",
    "    \n",
    "    if model_type == \"lstm\":\n",
    "        x = tf.keras.layers.LSTM(num_rnn_node)(x)\n",
    "    elif model_type==\"gru\":\n",
    "        x = tf.keras.layers.GRU(num_rnn_node)(x)\n",
    " \n",
    "    num = num_dense_node\n",
    "    for _ in range(num_layer):\n",
    "        x = tf.keras.layers.Dense(num, activation=activation_fn)(x)\n",
    "        num /= 2\n",
    "        \n",
    "    embedding_network = tf.keras.Model(input_x, x)\n",
    "\n",
    "    tower_1 = embedding_network(input_1)\n",
    "    tower_2 = embedding_network(input_2)\n",
    "\n",
    "    merge_layer = tf.keras.layers.Lambda(cosine_distance)([tower_1, tower_2])\n",
    "    output_layer = tf.keras.layers.Dense(1, activation=\"sigmoid\")(merge_layer)\n",
    "    contr = tf.keras.Model(inputs=[input_1, input_2], outputs=output_layer)\n",
    "    \n",
    "    if optimizer == \"Adam\":\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer ==\"RMSprop\":                \n",
    "        opt = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    contr.compile(loss=loss(margin= margin), optimizer=opt, metrics=[\"accuracy\"])\n",
    "    return contr\n",
    "\n",
    "\n",
    "model = build_model2(\"lstm\", 256, 512, 256, 1, \"tanh\", 2e-4, \"Adam\", 0.8)\n",
    "# history = model.fit(x=[np.array(x1TrainRnnS), np.array(x2TrainRnnS)],\n",
    "#                         y=np.array(yTrainRnnS, dtype=np.float32),\n",
    "#                         epochs=30,\n",
    "#                         batch_size=4,\n",
    "#                         validation_data=([np.array(x1ValRnnS), np.array(x2ValRnnS)], np.array(yValRnnS, dtype=np.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbdef53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"alstm-22-0.01.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3de51446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "607e2242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = model.layers[2] \n",
    "\n",
    "tf.keras.utils.plot_model(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "411314df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9209609 ,  0.9818054 , -0.55112475, ...,  0.9550037 ,\n",
       "        -0.91177493,  0.33567536],\n",
       "       [-0.32707602, -0.8085312 ,  0.36298504, ..., -0.5971373 ,\n",
       "        -0.48414686, -0.7461844 ],\n",
       "       [ 0.7975746 ,  0.911223  ,  0.97358453, ..., -0.9646154 ,\n",
       "        -0.9465658 ,  0.87808084],\n",
       "       ...,\n",
       "       [ 0.91921526, -0.19321522, -0.48451972, ..., -0.26542348,\n",
       "        -0.6002104 ,  0.9337821 ],\n",
       "       [ 0.88084954, -0.8885829 , -0.93869764, ..., -0.851074  ,\n",
       "        -0.9151342 , -0.74037963],\n",
       "       [-0.829067  ,  0.98988235,  0.9152043 , ..., -0.9624905 ,\n",
       "         0.5317913 , -0.9575233 ]], dtype=float32)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.predict(dUnique)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clock",
   "language": "python",
   "name": "clock"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
